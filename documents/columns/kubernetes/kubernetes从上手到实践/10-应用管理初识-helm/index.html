<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
<meta name="X-UA-Compatible" , content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0">

<link rel="icon" type="image/png" href="/%20/favicon.png">

<title>10 应用管理：初识 Helm | Yipsen Ye</title>
<meta name="description" content="整体概览 上节，我们已经学习了如何通过编写配置文件的方式部署项目。而在实际生产环境中，项目所包含组件可能不止 3 个，并且可能项目数会很多，如果每个项目的发布，更新等都通过手动去编写配置文件的方式，实在不利于管理。
并且，当线上出现个别组件升级回滚之类的操作，如果组件之间有相关版本依赖等情况，那事情会变得复杂的多。我们需要有更简单的机制来辅助我们完成这些事情。
Helm 介绍 Helm 是构建于 K8S 之上的包管理器，可与我们平时接触到的 Yum，APT，Homebrew 或者 Pip 等包管理器相类比。
使用 Helm 可简化包分发，安装，版本管理等操作流程。同时它也是 CNCF 孵化项目。
Helm 安装 Helm 是 C/S 架构，主要分为客户端 helm 和服务端 Tiller。安装时可直接在 Helm 仓库的 Release 页面 下载所需二进制文件或者源码包。
由于当前项目的二进制文件存储已切换为 GCS，我已经为国内用户准备了最新版本的二进制包，可通过以下链接进行下载。
链接: https://pan.baidu.com/s/1n1zj3rlv2NyfiA6kRGrHfg 提取码: 5huw 下载后对文件进行解压，我这里以 Linux amd64 为例。
➜ /tmp tar -zxvf helm-v2.11.0-linux-amd64.tar.gz linux-amd64/ linux-amd64/tiller linux-amd64/README.md linux-amd64/helm linux-amd64/LICENSE ➜ /tmp tree linux-amd64 linux-amd64 ├── helm ├── LICENSE ├── README.md └── tiller 0 directories, 4 files 解压完成后，可看到其中包含 helm 和 tiller 二进制文件。">
<meta name="author" content="">

<link rel="stylesheet" type="text/css" href="/styles/main.css">

</head>

<body id="page">
    <header>
        <div class="logo-link" style="width: 60px; color: #CA6924;">
    <a href="http://yipsen.github.io/">
        <img style="margin-bottom: -1rem;" src="/images/deer.svg" alt="logo">
        <span style="font-size: 0.5rem; color: #CA6924;">Yipsen Ye</span>
    </a>
</div>
<nav class="navbar justify-content-end">
    <ul class="nav-list">
        
        
        <li class="nav-item">
            <a class="nav-link"
                href="http://yipsen.github.io/posts/">札记</a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link"
                href="http://yipsen.github.io/collections/">附表</a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link"
                href="http://yipsen.github.io/about/">关于</a>
        </li>
        
    </ul>
</nav>
    </header>
    <main id="content">
        
<div class="container"><aside>
    <div>
        
        
            
            
            <div class="post-category-icon"></div>
            <a href="/categories/kubernetes%e4%bb%8e%e4%b8%8a%e6%89%8b%e5%88%b0%e5%ae%9e%e8%b7%b5/">Kubernetes从上手到实践</a>
            <ul>
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/01-%E5%BC%80%E7%AF%87-kubernetes-%E6%98%AF%E4%BB%80%E4%B9%88%E4%BB%A5%E5%8F%8A%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%AE%83/">01 开篇： Kubernetes 是什么以及为什么需要它</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/02-%E5%88%9D%E6%AD%A5%E8%AE%A4%E8%AF%86kubernetes-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/">02 初步认识：Kubernetes 基础概念</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/03-%E5%AE%8F%E8%A7%82%E8%AE%A4%E8%AF%86%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/">03 宏观认识：整体架构</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/04-%E6%90%AD%E5%BB%BA-kubernetes-%E9%9B%86%E7%BE%A4-%E6%9C%AC%E5%9C%B0%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/">04 搭建 Kubernetes 集群 - 本地快速搭建</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/05-%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA-kubernetes-%E9%9B%86%E7%BE%A4-%E7%94%9F%E4%BA%A7%E5%8F%AF%E7%94%A8/">05 动手实践：搭建一个 Kubernetes 集群 - 生产可用</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/06-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%88%9D%E8%AF%86-kubectl/">06 集群管理：初识 kubectl</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/07-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E4%BB%A5-redis-%E4%B8%BA%E4%BE%8B-%E9%83%A8%E7%BD%B2%E5%8F%8A%E8%AE%BF%E9%97%AE/">07 集群管理：以 Redis 为例-部署及访问</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/08-%E5%AE%89%E5%85%A8%E9%87%8D%E7%82%B9-%E8%AE%A4%E8%AF%81%E5%92%8C%E6%8E%88%E6%9D%83/">08 安全重点 认证和授权</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/09-%E5%BA%94%E7%94%A8%E5%8F%91%E5%B8%83%E9%83%A8%E7%BD%B2%E5%AE%9E%E9%99%85%E9%A1%B9%E7%9B%AE/">09 应用发布：部署实际项目</a></li>
                
                
                
                    <li>10 应用管理：初识 Helm</li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/11-%E9%83%A8%E7%BD%B2%E5%AE%9E%E8%B7%B5%E4%BB%A5-helm-%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE/">11 部署实践：以 Helm 部署项目</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/12-%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9Bkube-apiserver/">12 庖丁解牛：kube-apiserver</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/13-%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9Betcd/">13 庖丁解牛：etcd</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/14-%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9Bcontroller-manager/">14 庖丁解牛：controller-manager</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/15-%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9Bkube-scheduler/">15 庖丁解牛：kube-scheduler</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/16-%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9Bkubelet/">16 庖丁解牛：kubelet</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/17-%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9Bkube-proxy/">17 庖丁解牛：kube-proxy</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/18-%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9Bcontainer-runtime-docker/">18 庖丁解牛：Container Runtime （Docker）</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/19-troubleshoot/">19 Troubleshoot</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/20-%E6%89%A9%E5%B1%95%E5%A2%9E%E5%BC%BAdashboard/">20 扩展增强：Dashboard</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/21-%E6%89%A9%E5%B1%95%E5%A2%9E%E5%BC%BAcoredns/">21 扩展增强：CoreDNS</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/22-%E6%9C%8D%E5%8A%A1%E5%A2%9E%E5%BC%BAingress/">22 服务增强：Ingress</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/23-%E7%9B%91%E6%8E%A7%E5%AE%9E%E8%B7%B5%E5%AF%B9-k8s-%E9%9B%86%E7%BE%A4%E8%BF%9B%E8%A1%8C%E7%9B%91%E6%8E%A7/">23 监控实践：对 K8S 集群进行监控</a></li>
                
                
                
                    <li><a href="http://yipsen.github.io/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/24-%E6%80%BB%E7%BB%93/">24 总结</a></li>
                
                
            </ul>
        
    </div>
</aside>

<style>
    aside {
        position: fixed;
        left: 20px;
        background: #ffdee3;
        border-radius: 6px;
        padding: 20px;
        padding-top: 60px;
        box-shadow: 5px 10px #888;
        list-style-type: none;
        display: none;
    }

    .post-category-icon {
        position: absolute;
        width: 80px;
        height: 80px;
        top: -40px;
        left: 50%;
        margin-left: -40px;
        text-align: center;
        font-size: 36px;
        content: 'J';
        background: #ffdee3;
        border-radius: 100%;
        border: 10px solid #fff;
        box-shadow: 5px 10px #888;
    }
</style><article class="post-block">
        <h1 class="post-title">10 应用管理：初识 Helm</h1>
        <div class="post-info">
            <div> 
                <span class="post-date">📅&nbsp;2021-12-22 01:47:36</span>🏷️&nbsp;<a class="post-tag" href="/tags/kubernetes/">kubernetes</a></div><div class="post-category">
                
                📚&nbsp;<a href="/categories/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/">Kubernetes从上手到实践</a>
                
            </div></div>
        <div class="post-content">
            <h2 id="整体概览">整体概览</h2>
<p>上节，我们已经学习了如何通过编写配置文件的方式部署项目。而在实际生产环境中，项目所包含组件可能不止 3 个，并且可能项目数会很多，如果每个项目的发布，更新等都通过手动去编写配置文件的方式，实在不利于管理。</p>
<p>并且，当线上出现个别组件升级回滚之类的操作，如果组件之间有相关版本依赖等情况，那事情会变得复杂的多。我们需要有更简单的机制来辅助我们完成这些事情。</p>
<h2 id="helm-介绍">Helm 介绍</h2>
<p><a href="https://www.helm.sh/">Helm</a> 是构建于 K8S 之上的包管理器，可与我们平时接触到的 <code>Yum</code>，<code>APT</code>，<code>Homebrew</code> 或者 <code>Pip</code> 等包管理器相类比。</p>
<p>使用 Helm 可简化包分发，安装，版本管理等操作流程。同时它也是 CNCF 孵化项目。</p>
<h2 id="helm-安装">Helm 安装</h2>
<p>Helm 是 C/S 架构，主要分为客户端 <code>helm</code> 和服务端 <code>Tiller</code>。安装时可直接在 <a href="https://github.com/helm/helm/releases">Helm 仓库的 Release 页面</a> 下载所需二进制文件或者源码包。</p>
<p>由于当前项目的二进制文件存储已切换为 GCS，我已经为国内用户准备了最新版本的二进制包，可通过以下链接进行下载。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">链接: https://pan.baidu.com/s/1n1zj3rlv2NyfiA6kRGrHfg 提取码: 5huw 
</code></pre></div><p>下载后对文件进行解压，我这里以 Linux amd64 为例。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  /tmp tar -zxvf helm-v2.11.0-linux-amd64.tar.gz
linux-amd64/
linux-amd64/tiller
linux-amd64/README.md
linux-amd64/helm
linux-amd64/LICENSE
➜  /tmp tree linux-amd64 
linux-amd64
├── helm
├── LICENSE
├── README.md
└── tiller

<span style="color:#ae81ff">0</span> directories, <span style="color:#ae81ff">4</span> files
</code></pre></div><p>解压完成后，可看到其中包含 <code>helm</code> 和 <code>tiller</code> 二进制文件。</p>
<h3 id="客户端-helm">客户端 helm</h3>
<p><code>helm</code> 是个二进制文件，直接将它移动至 <code>/usr/bin</code> 目录下即可。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  /tmp sudo mv linux-amd64/helm /usr/bin/helm 
</code></pre></div><p>这时候便可直接通过 <code>helm</code> 命令使用了。比如，我们验证当前使用的版本。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  /tmp helm version
Client: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;2e55dbe1fdb5fdb96b75ff144a339489417b146b&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
Error: Get http://localhost:8080/api/v1/namespaces/kube-system/pods?labelSelector<span style="color:#f92672">=</span>app%3Dhelm%2Cname%3Dtiller: dial tcp 127.0.0.1:8080: connect: connection refused
</code></pre></div><p>可以看到上面有明显的报错，并且很像 <code>kubectl</code> 未正确配置时的错误。这是因为 <code>helm</code> 默认会去读取 <code>$HOME/.kube/config</code> 的配置文件，用于正确的连接至目标集群。</p>
<p>当我们正确的配置好 <code>$HOME/.kube/config</code> 文件时，再次执行：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  /tmp helm version
Client: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;2e55dbe1fdb5fdb96b75ff144a339489417b146b&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
Error: could not find tiller
</code></pre></div><p>这次报错是因为找不到服务端 <code>Tiller</code>，接下来我们部署服务端。</p>
<h3 id="服务端-tiller">服务端 Tiller</h3>
<p>以下讨论中，前提都是 <code>$HOME/.kube/config</code> 已正确配置，并且 <code>kebectl</code> 有操作集群的权限。</p>
<h4 id="本地安装">本地安装</h4>
<p>刚才我们解压的文件中，还有一个二进制文件 <code>tiller</code> 。我们可以直接执行它，用于在本地启动服务。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  /tmp ./linux-amd64/tiller
<span style="color:#f92672">[</span>main<span style="color:#f92672">]</span> 2018/11/18 23:47:10 Starting Tiller v2.11.0 <span style="color:#f92672">(</span>tls<span style="color:#f92672">=</span>false<span style="color:#f92672">)</span>
<span style="color:#f92672">[</span>main<span style="color:#f92672">]</span> 2018/11/18 23:47:10 GRPC listening on :44134
<span style="color:#f92672">[</span>main<span style="color:#f92672">]</span> 2018/11/18 23:47:10 Probes listening on :44135
<span style="color:#f92672">[</span>main<span style="color:#f92672">]</span> 2018/11/18 23:47:10 Storage driver is ConfigMap
<span style="color:#f92672">[</span>main<span style="color:#f92672">]</span> 2018/11/18 23:47:10 Max history per release is <span style="color:#ae81ff">0</span>
</code></pre></div><p>直接执行时，默认会监听 <code>44134</code> 和 <code>44135</code> 端口，<code>44134</code> 端口用于和 <code>helm</code> 进行通信，而 <code>44135</code> 主要是用于做探活的，在部署至 K8S 时使用。</p>
<p>当我们使用客户端连接时，只需设置 <code>HELM_HOST</code> 环境变量即可。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  ~ export HELM_HOST<span style="color:#f92672">=</span>localhost:44134
➜  ~ helm version
Client: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;2e55dbe1fdb5fdb96b75ff144a339489417b146b&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
Server: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;2e55dbe1fdb5fdb96b75ff144a339489417b146b&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
</code></pre></div><p><strong>注意</strong> 一定要正确配置 <code>$HOME/.kube/config</code> 文件，否则会影响正常功能使用。</p>
<h4 id="默认安装">默认安装</h4>
<p>官方提供了一种一键式安装的方式。那便是 <code>helm init</code> 执行这条命令后，会同时在 K8S 中部署服务端 Tiller 和初始化 helm 的默认目录 <code>$HELM_HOME</code> 默认值为 <code>$HOME/.helm</code>。</p>
<p>这种方式下会默认使用官方镜像 <code>gcr.io/kubernetes-helm/tiller</code> 网络原因可能会导致安装失败。所以我已将官方镜像进行同步。可使用以下方式进行使用：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  ~ helm init --tiller-image taobeier/tiller:v2.11.0 
Creating /root/.helm
Creating /root/.helm/repository
Creating /root/.helm/repository/cache
Creating /root/.helm/repository/local
Creating /root/.helm/plugins
Creating /root/.helm/starters
Creating /root/.helm/cache/archive
Creating /root/.helm/repository/repositories.yaml
Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com
Adding local repo with URL: http://127.0.0.1:8879/charts
$HELM_HOME has been configured at /root/.helm.

Tiller <span style="color:#f92672">(</span>the Helm server-side component<span style="color:#f92672">)</span> has been installed into your Kubernetes Cluster.

Please note: by default, Tiller is deployed with an insecure <span style="color:#e6db74">&#39;allow unauthenticated users&#39;</span> policy.
To prevent this, run <span style="color:#e6db74">`</span>helm init<span style="color:#e6db74">`</span> with the --tiller-tls-verify flag.
For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation
Happy Helming!
➜  ~ helm version
Client: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;9ad53aac42165a5fadc6c87be0dea6b115f93090&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
Server: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;2e55dbe1fdb5fdb96b75ff144a339489417b146b&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
</code></pre></div><p>可以看到 <code>$HELM_HOME</code> 目录已经初始化完成，客户端与服务端已可以正常通信。查看下当前 K8S 集群中的情况：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  ~ kubectl -n kube-system get deploy tiller-deploy
NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
tiller-deploy   <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           6m
</code></pre></div><p>可以看到已正常部署。</p>
<h4 id="手动安装">手动安装</h4>
<p>通过上面的描述，可能你已经发现，安装服务端，其实也就是一次普通的部署，我们可以通过以下方式来自行通过 <code>kubectl</code> 完成部署。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  ~ helm init --dry-run --debug  <span style="color:#75715e"># 篇幅原因，以下内容进行了省略</span>
---                               
apiVersion: extensions/v1beta1
kind: Deployment                                    
metadata:                            
  creationTimestamp: null
  labels:         
    app: helm              
    name: tiller       
  name: tiller-deploy           
  namespace: kube-system   
spec:               
  replicas: <span style="color:#ae81ff">1</span> 
  strategy: <span style="color:#f92672">{}</span>                
  ...
status: <span style="color:#f92672">{}</span>

---
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    app: helm
    name: tiller
  name: tiller-deploy
  namespace: kube-system
spec:
  ports:
  - name: tiller
    port: <span style="color:#ae81ff">44134</span>
    targetPort: tiller
  selector:
    app: helm
    name: tiller
  type: ClusterIP
status:
  loadBalancer: <span style="color:#f92672">{}</span>
</code></pre></div><p>将输出内容保存至文件中，自行修改后，通过 <code>kubectl</code> 进行部署即可。建议在修改过程中，尽量不要去更改标签及选择器。</p>
<h4 id="rbac-使用">RBAC 使用</h4>
<p>上面的内容中，均未提及到权限控制相关的内容，但是在生产环境中使用，我们一般都是会进行权限控制的。</p>
<p>在第 8 节中，我们已经详细的解释了认证授权相关的内容。所以下面的内容不做太多详细解释。</p>
<p>这里我们创建一个 <code>ServiceAccount</code> 命名为 <code>tiller</code>，为了简单，我们直接将它与 <code>cluster-admin</code> 进行绑定。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tiller</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tiller</span>
<span style="color:#f92672">roleRef</span>:
  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admin</span>
<span style="color:#f92672">subjects</span>:
  - <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tiller</span>
    <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</code></pre></div><p>将此内容保存为 <code>tiller-rbac.yaml</code>，开始进行部署操作。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  ~ kubectl apply -f tiller-rbac.yaml
serviceaccount/tiller created
clusterrolebinding.rbac.authorization.k8s.io/tiller created
➜  ~ helm init --service-account tiller
Creating /root/.helm
Creating /root/.helm/repository
Creating /root/.helm/repository/cache
Creating /root/.helm/repository/local
Creating /root/.helm/plugins
Creating /root/.helm/starters
Creating /root/.helm/cache/archive
Creating /root/.helm/repository/repositories.yaml
Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com
Adding local repo with URL: http://127.0.0.1:8879/charts
$HELM_HOME has been configured at /root/.helm.

Tiller <span style="color:#f92672">(</span>the Helm server-side component<span style="color:#f92672">)</span> has been installed into your Kubernetes Cluster.

Please note: by default, Tiller is deployed with an insecure <span style="color:#e6db74">&#39;allow unauthenticated users&#39;</span> policy.
To prevent this, run <span style="color:#e6db74">`</span>helm init<span style="color:#e6db74">`</span> with the --tiller-tls-verify flag.
For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation
Happy Helming!
➜  ~ helm version
Client: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;2e55dbe1fdb5fdb96b75ff144a339489417b146b&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
Server: &amp;version.Version<span style="color:#f92672">{</span>SemVer:<span style="color:#e6db74">&#34;v2.11.0&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;2e55dbe1fdb5fdb96b75ff144a339489417b146b&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span><span style="color:#f92672">}</span>
</code></pre></div><p>以此方式完成部署。</p>
<h2 id="helm-概念">Helm 概念</h2>
<h3 id="chart">Chart</h3>
<p><code>chart</code> 就是 Helm 所管理的包，类似于 <code>Yum</code> 所管理的 <code>rpm</code> 包或是 <code>Homebrew</code> 管理的 <code>Formulae</code>。它包含着一个应用要部署至 K8S 上所必须的所有资源。</p>
<h3 id="release">Release</h3>
<p><code>Release</code> 就是 <code>chart</code> 在 K8S 上部署后的实例。<code>chart</code> 的每次部署都将产生一次 <code>Release</code>。这和上面类比的包管理器就有所不同了，多数的系统级包管理器所安装的包只会在系统中存在一份。我们可以以 <code>Pip</code> 在虚拟环境下的包安装，或者 <code>Npm</code> 的 local install 来进行类比。</p>
<h3 id="repository">Repository</h3>
<p><code>Repository</code> 就是字面意思，存储 <code>chart</code> 的仓库。还记得我们上面执行 <code>helm init</code> 时的输出吗？默认情况下，初始化 Helm 的时候，会添加两个仓库，一个是 <code>stable</code> 仓库 <a href="https://kubernetes-charts.storage.googleapis.com/">kubernetes-charts.storage.googleapis.com</a> 另一个则是 <code>local</code> 仓库，地址是 <a href="http://127.0.0.1:8879/charts">http://127.0.0.1:8879/charts</a> 。</p>
<h3 id="config">Config</h3>
<p>前面提到了 <code>chart</code> 是应用程序所必须的资源，当然我们实际部署的时候，可能就需要有些自定义的配置了。<code>Config</code> 便是用于完成此项功能的，在部署时候，会将 <code>config</code> 与 <code>chart</code> 进行合并，共同构成我们将部署的应用。</p>
<h2 id="helm-的工作原理">Helm 的工作原理</h2>
<p><code>helm</code> 通过 <code>gRPC</code> 将 <code>chart</code> 发送至 <code>Tiller</code> ，<code>Tiller</code> 则通过内置的 <code>kubernetes</code> 客户端库与 K8S 的 API server 进行交流，将 <code>chart</code> 进行部署，并生成 <code>Release</code> 用于管理。</p>
<p>前面只说到了 <code>helm</code> 与 <code>Tiller</code> 交互的协议，但尚未说其数据链路。</p>
<p>我们来看看 <code>Tiller</code> 的部署情况。主要看 <code>Service</code>：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">➜  ~ kubectl -n kube-system get svc
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>         AGE
kube-dns        ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP   1h
tiller-deploy   ClusterIP   10.107.204.164   &lt;none&gt;        44134/TCP       33m
</code></pre></div><p><code>Tiller</code> 默认采用 <code>ClusterIP</code> 类型的 <code>Service</code> 进行部署。而我们知道的 <code>ClusterIP</code> 类型的 <code>Service</code> 是仅限集群内访问的。</p>
<p>在这里所依赖的技术，便是在第 5 节，我们提到的 <code>socat</code> 。<code>helm</code> 通过 <code>socat</code> 的端口转发（或者说 K8S 的代理），进而实现了本地与 <code>Tiller</code> 的通信。</p>
<p>当然，以上内容均以当前最新版本 <code>2.11.0</code> 为例。当下一个大版本 Helm v3 出现时， <code>Tiller</code> 将不复存在，通信机制和工作原理也将发生变化。</p>
<h2 id="总结">总结</h2>
<p>通过本节，我们已经学习到了 Helm 的基础知识和工作原理，了解到了 Helm 的用途以及如何在本地和 K8S 中部署它。需要注意的是 <code>$HOME/.kube/config</code> 需要提前配置好，以及 <code>socat</code> 工具需要提前安装，可参考第 5 节的内容。</p>
<p>接下来，我们将上节中的示例项目使用 Helm 部署至 K8S 集群中。</p>

        </div>
    </article>
</div>

    </main>
    <footer>
        <div id="pagination">
            
<div class="paginator">
    <div class="prev">
        
        <a href="/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/09-%E5%BA%94%E7%94%A8%E5%8F%91%E5%B8%83%E9%83%A8%E7%BD%B2%E5%AE%9E%E9%99%85%E9%A1%B9%E7%9B%AE/"><span>09 应用发布：部署实际项目</span></a>
    </div>
    <div class="next">
        
        <a href="/documents/columns/kubernetes/kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5/11-%E9%83%A8%E7%BD%B2%E5%AE%9E%E8%B7%B5%E4%BB%A5-helm-%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE/"><span>11 部署实践：以 Helm 部署项目</span></a>
    </div>
</div>

        </div>
        <div class="toggler" onclick="toggleLight(this);">💡</div>
        <div id="copyright" style="display: none;">
    
    
    <p>&copy; 28280 <a href="/"></a>, powered by Hugo and Qiao</p>
</div>
    </footer>
    
<script>
    function toggleLight() {
        document.getElementById('page').classList.toggle('night');
    }
</script>
</body>

</html>