<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>重学操作系统 on </title>
    <link>http://yipsen.github.io/categories/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
    <description>Recent content in 重学操作系统 on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 22 Dec 2021 01:49:42 +0800</lastBuildDate><atom:link href="http://yipsen.github.io/categories/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>41 结束语 论程序员的发展——信仰、选择和博弈</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/41-%E7%BB%93%E6%9D%9F%E8%AF%AD-%E8%AE%BA%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E5%8F%91%E5%B1%95%E4%BF%A1%E4%BB%B0%E9%80%89%E6%8B%A9%E5%92%8C%E5%8D%9A%E5%BC%88/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:42 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/41-%E7%BB%93%E6%9D%9F%E8%AF%AD-%E8%AE%BA%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E5%8F%91%E5%B1%95%E4%BF%A1%E4%BB%B0%E9%80%89%E6%8B%A9%E5%92%8C%E5%8D%9A%E5%BC%88/</guid>
      <description>历时 5 个多月、40 讲的操作系统知识我们已经学完了。更准确地说应该是 50 讲，这最后一讲我想和你聊聊，作为一名程序员，我的职业观，以及我是如何进行选择的。
信仰 我觉得一切选择的根源是自己相信的东西，简单理解你可以说这就是信仰。信仰是如同地下车库中看不见的龙那样的事物，从哥德尔不完备性定理上去看信仰，它既不可以被证明也不可以被证伪，但是这是支撑你一切行为的基础。
相信知识的家庭砸锅卖铁让孩子上大学；不相信知识了家庭，冲进厕所，撕了孩子手上的《三国演义》。我相信知识改变命运，它毫无道理，毫无依据，没有办法证明，亦无法证伪，它完全可以自圆其说，但是却又找不到源头，可是就是这种虚无缥缈的东西左右着我的选择。
选择 有了信仰，自然而然，人就会选择。比如我林䭽的信仰是“知识改变命运”，而获取知识需要渠道和时间。
拓展渠道就要虚心地请教拥有知识的人，不能吝啬请客吃饭的钱，过节要给技术大牛筹备礼物，花钱买书不能心疼。为了节省时间，就需要租下公司边上很贵的房子，去节省上下班的时间。哪怕我工资将将过万的时候，我也愿意花 5000 块钱去租公司旁边的房子。
那么做这些事情，是对还是错呢？——我永远都无法去证明这些答案的对错，甚至我们得不到答案。不过有了相信的东西是美好的，因为你选择的时候不需要焦虑和犹豫。有了相信的东西，不去做，一定会后悔。这不是我给你的建议，我不太喜欢给人以人生大道理和建议，我觉得每个人思考的方式是不同的。我只能告诉你，我在这样思考问题。其实你也可以在留言区和我交流你的想法，和大家一起交流。
博弈 做出了选择，就会承担后果，这就博弈。每一个选择都有两面性，可能成功，也可能失败，所以是在博弈。
拿时间换来知识，知识不一定能用上。熬夜去背面试题，明天面试官也未见得会考到你背好的题目。花 1 年刷算法题，将来能写几个算法？
所以这个时候，我们需要的是相信。支撑人走到最后的东西。一定是你相信的东西。如果你相信善，那你就将它贯彻到底。也许会得到回报，多数我遇到的情况是这种回报未必就是我一开始设想的。因为所有东西都会出现变数，我知道多数人想做优秀的程序员。但是你有没有相信过，未来的 50 年程序将继续改变这个世界？你信不信，黑客的精神，依然会在未来的 100 年内延续。这些东西没有办法证明，只有相信。我相信！也许你不信，这不重要。
用我自己感受来说，在我人生的某个时候，我也曾经觉得《原神》比程序好玩。但是我玩腻了游戏，就要回去写程序了。写程序的时候，给了我人生一种满足感，是和游戏的满足感不一样的。
我现在所说的并不是一次心灵的鸡汤，不是告诉你“爱拼就会赢”这种无法证明的道理。我是把一个工作了 11 年的资深程序员的感受告诉给你：当为了自己所相信的东西去努力的时候，人的快乐和幸福指数会高一些。
以上就是我，对程序员职业发展的一点见解。最后还是感谢你来学习我的专栏，我会继续努力。将更多、更难的知识，以简单、有趣的形式带入你的视野，帮助你成长。如果你感兴趣，今后可以和我一起学习。</description>
    </item>
    
    <item>
      <title>40 商业操作系统：电商操作系统是不是一个噱头？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/40-%E5%95%86%E4%B8%9A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%94%B5%E5%95%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%98%AF%E4%B8%8D%E6%98%AF%E4%B8%80%E4%B8%AA%E5%99%B1%E5%A4%B4/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:41 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/40-%E5%95%86%E4%B8%9A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%94%B5%E5%95%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%98%AF%E4%B8%8D%E6%98%AF%E4%B8%80%E4%B8%AA%E5%99%B1%E5%A4%B4/</guid>
      <description>关于电商操作系统是不是一个噱头？我觉得对于想要哄抬股价、营造风口的资本来说，这无疑是一场盛宴。但是对于从事多年业务架构，为了这件事情努力的架构师们而言，这似乎不是一个遥远的梦想，而是可以通过手中的键盘、白板上的图纸去付诸实践的目标。
我们暂且不为这个问题是不是噱头定性，不如先来聊一聊什么是商业操作系统，聊一聊它的设计思路和基本理念。
进程的抽象 你可以把一个大型的电商公司想象成一个商业操作系统，它的目标是为其中的每个参与者分配资源。这些资源不仅仅是计算资源，还会有市场资源、渠道资源、公关资源、用户资源，等等。
这样操作系统上的进程也被分成了几种类别，比如说内核程序，其实就是电商公司。应用程序就包括商家、供应商、品牌方、第三方支付、大数据分析公司等一系列组织的策略。
接下来，我们以商家为例讨论进程。在操作系统中进程是应用程序的执行副本。它不仅仅是在内核的进程表中留下一条记录，它更像拥有独立思考能力的人，它需要什么资源就会自己去操作系统申请。它会遵循操作系统的规则，为自己的用户服务，完成自己的商业目的。
所以如果上升到操作系统的高度来设计电商系统。我们不仅要考虑如何在数据库表中记录这个商家、如何实现跟这个商家相关的业务逻辑，还要让商家的行为是定制化的，可以自发地组织营业。同时，也要服从平台制定的规则，共同维护商业秩序，比如定价策略、物流标准、服务水平，等等。
你可能会说，要达到这点其实很容易。实现一个开放平台，将所有的平台能力做成 API。让商家可以自己开发程序，去调用这些 API 来完成自己的服务。商家可以利用这些接口自定义自己的办公自动化软件。
事实上很多电商公司也确实是这样去做的，但我认为这样做没有抓住问题的核心。一方面是系统的开发、对接成本会难住很多中小型商家。但最重要的并不是研发成本，而是开放的 API 平台通常只能提供基础能力——比如说订单查询、商品创建、活动创建，等等。这些能力是电商平台已有能力的一种投影，超不过商家本身能在后台中配置和使用的范畴，基于这样的 API 架构出来的应用程序，可以节省商家的时间，但是不能称为进程。因为独立性不够，且不够智能。
所以真正的发展方向和目标是商业的智能化。这里有一个在游戏领域常见的设计模式，可以实现智能化，叫作代理人（Agent）模式。就是为每一个商家提供一个或者多个代理（Agent）程序。这些代理人像机器人一样，会帮助商家运营自己的网店、客服、物流体系，等等。
代理人知道什么时候应该做什么，比如说：
 帮商家预约物流、为新老用户提供不同的服务； 通过分析数据决定是否需要花钱做活动； 当品牌方有活动的时候，帮助商家联系； 当线上商店经营出现问题的时候，主动帮商家分析； ……  你可以把代理人理解成一个游戏的 AI，它们会根据一些配置选项自发地完成任务。而代理人的提供者，也就是程序员，只需要证明在某些方面，代理人比人更优秀即可。而在这些优秀的方面，就可以交给代理人处理。
这样，商家放弃了一部分的管理权限，也减轻了很大的负担，成了代理人决策中的某个节点——比如有时候需要邮件确认一些内容、有时候需要支付运营费用、有时候会遵循代理人的建议对商店进行装修等。
资源和权限 对于一个计算机上的操作系统而言，我们对进程使用了什么样的资源并不是非常的敏感。而对于一个商业操作系统来说，我们就需要设计严格的权限控制。因为权限从某种意义上就代表着收入，代表着金钱。
资源是一个宽泛的概念。广告位是资源，可以带来直接的流量。基于用户的历史行为，每个用户看到的广告位是不同的，这个也叫作“千人千面”，所以一个广告位可以卖给很多个代理人。站内信、用户召回的权限也可以看作资源。 有权利建立自己的会员体系，可以看作资源。数据分析的权限可以看作资源。如果将商业系统看作一个操作系统，资源就是所有在这个系统中流通的有价值的东西。
有同学可能会认为，一切资源都可以用数据描述，那么权限控制也应该会比较简单。比如说某一个推广位到底给哪个商家、到底推广多长时间……
其实并不是这样，虽然有很多权限可以用数据描述但是并不好控制。比如一个商品，“商家最低可以设置多少价格”就是一件非常不好判断的事情。商品有标品也有非标品，标品的价格好控制，非标品的价格缺少参照。如果平台方不希望花费太多精力在价格治理上，就要想办法让这些不守规则的商家无法盈利。比如说一旦发现恶性价格竞争，或者虚报价格骗钱的情况，需要及时给予商家打击和处罚。
和权限对应的就是资源。如果让商家以代理人的身份在操作系统中运行，那么这个代理人可以使用多少资源，就需要有一个访问权限控制列表（Access Control List,，ACL）。这里有一个核心的问题，在传统的 ACL 设计中，是基于权限的管控，而不是权限、内容的发现。而对于设计得优秀的代理人 （Agent），应该是订阅所有的可能性，知道如何获取、申请所有的权限，然后不断思考怎样做更好。对代理人而言，这不是一个权限申请的问题，而是一个最优化策略——思考如何盈利。
策略 商家、组织在操作系统上化身成为代理人，也就是进程。商业操作系统的调度不仅仅体现在给这些代理人足够的计算、存储资源，更重要的是为这些代理人的决策提供上下文以及资源。
就好像真实的人一样：听到、看到、触摸到，然后做决策。做决策需要策略，一个好的策略可能是赚钱的，而一个坏的策略可能是灾难性的。从人做决策到机器做决策，有一个中间的过程。一开始的目标可以设立在让机器做少量的决策，比如说，机器通过观察近期来到商店用户的行为，决定哪些商品出现在店铺的首页上。但是在做这个决策之前，机器需要先咨询人的意愿。这样就把人当成了决策节点，机器变成了工具人。这样做一方面为人节省了时间，一方面也避免了错误。
再比如说机器可以通过数据预估一个广告位的收益，通过用户集群的画像得知在某个广告位投放店铺广告是否划算。如果机器得到一个正向的结果，可能会通知商家来完成付费和签约。那么问题来了，商家是否可以放心将付费和签约都交给机器呢？
当然不可以。如果家里急着用钱，可能就无法完成这笔看上去是划算的交易。另外，如果有其他的商家也看上了这个广告位。可能就需要竞价排名，所以需要人和机器的混合决策。
上述的模式会长期存在，例如设置价格是一个复杂的模型——疫情来了，口罩的销量会上升。机器可以理解这个口罩销量上升的过程，但是机器很难在疫情刚刚开始、口罩销量还没有上升的时候就预判到这个趋势。如果逻辑是确定的，那机器可以帮人做到极致，但如果逻辑不确定呢？如果很多判断是预判，是基于复杂的现实世界产生的思考，那么这就不是机器擅长的领域了。
所以智能的目标并不是替代人，而是让人更像人、机器更像机器。
另外再和你聊一下我自己的观点，以自动驾驶为例。如果一个完全自动驾驶的汽车发生车祸，那么应该由汽车制造商、算法的提供方、自动驾驶设备的提供方、保险公司来共同来承担责任。类比下，如果策略可以售卖，那么提供策略的人就要承担相应的责任。比如说策略出现故障，导致营销券被大量套现，那提供策略方就需要承担相应的赔偿。
在可预见到的未来，策略也会成为一种可交易的资源。维护一个网上商店，从原材料到生产加工、渠道、物流体系、获客、销售环节，再到售后——以目前的技术水平，可以实现到一种半人工参与的状态。但这样也产生了很多非常现实的问题，比如说，既然开店变得如此容易，那资本为什么不自己开店。这样去培养合格、服务态度更好的店员不是更加容易吗？
这也是互联网让人深深担忧的原因之一。所有的东西被自动化之后，代表着一种时代的变迁，剩下不能够自动化的，都变成了“节点”。很多过程不需要人参与之后，人就变成了在某些机器无法完成工作的节点上不断重复劳动的工具——这也是近年来小朋友们经常说自己是“工具人”的原因了。
而且，我们程序员是在推动这样的潮流。因此你可以想象，未来对程序员的需求是很大的。一个普通的商店可能会雇佣一名程序员，花上半年匠心打造某个策略，收费标准可能会像现在的住房装修一样贵。这个策略成功之后还会进行微调，这就是后期的服务费用。完全做到配置化的策略，会因为不够差异化，无法永久盈利。最终在商业市场上竞争的，会是大量将人作为决策节点的 AI。
总结 商业是人类繁荣后的产物，电商是信息时代商业早期形式，未来的发展方向一定是像一个操作系统那样，让每个实体，都可以有自己的策略。用户可以写策略订餐，比如说我每天中午让 AI 帮助我挑选、并订一份午餐。商家写策略运营，比如运营网店。
至于商业操作系统到底是不是一个噱头？我觉得这是商业的发展方向。操作系统上的进程应该是策略，或者说是机器人。这样的未来也让我深深的焦虑过：它可能让人失去工作，让连接变得扁平，焦虑散播在加速——这些问题都需要解决，而解决需要时间、需要探索。</description>
    </item>
    
    <item>
      <title>40 (1)加餐 练习题详解（八）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/40-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E5%85%AB/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:40 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/40-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E5%85%AB/</guid>
      <description>今天我会带你把《模块八：虚拟化和其他》中涉及的课后练习题，逐一讲解，并给出每一讲练习题的解题思路和答案。
练习题详解 37 | 虚拟化技术介绍：VMware 和 Docker 的区别？ 【问题】自己尝试用 Docker 执行一个自己方向的 Web 程序：比如 Spring/Django/Express 等？
【解析】关于如何安装 Docker，你可以参考这篇文档。然后这里还有一个不错的 SpringBoot+MySQL+Redis 例子，你可以参考这篇内容。
其他方向可以参考上面例子中的 Compose.yml 去定义自己的环境。 一般开发环境喜欢把所有工具链用 Compose 放到一起，上线的环境数据库一般不会用 Docker 容器。 Docker-Compose 是一个专门用来定义多容器任务的工具，你可以在这里得到。
国内镜像可以用 Aliyun 的，具体你可以参考这篇文档。
（注：需要一个账号并且登录）
38 | 容器编排技术：如何利用 K8s 和 Docker Swarm 管理微服务？ 【问题】为什么会有多个容器共用一个 Pod 的需求？
【解析】Pod 内部的容器共用一个网络空间，可以通过 localhost 进行通信。另外多个容器，还可以共享一个存储空间。
比如一个 Web 服务容器，可以将日志、监控数据不断写入共享的磁盘空间，然后由日志服务、监控服务处理将日志上传。
再比如说一些跨语言的场景，比如一个 Java 服务接收到了视频文件传给一 个 OpenCV 容器进行处理。
以上这种设计模式，我们称为边车模式（Sidecar），边车模式将数个容器放入一个分组内（例如 K8s 的 Pod），让它们可以分配到相同的节点上。这样它们彼此间可以共用磁盘、网络等。
在边车模式中，有一类容器，被称为Ambassador Container，翻译过来是使节容器。对于一个主容器（Main Container）上的服务，可以通过 Ambassador Container 来连接外部服务。如下图所示：
我们在开发的时候经常会配置不同的环境。如果每个 Web 应用都要实现一套环境探测程序，比如判断是开发、测试还是线上环境，从而连接不同的 MySQL、Redis 等服务，那么每个项目都需要引入一个公用的库，或者实现一套逻辑。这样我们可以使用一个边车容器，专门提供数据库连接的服务。让连接服务可以自动探测环境，并且从远程读取全局配置，这样每个项目的开发者不需要再关心数据库有多少套环境、如何配置了。</description>
    </item>
    
    <item>
      <title>39 Linux 架构优秀在哪里</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/39-linux-%E6%9E%B6%E6%9E%84%E4%BC%98%E7%A7%80%E5%9C%A8%E5%93%AA%E9%87%8C/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:39 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/39-linux-%E6%9E%B6%E6%9E%84%E4%BC%98%E7%A7%80%E5%9C%A8%E5%93%AA%E9%87%8C/</guid>
      <description>我们在面试的时候经常会和面试官聊架构，多数同学可能会认为架构是一个玄学问题，讨论的是“玄而又玄”的知识——如同道德经般的开头“玄之又玄、众妙之门”。其实架构领域也有通用的语言，有自己独有的词汇。虽然架构师经常为了系统架构争得面红耳赤，但是即使发生争吵，大家也会遵守架构思想准则。
这些优秀的架构思想和准则，很大一部分来自早期的黑客们对程序语言编译器实现的探索、对操作系统实现方案的探索，以及对计算机网络应用发展的思考，并且一直沿用至今。比如现在的面向对象编程、函数式编程、子系统的拆分和组织，以及分层架构设计，依然沿用了早期的架构思路。
其中有一部分非常重要的思想，被著名的计算机科学家、Unix 代码贡献者 Douglas McIlroy 誉为 Unix 哲学，也是 Linux 遵循的设计思想。今天我就和你一起讨论下，这部分前人留下的思想精华，希望可以帮助到你日后的架构工作。
组合性设计（Composability） Unix 系设计的哲学，都在和单体设计（Monolithic Design）和中心化唱反调。作为社区产品，开发者来自全世界不同的地方，这就构成了一个巨大的开发团队，自然会反对中心化。
而一个巨大的开发团队的管理，一定不能是 Mono 的。举个例子，如果代码仓库是Mono的，这意味着所有的代码都存放在一个仓库里。如果要上线项目中的一个功能，那所有项目中的代码都要一起上线，只要一个小地方出了问题，就会影响到全局。在我们设计这个系统的时候，应该允许不同的程序模块通过不同的代码仓库发布。
再比如说，整体的系统架构应该是可以组合的。比如文件系统的设计，每个目录可以有不同的文件系统，我们可以随时替换文件系统、接入新的文件系统。比如接入一个网络的磁盘，或者接入一个内存文件系统。
与其所有的程序工具模块都由自己维护，不如将这项权利分发给需要的人，让更多的人参与进来。让更多的小团队去贡献代码，这样才可以把更多的工具体验做到极致。
这个思想在面向对象以及函数式编程的设计中，同样存在。比如在面向对象中，我们会尽量使用组合去替代继承。因为继承是一种 Mono 的设计，一旦发生继承关系，就意味着父类和子类之间的强耦合。而组合是一种更轻量级的复用。对于函数式编程，我们有 Monad 设计（单子），本质上是让事物（对象）和处理事物（计算）的函数之间可以进行组合，这样就可以最小粒度的复用函数。
同理，Unix 系操作系统用管道组合进程，也是在最小粒度的复用程序。
管道设计（Pipeline） 提到最小粒度的复用程序，就必然要提到管道（Pipeline）。Douglas McIlroy 在 Unix 的哲学中提到：一个应用的输出，应该是另一个应用的输入。这句话，其实道出了计算的本质。
计算其实就是将一个计算过程的输出给另一个计算过程作为输入。在构造流计算、管道运算、Monad 类型、泛型容器体系时——很大程度上，我们希望计算过程间拥有一定的相似性，比如泛型类型的统一。这样才可以把一个过程的输出给到另一个过程的输入。
重构和丢弃 在 Unix 设计当中有一个非常有趣的哲学。就是希望每个应用都只做一件事情，并且把这件事情做到极致。如果当一个应用变得过于复杂的时候，就去重构这个应用，或者重新写一个应用。而不是在原有的应用上增加功能。
上述逻辑和商业策略是否有相悖的地方？
关于这个问题，我觉得需要你自己进行思考，我不能给你答案，但欢迎把你的想法和答案写在留言区，我们一起交流。
设想一下，我们把微信的聊天工具、朋友圈、短视频、游戏都做成不同的应用，是不是会更好一些？
这是一个见仁见智的问题。但是目前来看，如果把短视频做成一个单独的应用，比如抖音，它在全球已经拥有 10 几亿的用户了；如果把游戏做成一个单独的应用，比如王者荣耀和 LoL，它们深受程序员们和广大上班族的喜爱。
还有，以我多年从事大型系统开发的经验来看，我宁愿重新做一些微服务，也不愿意去重构巨大的、复杂的系统。换句话说，我更乐意将新功能做到新系统里面，而不是在一个巨大的系统上不断地迭代和改进。这样不仅节省开发成本，还可以把事情做得更好。从这个角度看，我们进入微服务时代，是一个不可逆的过程。
另外多说一句，如果一定要在原有系统上增加功能，也应该多重构。重构和重写原有的系统有很多的好处，希望你不要有畏难情绪。优秀的团队，总是处在一个代码不断迭代的过程。一方面是因为业务在高速发展，旧代码往往承接不了新需求；另一方面，是因为程序员本身也在不断地追求更好的架构思路。
而重构旧代码，还经常可以看到业务逻辑中出问题的地方，看到潜在的隐患和风险，同时让程序员更加熟悉系统和业务逻辑。而且程序的复杂度，并不是随着需求量线性增长的。当需求量超过一定的临界值，复杂度增长会变快，类似一条指数曲线。因此，控制复杂度也是软件工程的一个核心问题。
写复杂的程序就是写错了 我们经常听到优秀的架构师说，**程序写复杂了，就是写错了。**在 Unix 哲学中，也提出过这样的说法：写一个程序的时候，先用几周时间去构造一个简单的版本，如果发现复杂了，就重写它。
确实实际情景也是如此。我们在写程序的时候，如果一开始没有用对工具、没有分对层、没有选对算法和数据结构、没有用对设计模式，那么写程序的时候，就很容易陷入大量的调试，还会出现很多 Bug。优秀的程序往往是思考的过程很长，调试的时间很短，能够迅速地在短时间内完成测试和上线。
所以当你发现一段代码，或者一段业务逻辑很消耗时间的时候，可能是你的思维方式出错了。想一想是不是少了必要的工具的封装，或者遗漏了什么中间环节。当然，也有可能是你的架构设计有问题，这就需要重新做架构了。
优先使用工具而不是“熟练” 关于优先使用工具这个哲学，我深有体会。
很多程序员在工作当中都忽略了去积累工具。比如说：
 你经常要重新配置自己的开发环境，也不肯做一个 Docker 的镜像； 你经常要重新部署自己的测试环境，而且有时候还会出现使用者太多而不够用的情况。即使这样的情况屡屡发生，也不肯做一下容器化的管理； Git 的代码提交之后，不会触发自动化测试，需要人工去点鼠标，甚至需要由资深的测试手动去测。  很多程序员都认为自己对某项技术足够熟练了。因此，宁愿长年累月投入更多的时间，也不愿意主动跳脱出固化思维。宁愿不断使用某一项技术，而不愿意将重复劳动转化成工具。比如写一个小型的 ORM 框架、缓存引擎、业务容器……总之，养成良好的习惯，可以让开发效率越来越高。</description>
    </item>
    
    <item>
      <title>38 容器编排技术：如何利用 K8s 和 Docker Swarm 管理微服务？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/38-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8-k8s-%E5%92%8C-docker-swarm-%E7%AE%A1%E7%90%86%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:38 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/38-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8-k8s-%E5%92%8C-docker-swarm-%E7%AE%A1%E7%90%86%E5%BE%AE%E6%9C%8D%E5%8A%A1/</guid>
      <description>作为操作系统的最后一个部分，我选择了三个主题：虚拟化、Linux 的架构哲学和商业操作系统的设计。我还是以探索式教学为主，帮助你建立和掌握虚拟化、程序架构、业务架构三个方向的基本概念。
操作系统的设计者和芯片的制造商们，早就感受到了虚拟化、容器化带来的变化，早早地支持了虚拟化，比如 Linux 的命名空间、Intel 的 VT-X 技术。这一讲作为虚拟化的一个延伸，我们一起讨论一下如何管理海量的容器，如何去构造一个高可用且具有扩展能力强的集群。
话不多说，让我们开始学习 Kubernetes 和 Docker Swarm 吧！
微服务 现在的面试官都喜欢问微服务相关的内容。微服务（Micro Service），指的是服务从逻辑上不可再分，是宏服务（Mono Service）的反义词。
比如初学者可能认为交易相关的服务都应该属于交易服务，但事实上，交易相关的服务可能会有交易相关的配置服务、交易数据的管理服务、交易履约的服务、订单算价的服务、流程编排服务、前端服务……
所以到底什么是不可再分呢？
其实没有不可再分，永远都可以继续拆分下去。只不过从逻辑上讲，系统的拆分，应该结合公司部门组织架构的调整，反映公司的战斗结构编排。但总的来说，互联网上的服务越来越复杂，几个简单的接口就可能形成一个服务，这些服务都要上线。如果用实体机来承载这些服务，开销太大。如果用虚拟机来承载这些服务倒是不错的选择，但是创建服务的速度太慢，不适合今天这个时代的研发者们。
试想你的系统因为服务太多，该如何管理？尤其是在大型的公司，员工通过自发组织架构评审就可以上线微服务——天长日久，微服务越来越多，可能会有几万个甚至几十万个。那么这么多的微服务，如何分布到数万台物理机上工作呢？
如下图所示，为了保证微服务之间是隔离的，且可以快速上线。每个微服务我们都使用一个单独的容器，而一组容器，又包含在一个虚拟机当中，具体的关系如下图所示：
上图中的微服务 C 因为只有一个实例存在单点风险，可能会引发单点故障。因此需要为微服务 C 增加副本，通常情况下，我们必须保证每个微服务至少有一个副本，这样才能保证可用性。
上述架构的核心就是要解决两个问题：
 减少 downtime（就是减少服务不可用的时间）； 支持扩容（随时都可以针对某个微服务增加容器）。  因此，我们需要容器编排技术。容器编排技术指自动化地对容器进行部署、管理、扩容、迁移、保证安全，以及针对网络负载进行优化等一系列技术的综合体。Kubernetes 和 Docker Swarm 都是出色的容器编排方案。
Kubernetes Kubernetes（K8s）是一个 Google 开源的容器编排方案。
节点（Master&amp;amp;Worker） K8s 通过集群管理容器。用户可以通过命令行、配置文件管理这个集群——从而编排容器；用户可以增加节点进行扩容，每个节点是一台物理机或者虚拟机。如下图所示，Kubernetes 提供了两种分布式的节点。Master 节点是集群的管理者，Worker 是工作节点，容器就在 Worker 上工作，一个 Worker 的内部可以有很多个容器。
在我们为一个微服务扩容的时候，首选并不是去增加 Worker 节点。可以增加这个微服务的容器数量，也可以提升每个容器占用的 CPU、内存存储资源。只有当整个集群的资源不够用的时候，才会考虑增加机器、添加节点。
Master 节点至少需要 2 个，但并不是越多越好。Master 节点主要是管理集群的状态数据，不需要很大的内存和存储空间。Worker 节点根据集群的整体负载决定，一些大型网站还有弹性扩容的手段，也可以通过 K8s 实现。
单点架构 接下来我们讨论一下 Worker 节点的架构。所有的 Worker 节点上必须安装 kubelet，它是节点的管理程序，负责在节点上管理容器。</description>
    </item>
    
    <item>
      <title>37 虚拟化技术介绍：VMware 和 Docker 的区别？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/37-%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8Dvmware-%E5%92%8C-docker-%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:37 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/37-%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8Dvmware-%E5%92%8C-docker-%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>都说今天是一个云时代，其实云的本质就是由基础架构提供商提供基础架构，应用开发商不再关心基础架构。我们可以类比人类刚刚发明电的时候，工厂需要自己建电站，而现在只需要电线和插座就可以使用电。
云时代让我们可以在分钟、甚至秒级时间内获得计算、存储、操作系统等资源。设备不再论个卖，而是以一个虚拟化单位售卖，比如：
 用户可以买走一个 64 核 CPU 机器中的 0.25 个 CPU； 也可以买走一个 128GB 内存机器中的 512M 内存； 还可以买走 1/2 台机器三个小时了执行时间。  实现以上这些，就需要虚拟化技术。这一讲我将以虚拟化技术中两种最具代表性的设计——VMware 和 Docker，为你解读解虚拟化技术。
什么是“虚拟化” 顾名思义，虚拟是相对于现实而言。虚拟化（Virutualization）通常是指构造真实的虚拟版本。不严谨地说，用软件模拟计算机，就是虚拟机；用数字模拟价值，就是货币；用存储空间模拟物理存储，就是虚拟磁盘。
VMware 和 Docker 是目前虚拟化技术中最具代表性的两种设计。VMware 为应用提供虚拟的计算机（虚拟机）；Docker 为应用提供虚拟的空间，被称作容器（Container），关于空间的含义，我们会在下文中详细讨论。
VMware在 1998 年诞生，通过 Hypervisor 的设计彻底改变了虚拟化技术。2005 年，VMware 不断壮大，在全球雇用了 1000 名员工，成为世界上最大的云基础架构提供商。
Docker则是 2013 年发布的一个社区产品，后来逐渐在程序员群体中流行了起来。大量程序员开始习惯使用 Docker，所以各大公司才决定使用它。在“38 讲”中我们要介绍的 Kubernates（K8s）容器编排系统，一开始也是将 Docker 作为主要容器。虽然业内不时有传出二者即将分道扬镳的消息，但是目前（2021 年）K8s 下的容器主要还是 Docker。
虚拟机的设计 接下来我们说说虚拟机设计。要虚拟一台计算机，要满足三个条件：隔离、仿真、高效。
隔离（Isolation）， 很好理解，指的是一台实体机上的所有的虚拟机实例不能互相影响。这也是早期设计虚拟机的一大动力，比如可以在一台实体机器上同时安装 Linux、Unix、Windows、MacOS 四种操作系统，那么一台实体机器就可以执行四种操作系统上的程序，这就节省了采购机器的开销。
仿真（Simulation）指的是用起来像一台真的机器那样，包括开机、关机，以及各种各样的硬件设备。在虚拟机上执行的操作系统认为自己就是在实体机上执行。仿真主要的贡献是**让进程可以无缝的迁移，**也就是让虚拟机中执行的进程，真实地感受到和在实体机上执行是一样的——这样程序从虚拟机到虚拟机、实体机到虚拟机的应用迁移，就不需要修改源代码。
高效（Efficient）的目标是减少虚拟机对 CPU、对硬件资源的占用。通常在虚拟机上执行指令需要额外负担10~15% 的执行成本，这个开销是相对较低的。因为应用通常很少将 CPU 真的用满，在容器中执行 CPU 指令开销会更低更接近在本地执行程序的速度。
为了实现上述的三种诉求，最直观的方案就是将虚拟机管理程序 Hypervisor 作为操作系统，在虚拟机管理程序（Hypervisor）之上再去构建更多的虚拟机。像这种管理虚拟机的架构，也称为 Type-1 虚拟机，如下图所示：</description>
    </item>
    
    <item>
      <title>36 公私钥体系和网络安全：什么是中间人攻击？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/36-%E5%85%AC%E7%A7%81%E9%92%A5%E4%BD%93%E7%B3%BB%E5%92%8C%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:36 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/36-%E5%85%AC%E7%A7%81%E9%92%A5%E4%BD%93%E7%B3%BB%E5%92%8C%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB/</guid>
      <description>设想你和一个朋友签订了合同，双方各执一份。如果朋友恶意篡改了合同内容，比如替换了合同中的条款，最后大家闹到法院、各执一词。这个时候就需要专业鉴定机构去帮你鉴定合同的真伪，朋友花越多心思去伪造合同，那么鉴定的成本就会越高。
在网络安全领域有个说法：没有办法杜绝网络犯罪，只能想办法提高网络犯罪的成本。我们的目标是提高作案的成本，并不是杜绝这种现象。今天我将带你初探网络安全的世界，学习网络安全中最重要的一个安全体系——公私钥体系。
合同的类比 我们尝试用签合同这种类比的方式来学习下面的内容。你可以先思考：如果选择“网签”，是不是能让伪造的成本更高呢？比如，是否能够降低存储的成本呢？
如果我们将两份合同都存到一个双方可以信任的第三方机构，只要这个机构不**监守自盗，**那么合同就是相对安全的。第三方机构保管后，合同的双方，都没有办法篡改这份合同的内容。而且双方随时可以去机构取出合同的原文，进行对比。
摘要算法 一家具有公信力的机构对内部需要严格管理。那么当合同存储下来之后，为了防止内部人员篡改合同，这家机构需要做什么呢？
很显然，这家机构需要证明合同没有被篡改。一种可行的做法，就是将合同原文和摘要一起存储。你可以把摘要算法理解成一个函数，原文经过一系列复杂的计算后，产生一个唯一的散列值。只要原文发生一丁点的变动，这个散列值就会发生变化。
目前比较常见的摘要算法有消息摘要算法（Message Digest Algorithm, MD5）和安全散列算法（Secure Hash Algorithm, SHA）。MD5 可以将任意长度的文章转化为一个 128 位的散列值。2004 年，MD5 被证实会发生碰撞，发生碰撞就是两篇原文产生了相同的摘要。这是非常危险的事情，这将允许黑客进行多种攻击手段，甚至可以伪造摘要。
因此在这之后，我们通常首选 SHA 算法。你不需要知道算法的准确运算过程，只需要知道 SHA 系的算法更加安全即可。在实现普通应用的时候可以使用 MD5，在计算对安全性要求极高的摘要时，就应该使用 SHA，比如订单、账号信息、证书等。
安全保存的困难 采用摘要算法，从理论上来说就杜绝了篡改合同的内容的做法。但在现实当中，公司也有可能出现内鬼。我们不能假定所有公司内部员工的行为就是安全的。因此可以考虑将合同和摘要分开存储，并且设置不同的权限。这样就确保在机构内部，没有任何一名员工同时拥有合同和摘要的权限。但是即便如此，依然留下了巨大的安全隐患。比如两名员工串通一气，或者员工利用安全漏洞，和外部的不法分子进行非法交易。
那么现在请你思考这个问题：如何确保公司内部的员工不会篡改合同呢？当然从理论上来说是做不到的。没有哪个系统能够杜绝内部人员接触敏感信息，除非敏感信息本身就不存在。因此，可以考虑将原文存到合同双方的手中，第三方机构中只存摘要。但是这又产生了一个新的问题，会不会有第三方机构的员工和某个用户串通一气修改合同呢？
至此，事情似乎陷入了僵局。由第三方平台保存合同，背后同样有很大的风险。而由用户自己保存合同，就是签约双方交换合同原文及摘要。但是这样的形式中，摘要本身是没有公信力的，无法证明合同和摘要确实是对方给的。
因此我们还要继续思考最终的解决方案：类比我们交换合同，在现实世界当中，还伴随着签名的交换。那么在计算机的世界中，签名是什么呢？
数字签名和证书 在计算机中，数字签名是一种很好的实现签名（模拟现实世界中签名）的方式。 所谓数字签名，就是对摘要进行加密形成的密文。
举个例子：现在 Alice 和 Bob 签合同。Alice 首先用 SHA 算法计算合同的摘要，然后用自己私钥将摘要加密，得到数字签名。Alice 将合同原文、签名，以及公钥三者都交给 Bob。如下图所示：
Bob 如果想证明合同是 Alice 的，就要用 Alice 的公钥，将签名解密得到摘要 X。然后，Bob 计算原文的 SHA 摘要 Y。Bob 对比 X 和 Y，如果 X = Y 则说明数据没有被篡改过。
在这样的一个过程当中，Bob 不能篡改 Alice 合同。因为篡改合同不但要改原文还要改摘要，而摘要被加密了，如果要重新计算摘要，就必须提供 Alice 的私钥。所谓私钥，就是 Alice 独有的密码。所谓公钥，就是 Alice 公布给他人使用的密码。</description>
    </item>
    
    <item>
      <title>36 (1)加餐 练习题详解（七）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/36-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%B8%83/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:35 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/36-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%B8%83/</guid>
      <description>今天我会带你把《模块七：网络和安全》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。
练习题详解 33 | 互联网协议群（TCP/IP）：多路复用是怎么回事？ 【问题】IPv4 和 IPv6 有什么区别？
【解析】 IPv4 和 IPv6 最大的区别是地址空间大小不同。
 IPv4 是用 32 位描述 IP 地址，理论极限约在 40 亿 IP 地址； IPv6 是用 128 位描述 IP 地址，IPv6 可以大到给每个人都分配 40 亿个 IP 地址，甚至更多的 IP 地址。  IPv4 地址不够用，因此需要划分子网。比如公司的几千台机器（计算机、手机），复用一个出口 IP 地址。子网内部，就用 192.168 开头的 IP 地址。
而 IPv6 地址够用，可以给全世界每台设备都分配一个地址，也可以给每一个组织（甚至家庭）都分配数以亿计的地址，目前不存在地址枯竭的问题。因此不需要像 IPv4 那样通过网络地址转换协议（NAT）去连接子网和外部网络。
因为地址数目的不同导致这两个协议在分配 IP 地址的时候行为也不一样。
IPv4 地址，空间小，如果没有一个中心的服务为所有设备分配地址，那么产生的冲突非常严重。所以IPv4 地址分配，是一种中心化的请求/返回的模式。客户端向服务端请求，分配地址。服务端，将计算好可以分配的地址返回给客户端。
而 IPv6 可以采用先计算，再申请的模式。由客户端自己随机抽取得出一个 IP 地址（能这样做是因为闲置的 IP 地址太多，随机抽取一个大概率没有设备使用），然后再向这个 IP 地址发送信息。如果没有得到返回，那么说明这个 IP 地址还没有设备使用。大体来说，这就是 IPv6 邻居发现协议，但上述内容只是其中该协议的一小部分。</description>
    </item>
    
    <item>
      <title>35 Linux 的 IO 模式：selectpollepoll 有什么区别？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/35-linux-%E7%9A%84-io-%E6%A8%A1%E5%BC%8Fselectpollepoll-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:34 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/35-linux-%E7%9A%84-io-%E6%A8%A1%E5%BC%8Fselectpollepoll-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</guid>
      <description>我们总是想方设法地提升系统的性能。操作系统层面不能给予处理业务逻辑太多帮助，但对于 I/O 性能，操作系统可以通过底层的优化，帮助应用做到极致。
这一讲我将和你一起讨论 I/O 模型。为了引发你更多的思考，我将同步/异步、阻塞/非阻塞等概念滞后讲解。我们先回到一个最基本的问题：如果有一台服务器，需要响应大量的请求，操作系统如何去架构以适应这样高并发的诉求。
说到架构，就离不开操作系统提供给应用程序的系统调用。我们今天要介绍的 select/poll/epoll 刚好是操作系统提供给应用的三类处理 I/O 的系统调用。这三类系统调用有非常强的代表性，这一讲我会围绕它们，以及处理并发和 I/O 多路复用，为你讲解操作系统的 I/O 模型。
从网卡到操作系统 为了弄清楚高并发网络场景是如何处理的，我们先来看一个最基本的内容：当数据到达网卡之后，操作系统会做哪些事情？
网络数据到达网卡之后，首先需要把数据拷贝到内存。拷贝到内存的工作往往不需要消耗 CPU 资源，而是通过 DMA 模块直接进行内存映射。之所以这样做，是因为网卡没有大量的内存空间，只能做简单的缓冲，所以必须赶紧将它们保存下来。
Linux 中用一个双向链表作为缓冲区，你可以观察下图中的 Buffer，看上去像一个有很多个凹槽的线性结构，每个凹槽（节点）可以存储一个封包，这个封包可以从网络层看（IP 封包），也可以从传输层看（TCP 封包）。操作系统不断地从 Buffer 中取出数据，数据通过一个协议栈，你可以把它理解成很多个协议的集合。协议栈中数据封包找到对应的协议程序处理完之后，就会形成 Socket 文件。
!
如果高并发的请求量级实在太大，有可能把 Buffer 占满，此时，操作系统就会拒绝服务。网络上有一种著名的攻击叫作拒绝服务攻击，就是利用的这个原理。操作系统拒绝服务，实际上是一种保护策略。通过拒绝服务，避免系统内部应用因为并发量太大而雪崩。
如上图所示，传入网卡的数据被我称为 Frames。一个 Frame 是数据链路层的传输单位（或封包）。现代的网卡通常使用 DMA 技术，将 Frame 写入缓冲区（Buffer），然后在触发 CPU 中断交给操作系统处理。操作系统从缓冲区中不断取出 Frame，通过协进栈（具体的协议）进行还原。
在 UNIX 系的操作系统中，一个 Socket 文件内部类似一个双向的管道。因此，非常适用于进程间通信。在网络当中，本质上并没有发生变化。网络中的 Socket 一端连接 Buffer， 一端连接应用——也就是进程。网卡的数据会进入 Buffer，Buffer 经过协议栈的处理形成 Socket 结构。通过这样的设计，进程读取 Socket 文件，可以从 Buffer 中对应节点读走数据。
对于 TCP 协议，Socket 文件可以用源端口、目标端口、源 IP、目标 IP 进行区别。不同的 Socket 文件，对应着 Buffer 中的不同节点。进程们读取数据的时候从 Buffer 中读取，写入数据的时候向 Buffer 中写入。通过这样一种结构，无论是读和写，进程都可以快速定位到自己对应的节点。</description>
    </item>
    
    <item>
      <title>34 UDP 协议：UDP 和 TCP 相比快在哪里？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/34-udp-%E5%8D%8F%E8%AE%AEudp-%E5%92%8C-tcp-%E7%9B%B8%E6%AF%94%E5%BF%AB%E5%9C%A8%E5%93%AA%E9%87%8C/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:33 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/34-udp-%E5%8D%8F%E8%AE%AEudp-%E5%92%8C-tcp-%E7%9B%B8%E6%AF%94%E5%BF%AB%E5%9C%A8%E5%93%AA%E9%87%8C/</guid>
      <description>TCP 和 UDP 是目前使用最广泛的两个传输层协议，同时也是面试考察的重点内容。今天我会初步带你认识这两个协议，一起探寻它们之间最大的区别。
在开始本讲的重点内容前，我们先来说说 RFC 文档（Request For Comments，请求评论），互联网的很多基础建设都是以 RFC 的形式文档化，它给用户提供了阅读和学习的权限。在给大家准备《计算机网络》专栏的时候，我也经常查阅 RFC 文档。
如果你查阅 TCP 和 UDP 的 RFC 文档，会发现一件非常有趣的事情。TCP 协议的 RFC 很长，我足足读了好几天才把它们全部弄明白。UDP 的 RFC 非常短，只有短短的两页，一个小时就能读明白。这让我不禁感叹，如果能穿越到当时那个年代，我就去发明 UDP 协议，因为实在是太简单了。但即使是这个简单协议，也同样主宰着计算机网络协议的半壁江山。
那么这一讲我们就以 TCP 和 UDP 的区别为引，带你了解这两个在工作中使用频率极高、极为重要的传输层协议。
可靠性 首先我们比较一下这两个协议在可靠性（Reliablility）上的区别。如果一个网络协议是可靠的，那么它能够保证数据被无损地传送到目的地。当应用的设计者选择一个具有可靠性的协议时，通常意味着这个应用不能容忍数据在传输过程中被损坏。
如果你是初学者，可能会认为所有的应用都需要可靠性。其实不然，比如说一个视频直播服务。如果在传输过程当中，视频图像发生了一定的损坏，用户看到的只是某几个像素、颜色不准确了，或者某几帧视频丢失了——这对用户来说是可以容忍的。但在观看视频的时候，用户最怕的不是实时数据发生一定的损坏，而是吞吐量得不到保证。比如视频看到一半卡住了，要等很久，或者丢失了一大段视频数据，导致错过精彩的内容。
TCP 协议，是一个支持可靠性的协议。UDP 协议，是一个不支持可靠性的协议。接下来我们讨论几个常见实现可靠性的手段。
校验和（Checksum） 首先我们来说说校验和。这是一种非常常见的可靠性检查手段。
尽管 UDP 不支持可靠性，但是像校验和（Checksum）这一类最基本的数据校验，它还是支持的。不支持可靠性，并不意味着完全放弃可靠性。TCP 和 UDP 都支持最基本的校验和算法。
下面我为你举例一种最简单的校验和算法：纵向冗余检查。伪代码如下：
byte c = 0;for(byte x in bytes) {c = c xor x;}xor是异或运算。上面的程序在计算字节数组 bytes 的校验和。c是最终的结果。你可以看到将所有bytes两两异或，最终的结果就是校验和。假设我们要传输 bytes，如果在传输过程中bytes发生了变化，校验和有很大概率也会跟着变化。当然也可能存在bytes发生变化，校验和没有变化的特例，不过校验和可以很大程度上帮助我们识别数据是否损坏了。
当要传输数据的时候，数据会被分片，我们把每个分片看作一个字节数组。然后在分片中，预留几个字节去存储校验和。校验和随着数据分片一起传输到目的地，目的地会用同样的算法再次计算校验和。如果二者校验和不一致，代表中途数据发生了损坏。
对于 TCP 和 UDP，都实现了校验和算法，但二者的区别是，TCP 如果发现校验核对不上，也就是数据损坏，会主动丢失这个封包并且重发。而 UDP 什么都不会处理，UDP 把处理的权利交给使用它的程序员。</description>
    </item>
    
    <item>
      <title>33 互联网协议群（TCPIP）：多路复用是怎么回事？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/33-%E4%BA%92%E8%81%94%E7%BD%91%E5%8D%8F%E8%AE%AE%E7%BE%A4tcpip%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:32 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/33-%E4%BA%92%E8%81%94%E7%BD%91%E5%8D%8F%E8%AE%AE%E7%BE%A4tcpip%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</guid>
      <description>这一讲我们开始学习《计算机网络》相关的知识。你可以把《计算机组成原理》《操作系统》和《计算机网络》看作补充计算机基础知识的 3 门必修课程。
 《计算机组成原理》讲述的是如何去理解程序和计算。 《操作系统》讲述的是如何去理解和架构应用程序。 《计算机网络》讲述的是如何去理解今天的互联网。  本模块讲解的计网知识，以科普为主，我会用通俗的比喻、简单明了的语言，帮你在短时间内构建起网络的基本概念。如果要深入学习计算机网络的原理、算法，可以关注我即将在拉勾教育推出的《计算机网络》专栏。
现在来看，“计算机网络”也许是一个过时的词汇，它讲的是怎么用计算实现通信。今天我们已经发展到了一个互联网、物联网的时代，社交网络、云的时代，再来看网络，意义已经发生转变。但这里面还是有很多经典的知识依旧在传承。比如说 TCP/IP 协议，问世后就逐渐成为占有统治地位的通信协议。虽然后面诞生出了许许多多的协议，但是我们仍然习惯性地把整个互联网的架构称为 TCP/IP 协议群，也叫作互联网协议群（Internet Protocol Suit）。
协议的分层 对于多数的应用和用户而言，使用互联网的一个基本要求就是数据可以无损地到达。用户通过应用进行网络通信，应用启动之后就变成了进程。因此，所有网络通信的本质目标就是进程间通信。世界上有很多进程需要通信，我们要找到一种通用的，每个进程都能认可和接受的通信方式，这就是协议。
应用层 从分层架构上看，应用工作在应用层（Application Layer）。应用的功能，都在应用层实现。所以应用层很好理解，说的就是应用本身。当两个应用需要通信的时候，应用（进程中的线程）就调用传输层进行通信。从架构上说，应用层只专注于为用户提供价值即可，没有必要思考数据如何传输。而且应用的开发商和传输库的提供方也不是一个团队。
传输层 为应用层提供网络支持的，就是传输层（Transport Layer）。
传输层控制协议（Transmission Control Protocol）是目前世界上应用最广泛的传输层协议。传输层为应用提供通信能力。比如浏览器想访问服务器，浏览器程序就会调用传输层程序；Web 服务接收浏览器的请求，Web 服务程序就会调用传输层程序接收数据。
考虑到应用需要传输的数据可能会非常大，直接传输不好控制。传输层需要将数据切块，即使一个分块传丢了、损坏了，可以重新发一个分块，而不用重新发送整体。在 TCP 协议中，我们把每个分块称为一个 TCP 段（TCP Segment）。
传输层负责帮助应用传输数据给应用。考虑到一台主机上可能有很多个应用在传输数据，而一台服务器上可能有很多个应用在接收数据。因此，我们需要一个编号将应用区分开。这个编号就是端口号。比如 80 端口通常是 Web 服务器在使用；22 端口通常是远程登录服务在使用。而桌面浏览器，可能每个打开的标签栏都是一个独立的进程，每个标签栏都会使用临时分配的端口号。TCP 封包（TCP Segment）上携带了端口号，接收方可以识别出封包发送给哪个应用。
网络层 接下来你要思考的问题是：传输层到底负不负责将数据从一个设备传输到另一个设备（主机到主机，Host To Host）。仔细思考这个过程，你会发现如果这样设计，传输层就会违反简单、高效、专注的设计原则。
我们从一个主机到另一个主机传输数据的网络环境是非常复杂的。中间会通过各种各样的线路，有形形色色的交叉路口——有各式各样的路径和节点需要选择。核心的设计原则是，我们不希望一层协议处理太多的问题。传输层作为应用间数据传输的媒介，服务好应用即可。对应用层而言，传输层帮助实现应用到应用的通信。而实际的传输功能交给传输层的下一层，也就是网络层（Internet Layer） 会更好一些。
IP 协议（Internet Protocol）是目前起到统治地位的网络层协议。IP 协议会将传输层的封包再次切分，得到 IP 封包。网络层负责实际将数据从一台主机传输到另一台主机（Host To Host），因此网络层需要区分主机的编号。
在互联网上，我们用 IP 地址给主机进行编号。例如 IPv4 协议，将地址总共分成了四段，每段是 8 位，加起来是 32 位。寻找地址的过程类似我们从国家、城市、省份一直找到区县。当然还有特例，比如有的城市是直辖市，有的省份是一个特别行政区。而且国与国体制还不同，像美国这样的国家，一个州其实可以相当于一个国家。
IP 协议里也有这个问题，类似行政区域划分，IP 协议中具体如何划分子网，需要配合子网掩码才能够明确。每一级网络都需要一个子网掩码，来定义网络子网的性质，相当于告诉物流公司到这一级网络该如何寻找目标地址，也就是寻址（Addressing）。关于更多子网掩码如何工作，及更多原理类的知识我会在拉勾教育的《计算机网络》专栏中和你分享。</description>
    </item>
    
    <item>
      <title>32 HDFS 介绍：分布式文件系统是怎么回事？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/32-hdfs-%E4%BB%8B%E7%BB%8D%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:31 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/32-hdfs-%E4%BB%8B%E7%BB%8D%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</guid>
      <description>前面我们学习了单机文件系统、数据库索引的设计，这一讲我们讨论大数据环境下的数据管理——分布式文件系统和分布式数据库。分布式文件系统通过计算机网络连接大量物理节点，将不同机器、不同磁盘、不同逻辑分区的数据组织在一起，提供海量的数据存储（一般是 Petabytes 级别，1PB = 1024TB）。分布式数据库则在分布式文件系统基础上，提供应对具体场景的海量数据解决方案。
说起大数据，就不得不提历史上在存储领域影响深远的两篇 Paper。
 Google File System BigTable：A Distributed Storage System for Structured Data  Google File System 是一个分布式文件系统，构成了今天大数据生态的底层存储，也是我们本讲主角 HDFS 的原型。HDFS（Hadoop Distributed File System）是 Google File System 的一个重要实现。
后者 BigTable 是一个分布式数据库。BigTable 本身是 Google 内部的项目，建立在 Google File System 之上，为 Google 的搜索引擎提供数据支撑。它是 2005 年公布的第一个版本，而且通过 Paper 公布了实现，在那个大数据还处于萌芽阶段的时代，BigTable 成为了启明星，今天我们常用的 HBase 还沿用着 BigTable 的设计。
因为两个重量级的 Paper 都是 Google 的产物，所以这一讲，我会结合搜索引擎的设计，带你走进分布式存储和数据库的世界。
存储所有的网页 作为搜索引擎最核心的一个能力，就是要存储所有的网页。目前世界上有 20 多亿个网站，每个网站还有大量的页面。搜索引擎不单单要存下这些页面，而且搜索引擎还需要存储这些网页的历史版本。
这里请你思考下，网站所有页面加起来有多大？举个例子，豆瓣所有页面加起来会有多大？如果把所有的变更都算上，比如一张页面经过 200 次迭代，就存 200 份，那么需要多少空间？Google 要把这些数据都存储下来，肯定是 PB 级别的数据。而且这个庞大的数据还需要提供给 Google 内部的分布式计算引擎等去计算，为网站打分、为用户生成索引，如果没有强大的存储能力是做不到的。</description>
    </item>
    
    <item>
      <title>32 (1)加餐 练习题详解（六）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/32-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E5%85%AD/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:30 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/32-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E5%85%AD/</guid>
      <description>今天我会带你把《模块六：文件系统》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。
练习题详解 29 | Linux下各个目录有什么作用？ 【问题】socket 文件都存在哪里？
【解析】socket 没有实体文件，只有 inode，所以 socket 是没有名字的文件。
你可以在 /proc/net/tcp 目录下找到所有的 TCP 连接，在 /proc/[pid]/fd 下也可以找到这些 socket 文件，都是数字代号，数字就是 socket 文件的 fd，如下图所示：
你也可以用lsof -i -a -p [pid查找某个进程的 socket 使用情况。下面结果和你用ls /proc/[pid]/fd看到的 fd 是一致的，如下图所示：
30 | 文件系统的底层实现：FAT、NTFS 和 Ext3 有什么区别？ 【问题】思考日志文件系统的数据冗余如何处理？
**【解析】**日志系统产生冗余几乎是必然发生的。 只要发生了修改、删除，肯定就会有数据冗余。日志系统通常不会主动压缩，但是日志文件系统通常会对磁盘碎片进行整理，这种机制和内存的管理非常相似。
首先我们把这个磁盘切割成很多等大的小块，大文件可能需要分配多个小块，多个小文件共用一个小块。而当很多文件被删除之后，磁盘中的小块会产生碎片，文件系统会进行碎片整理，比如把多个有很多碎片的区域拷贝到一起，使存储空间更加紧凑。
回到正题，最终的答案就是不压缩、不处理冗余，空间换时间，提升写入速度。
31 | 数据库文件系统实例：MySQL 中 B 树和 B+ 树有什么区别？ 【问题】按照应该尽量减少磁盘读写操作的原则，是不是哈希表的索引更有优势？
【解析】哈希表是一种稀疏的离散结构，通常使用键查找值。给定一个键，哈希表会通过数学计算的方式找到值的内存地址。因此，从这个角度去分析，哈希表的查询速度非常快。单独查找某一个数据速度超过了 B+ 树（比如根据姓名查找用户）。因此，包括 MySQL 在内的很多数据库，在支持 B+ 树索引的同时，也支持哈希表索引。
这两种索引最大的区别是：B+ 树是对范围的划分，其中的数据还保持着连续性；而哈希表是一种离散的查询结构，数据已经分散到不同的空间中去了。所以当数据要进行范围查找时，比如查找某个区间内的订单，或者进行聚合运算，这个时候哈希表的性能就非常低了。
哈希表有一个设计约束，如果我们用了 m 个桶（Bucket，比如链表）去存储哈希表中的数据，再假设总共需要存储 N 个数据。那么平均查询次数 k = N/m。为了让 k 不会太大，当数据增长到一定规模时，哈希表需要增加桶的数目，这个时候就需要重新计算所有节点的哈希值（重新分配所有节点属于哪个桶）。</description>
    </item>
    
    <item>
      <title>30 文件系统的底层实现：FAT、NTFS 和 Ext3 有什么区别？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/30-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0fatntfs-%E5%92%8C-ext3-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:29 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/30-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0fatntfs-%E5%92%8C-ext3-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</guid>
      <description>这一讲给你带来的面试题是： FAT、NTFS 和 Ext3 文件系统有什么区别？
10 年前 FAT 文件系统还是常见的格式，而现在 Windows 上主要是 NTFS，Linux 上主要是 Ext3、Ext4 文件系统。关于这块知识，一般资料只会从支持的磁盘大小、数据保护、文件名等各种维度帮你比较，但是最本质的内容却被一笔带过。它们最大的区别是文件系统的实现不同，具体怎么不同？文件系统又有哪些实现？这一讲，我将带你一起来探索和学习这部分知识。
硬盘分块 在了解文件系统实现之前，我们先来了解下操作系统如何使用硬盘。
使用硬盘和使用内存有一个很大的区别，内存可以支持到字节级别的随机存取，而这种情况在硬盘中通常是不支持的。过去的机械硬盘内部是一个柱状结构，有扇区、柱面等。读取硬盘数据要转动物理的磁头，每转动一次磁头时间开销都很大，因此一次只读取一两个字节的数据，非常不划算。
随着 SSD 的出现，机械硬盘开始逐渐消失（还没有完全结束），现在的固态硬盘内部是类似内存的随机存取结构。但是硬盘的读写速度还是远远不及内存。而连续读多个字节的速度，还远不如一次读一个硬盘块的速度。
因此，为了提高性能，通常会将物理存储（硬盘）划分成一个个小块，比如每个 4KB。这样做也可以让硬盘的使用看起来非常整齐，方便分配和回收空间。况且，数据从磁盘到内存，需要通过电子设备，比如 DMA、总线等，如果一个字节一个字节读取，速度较慢的硬盘就太耗费时间了。过去的机械硬盘的速度可以比内存慢百万倍，现在的固态硬盘，也会慢几十到几百倍。即便是最新的 NvMe 接口的硬盘，和内存相比速度仍然有很大的差距。因此，一次读/写一个块（Block）才是可行的方案。
如上图所示，操作系统会将磁盘分成很多相等大小的块。这样做还有一个好处就是如果你知道块的序号，就可以准确地计算出块的物理位置。
文件的描述 我们将硬盘分块后，如何利用上面的硬盘存储文件，就是文件系统（File System）要负责的事情了。当然目录也是一种文件，因此我们先讨论文件如何读写。不同的文件系统利用方式不同，今天会重点讨论 3 种文件系统：
 早期的 FAT 格式 基于 inode 的传统文件系统 日志文件系统（如 NTFS, EXT2、3、4）  FAT 表 早期人们找到了一种方案就是文件分配表（File Allocate Table，FAT）。如下图所示：
一个文件，最基本的就是要描述文件在硬盘中到底对应了哪些块。FAT 表通过一种类似链表的结构描述了文件对应的块。上图中：文件 1 从位置 5 开始，这就代表文件 1 在硬盘上的第 1 个块的序号是 5 的块 。然后位置 5 的值是 2，代表文件 1 的下一个块的是序号 2 的块。顺着这条链路，我们可以找到 5 → 2 → 9 → 14 → 15 → -1。-1 代表结束，所以文件 1 的块是：5,2,9,14,15。同理，文件 2 的块是 3,8,12。</description>
    </item>
    
    <item>
      <title>29 Linux 下的各个目录有什么作用？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/29-linux-%E4%B8%8B%E7%9A%84%E5%90%84%E4%B8%AA%E7%9B%AE%E5%BD%95%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:28 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/29-linux-%E4%B8%8B%E7%9A%84%E5%90%84%E4%B8%AA%E7%9B%AE%E5%BD%95%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8/</guid>
      <description>今天我们开始学习模块六：文件系统。学习文件系统的意义在于文件系统有很多设计思路可以迁移到实际的工作场景中，比如：
 MySQL 的 binlog 和 Redis AOF 都像极了日志文件系统的设计； B Tree 用于加速磁盘数据访问的设计，对于索引设计也有通用的意义。  特别是近年来分布式系统的普及，学习分布式文件系统，也是理解分布式架构最核心的一个环节。其实文件系统最精彩的还是虚拟文件系统的设计，比如 Linux 可以支持每个目录用不同的文件系统。这些文件看上去是一个个目录和文件，实际上可能是磁盘、内存、网络文件系统、远程磁盘、网卡、随机数产生器、输入输出设备等，这样虚拟文件系统就成了整合一切设备资源的平台。大量的操作都可以抽象成对文件的操作，程序的书写就会完整而统一，且扩展性强。
这一讲，我会从 Linux 的目录结构和用途开始，带你认识 Linux 的文件系统。Linux 所有的文件都建立在虚拟文件系统（Virtual File System ，VFS）之上，如下图所示：
当你访问一个目录或者文件，虽然用的是 Linux 标准的文件 API 对文件进行操作，但实际操作的可能是磁盘、内存、网络或者数据库等。因此，Linux 上不同的目录可能是不同的磁盘，不同的文件可能是不同的设备。
分区结构 在 Linux 中，/是根目录。之前我们在“08 讲”提到过，每个目录可以是不同的文件系统（不同的磁盘或者设备）。你可能会问我，/是对应一个磁盘还是多个磁盘呢？在/创建目录的时候，目录属于哪个磁盘呢？
你可以用df -h查看上面两个问题的答案，在上图中我的/挂载到了/dev/sda5上。如果你想要看到更多信息，可以使用df -T，如下图所示：
/的文件系统类型是ext4。这是一种常用的日志文件系统。关于日志文件系统，我会在“**30 讲”**为你介绍。然后你可能还会有一个疑问，/dev/sda5究竟是一块磁盘还是别的什么？这个时候你可以用fdisk -l查看，结果如下图：
你可以看到我的 Linux 虚拟机上，有一块 30G 的硬盘（当然是虚拟的）。然后这块硬盘下有 3 个设备（Device）：/dev/sda1, /dev/sda2 和 /dev/sda5。在 Linux 中，数字 1~4 结尾的是主分区，通常一块磁盘最多只能有 4 个主分区用于系统启动。主分区之下，还可以再分成若干个逻辑分区，4 以上的数字都是逻辑分区。因此/dev/sda2和/dev/sda5是主分区包含逻辑分区的关系。
挂载 分区结构最终需要最终挂载到目录上。上面例子中/dev/sda5分区被挂载到了/下。 这样在/创建的文件都属于这个/dev/sda5分区。 另外，/dev/sda5采用ext4文件系统。可见不同的目录可以采用不同的文件系统。
将一个文件系统映射到某个目录的过程叫作挂载（Mount）。当然这里的文件系统可以是某个分区、某个 USB 设备，也可以是某个读卡器等。你可以用mount -l查看已经挂载的文件系统。
上图中的sysfs``proc``devtmpfs``tmpfs``ext4都是不同的文件系统，下面我们来说说它们的作用。
 sysfs让用户通过文件访问和设置设备驱动信息。 proc是一个虚拟文件系统，让用户可以通过文件访问内核中的进程信息。 devtmpfs在内存中创造设备文件节点。 tmpfs用内存模拟磁盘文件。 ext4是一个通常意义上我们认为的文件系统，也是管理磁盘上文件用的系统。  你可以看到挂载记录中不仅有文件系统类型，挂载的目录（on 后面部分），还有读写的权限等。你也可以用mount指令挂载一个文件系统到某个目录，比如说：</description>
    </item>
    
    <item>
      <title>28 内存回收下篇：三色标记-清除算法是怎么回事？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/28-%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E4%B8%8B%E7%AF%87%E4%B8%89%E8%89%B2%E6%A0%87%E8%AE%B0-%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:27 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/28-%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E4%B8%8B%E7%AF%87%E4%B8%89%E8%89%B2%E6%A0%87%E8%AE%B0-%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</guid>
      <description>今天我们继续讨论内存回收问题。在上一讲，我们发现双色标记-清除算法有一个明显的问题，如下图所示：
你可以把 GC 的过程看作标记、清除及程序不断对内存进行修改的过程，分成 3 种任务：
 标记程序（Mark） 清除程序（Sweep） 变更程序（Mutation）  标记（Mark）就是找到不用的内存，清除（Sweep）就是回收不用的资源，而修改（Muation）则是指用户程序对内存进行了修改。通常情况下，在 GC 的设计中，上述 3 种程序不允许并行执行（Simultaneously）。对于 Mark、Sweep、Mutation 来说内存是共享的。如果并行执行相当于需要同时处理大量竞争条件的手段，这会增加非常多的开销。当然你可以开多个线程去 Mark、Mutation 或者 Sweep，但前提是每个过程都是独立的。
因为 Mark 和 Sweep 的过程都是 GC 管理，而 Mutation 是在执行应用程序，在实时性要求高的情况下可以允许一边 Mark，一边 Sweep 的情况； 优秀的算法设计也可能会支持一边 Mark、一边 Mutation 的情况。这种算法通常使用了 Read On Write 技术，本质就是先把内存拷贝一份去 Mark/Sweep，让 Mutation 完全和 Mark 隔离。
上图中 GC 开始后，拷贝了一份内存的原本，进行 Mark 和 Sweep，整理好内存之后，再将原本中所有的 Mutation 合并进新的内存。 这种算法设计起来会非常复杂，但是可以保证实时性 GC。
上图的这种 GC 设计比较少见，通常 GC 都会发生 STL（Stop The World）问题，Mark/Sweep/Mutation 只能够交替执行。也就是说， 一种程序执行的时候，另一种程序必须停止。
对于双色标记-清除算法，如果 Mark 和 Sweep 之间存在 Mutation，那么 Mutation 的伤害是比较大的。比如 Mutation 新增了一个白色的对象，这个白色的对象就可能会在 Sweep 启动后被清除。当然也可以考虑新增黑色的对象，这样对象就不会在 Sweep 启动时被回收。但是会发生下面这个问题，如下图所示：</description>
    </item>
    
    <item>
      <title>28 (1)加餐 练习题详解（五）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/28-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%BA%94/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:26 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/28-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%BA%94/</guid>
      <description>今天我会带你把《模块五：内存管理》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。
练习题详解 24 | 虚拟内存 ：一个程序最多能使用多少内存？ 【问题】可不可以利用哈希表直接将页编号映射到 Frame 编号？
【解析】按照普通页表的设计，如果页大小是 4K，1G 空间内存需要 262144 个页表条目，如果每个条目用 4 个字节来存储，就需要 1M 的空间。那么创建 1T 的虚拟内存，就需要 1G 的空间。这意味着操作系统需要在启动时，就把这块需要的内存空间预留出来。
正因为我们设计的虚拟内存往往大于实际的内存，因此在历史上出现过各种各样节省页表空间的方案，其中就有用 HashTable 存储页表的设计。HashTable 是一种将键（Key）映射到值（Value）的数据结构。在页表的例子中，键是页编号，值是 Frame 编号。 你可以把这个 HashTable 看作存储了很多 &amp;lt;PageId, FrameId&amp;gt; 键值对的数据结构。
为了方便你理解下面的内容，我绘制了一张图。下图使用了一个有 1024 个条目的 HashTable。当查找页面 50000 的时候，先通过哈希函数 h 计算出 50000 对应的 HashTable 条目是 24。HashTable 的每个条目都是一个链表，链表的每个节点是一个 PageId 和 FrameId 的组合。接下来，算法会遍历条目 24 上的链表，然后找到 Page = 50000 的节点。取出 Frame 编号为 1232。
通常虚拟内存会有非常多的页，但是只有少数的页会被使用到。这种情况下，用传统的页表，会导致过多的空间被预分配。而基于 HashTable 的设计则不同，可以先分配少量的项，比如在上图中，先只分配了 1024 个项。每次查找一个页表编号发现不存在的情况，再去对应位置的链表中添加一个具体的键-值对。 这样就大大节省了内存。
当然节省空间也是有代价的，这会直接导致性能下降，因为比起传统页表我们可以直接通过页的编号知道页表条目，基于 HashTable 的做法需要先进行一次 Hash 函数的计算，然后再遍历一次链表。 最后，HashTable 的时间复杂度可以看作 O(k)，k 为 HashTable 表中总共的 &amp;lt;k,v&amp;gt; 数量除以哈希表的条目数。当 k 较小的时候 HashTable 的时间复杂度趋向于 O(1)。</description>
    </item>
    
    <item>
      <title>27 内存回收上篇：如何解决内存的循环引用问题？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/27-%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E4%B8%8A%E7%AF%87%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E7%9A%84%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:25 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/27-%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E4%B8%8A%E7%AF%87%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E7%9A%84%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/</guid>
      <description>内存泄漏一直是很多大型系统故障的根源，也是一个面试热点。那么在编程语言层面已经提供了内存回收机制，为什么还会产生内存泄漏呢？
这是因为应用的内存管理一直处于一个和应用程序执行并发的状态，如果应用程序申请内存的速度，超过内存回收的速度，内存就会被用满。当内存用满，操作系统就开始需要频繁地切换页面，进行频繁地磁盘读写。所以我们观察到的系统性能下降，往往是一种突然的崩溃，因为一旦内存被占满，系统性能就开始雪崩式下降。
特别是有时候程序员不懂内存回收的原理，错误地使用内存回收器，导致部分对象没有被回收。而在高并发场景下，每次并发都产生一点不能回收的内存，不用太长时间内存就满了，这就是泄漏通常的成因。
这一块知识点关联着很多常见的面试题，比如。
 这一讲关联的题目：如何解决循环引用问题？ 下节课关联的题目：三色标记-清除算法的工作原理？生代算法等。 还有一些题目会考察你对内存回收器整体的理解，比如如何在吞吐量、足迹和暂停时间之间选择？  接下来，我会用 27 和 28 两讲和你探讨内存回收技术，把这些问题一网打尽。
什么是 GC 通常意义上我们说的垃圾回收器（Garbage Collector，GC），和多数同学的理解会有出入。你可能认为 GC 是做内存回收用的模块，而事实上程序语言提供的 GC 往往是应用的实际内存管理者。刚刚入门咱们就遇到了一个容易出现理解偏差的问题，所以 GC 是值得花时间细学的。
如上图所示，一方面 GC 要承接操作系统虚拟内存的架构，另一方面 GC 还要为应用提供内存管理。GC 有一个含义，就是 Garbage Collection 内存回收的具体动作。无论是名词的回收器，还是动词的回收行为，在下文中我都称作 GC。
下面我们具体来看一下 GC 都需要承担哪些“工作”，这里我总结为以下 4 种。
 GC 要和操作系统进行交互，负责申请内存，并把不用的内存还给操作系统（释放内存）。 应用会向 GC 申请内存。 GC 要承担我们通常意义上说的垃圾回收能力，标记不用的对象，并回收他们。 GC 还需要针对应用特性进行动态的优化。  所以现在程序语言实现的 GC 模块通常是实际负责应用内存管理的模块。在程序语言实现 GC 的时候，会关注下面这几个指标。
 吞吐量（Throughput）：执行程序（不包括 GC 执行的时间）和总是间的占比。注意这个吞吐量和通常意义上应用去处理作业的吞吐量是不一样的，这是从 GC 的角度去看应用。只要不在 GC，就认为是吞吐量的一部分。 足迹（FootPrint）： 一个程序使用了多少硬件的资源，也称作程序在硬件上的足迹。GC 里面说的足迹，通常就是应用对内存的占用情况。比如说应用运行需要 2G 内存，但是好的 GC 算法能够帮助我们减少 500MB 的内存使用，满足足迹这个指标。 暂停时间（Pause Time）： GC 执行的时候，通常需要停下应用（避免同步问题），这称为 Stop The World，或者暂停。不同应用对某次内存回收可以暂停的时间需求是不同的，比如说一个游戏应用，暂停了几毫秒用户都可能有很大意见；而看网页的用户，稍微慢了几毫秒是没有感觉的。  GC 目标的思考 如果单纯从让 GC 尽快把工作做完的角度来讲，其实是提升吞吐量。比如利用好多核优势就是一种最直观的方法。</description>
    </item>
    
    <item>
      <title>26 缓存置换算法： LRU 用什么数据结构实现更合理？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/26-%E7%BC%93%E5%AD%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95-lru-%E7%94%A8%E4%BB%80%E4%B9%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E7%8E%B0%E6%9B%B4%E5%90%88%E7%90%86/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:24 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/26-%E7%BC%93%E5%AD%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95-lru-%E7%94%A8%E4%BB%80%E4%B9%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E7%8E%B0%E6%9B%B4%E5%90%88%E7%90%86/</guid>
      <description>这一讲给你带来的面试题目是：LRU 用什么数据结构实现更合理？
LRU（最近最少使用），是一种缓存置换算法。缓存是用来存储常用的数据，加速常用数据访问的数据结构。有软件实现，比如数据库的缓存；也有硬件实现，比如我们上一讲学的 TLB。缓存设计中有一个重要的环节：当缓存满了，新的缓存条目要写入时，哪个旧条目被置换出去呢？
这就需要用到缓存置换算法（Cache Replacement Algorithm）。缓存置换应用场景非常广，比如发生缺页中断后，操作系统需要将磁盘的页导入内存，那么已经在内存中的页就需要置换出去。CDN 服务器为了提高访问速度，需要决定哪些 Web 资源在内存中，哪些在磁盘上。CPU 缓存每次写入一个条目，也就相当于一个旧的条目被覆盖。数据库要决定哪些数据在内存中，应用开发要决定哪些数据在 Redis 中，而空间是有限的，这些都关联着缓存的置换。
今天我们就以 LRU 用什么数据结构实现更合理，这道缓存设计题目为引，为你讲解缓存设计中（包括置换算法在内）的一些通用的思考方法。
理想状态 设计缓存置换算法的期望是：每次将未来使用频率最低的数据置换出去。假设只要我们知道未来的所有指令，就可以计算出哪些内存地址在未来使用频率高，哪些内存地址在未来使用频率低。这样，我们总是可以开发出理论上最高效的缓存置换算法。
再复习下缓存的基本概念，在缓存中找到数据叫作一次命中（Hit），没有找到叫作穿透（Miss）。假设穿透的概率为 M，缓存的访问时间（通常叫作延迟）是 L，穿透的代价（访问到原始数据，比如 Redis 穿透，访问到 DB）也就是穿透后获取数据的平均时间是 T，那么 M*T+L 可以看作是接近缓存的平均响应时间。L 通常是不变的，这个和我们使用了什么缓存相关。这样，如果我们知道未来访问数据的顺序，就可以把 M 降到最低，让缓存平均响应时间降到最低。
当然这只是美好的愿望，在实际工作中我们还不可能预知未来。
随机/FIFO/FILO 接下来我要和你讨论的 3 种策略，是对理想状态的一种悲观表达，或者说不好的设计。
比如说随机置换，一个新条目被写入，随机置换出去一个旧条目。这种设计，具有非常朴素的公平，但是性能会很差（穿透概率高），因为可能置换出去未来非常需要的数据。
再比如先进先出（First In First Out）。设计得不好的电商首页，每次把离现在时间最久的产品下线，让新产品有机会展示，而忽略销量、热度、好评等因素。这也是一种朴素的公平，但是和我们设计缓存算法的初衷——预估未来使用频率更高的数据保留在缓存中，相去甚远。所以，FIFO 的结构也是一种悲观的设计。
FIFO 的结构使用一个链表就能实现，如下图所示：
为了方便你理解本讲后面的内容，我在这里先做一个知识铺垫供你参考。上图中，新元素从链表头部插入，旧元素从链表尾部离开。 这样就构成了一个队列（Queue），队列是一个经典的 FIFO 模型。
还有一种策略是先进后出（First In Last Out）。但是这种策略和 FIFO、随机一样，没有太强的实际意义。因为先进来的元素、后进来的元素，还是随机的某个元素，和我们期望的未来使用频率，没有任何本质联系。
同样 FILO 的策略也可以用一个链表实现，如下图所示：
新元素从链表头部插入链表，旧元素从链表头部离开链表，就构成了一个栈（Stack），栈是一种天然的 FILO 数据结构。这里仅供参考了，我们暂时还不会用到这个方法。
当然我们不可能知道未来，但是可以考虑基于历史推测未来。经过前面的一番分析，接下来我们开始讨论一些更有价值的置换策略。
最近未使用（NRU） 一种非常简单、有效的缓存实现就是优先把最近没有使用的数据置换出去（Not Recently Used)。从概率上说，最近没有使用的数据，未来使用的概率会比最近经常使用的数据低。缓存设计本身也是基于概率的，一种方案有没有价值必须经过实践验证——在内存缺页中断后，如果采用 NRU 置换页面，可以提高后续使用内存的命中率，这是实践得到的结论。
而且 NRU 实现起来比较简单，下图是我们在“24 讲”中提到的页表条目设计。
在页表中有一个访问位，代表页表有被读取过。还有一个脏位，代表页表被写入过。无论是读还是写，我们都可以认为是访问过。 为了提升效率，一旦页表被使用，可以用硬件将读位置 1，然后再设置一个定时器，比如 100ms 后，再将读位清 0。当有内存写入时，就将写位置 1。过一段时间将有内存写入的页回写到磁盘时，再将写位清 0。这样读写位在读写后都会置为 1，过段时间，也都会回到 0。</description>
    </item>
    
    <item>
      <title>25 内存管理单元： 什么情况下使用大内存分页？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/25-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%8D%95%E5%85%83-%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E4%BD%BF%E7%94%A8%E5%A4%A7%E5%86%85%E5%AD%98%E5%88%86%E9%A1%B5/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:22 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/25-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%8D%95%E5%85%83-%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E4%BD%BF%E7%94%A8%E5%A4%A7%E5%86%85%E5%AD%98%E5%88%86%E9%A1%B5/</guid>
      <description>今天我们的学习目标是：了解如何通过内存，提升你的程序性能。这一讲我带来了一道和内存优化相关的面试题：什么情况下使用大内存分页？
这道题目属于一个实用技巧，可以作为你积累高并发处理技能的一个小小的组成部分。要理解和解决这个问题，我们还需要在上一讲的基础上，继续挖掘虚拟内存和内存管理单元更底层的工作原理，以及了解转置检测缓冲区（TLB）的作用。
那么接下来就请你带着这个优化问题，和我一起开始学习今天的内容。
内存管理单元 上一讲我们学习了虚拟地址到物理地址的转换过程。如下图所示：
你可以把虚拟地址看成由页号和偏移量组成，把物理地址看成由 Frame Number 和偏移量组成。在 CPU 中有一个完成虚拟地址到物理地址转换的小型设备，叫作内存管理单元（Memory Management Unit(MMU）。
在程序执行的时候，指令中的地址都是虚拟地址，虚拟地址会通过 MMU，MMU 会查询页表，计算出对应的 Frame Number，然后偏移量不变，组装成真实地址。然后 MMU 通过地址总线直接去访问内存。所以 MMU 承担了虚拟地址到物理地址的转换以及 CPU 对内存的操作这两件事情。
如下图所示，从结构上 MMU 在 CPU 内部，并且直接和地址总线连接。因此 MMU 承担了 CPU 和内存之间的代理。对操作系统而言，MMU 是一类设备，有多种型号，就好比显卡有很多型号一样。操作系统需要理解这些型号，会使用 MMU。
TLB 和 MMU 的性能问题 上面的过程，会产生一个问题：指令的执行速度非常快，而 MMU 还需要从内存中查询页表。最快的内存查询页需要从 CPU 的缓存中读取，假设缓存有 95% 的命中率，比如读取到 L2 缓存，那么每次操作也需要几个 CPU 周期。你可以回顾一下 CPU 的指令周期，如下图所示，有 fetch/decode/execute 和 store。
在 fetch、execute 和 store 这 3 个环节中都有可能发生内存操作，因此内存操作最好能在非常短的时间内完成，尤其是 Page Number 到 Frame Number 的映射，我们希望尽快可以完成，最好不到 0.2 个 CPU 周期，这样就不会因为地址换算而增加指令的 CPU 周期。</description>
    </item>
    
    <item>
      <title>24 虚拟内存 ：一个程序最多能使用多少内存？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/24-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98-%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E6%9C%80%E5%A4%9A%E8%83%BD%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%B0%91%E5%86%85%E5%AD%98/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:21 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/24-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98-%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E6%9C%80%E5%A4%9A%E8%83%BD%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%B0%91%E5%86%85%E5%AD%98/</guid>
      <description>这个模块我们开始学习操作系统的内存管理，接下来我会先用 3 节课讲解操作系统对内存管理的原理。因为内存资源总是稀缺的，即便在拥有百 G 内存的机器上，我们都可以轻易把内存填满。为了解决这个问题，就需要用到虚拟化技术。
因此，本模块前面 3 讲将围绕虚拟化技术展开：第 24 讲介绍设计思想；第 25 讲介绍优化手段；第 26 讲挑选了对你工作比较有帮助的缓存置换算法深入讲解。
后面的第 27、28 讲将围绕内存回收（GC）讲解，GC 是面试的高频重点知识，同时也是程序员日常开发需要理解的部分。学习 GC 有助于你优化你开发应用的性能，特别是遇到内存不够用不会束手无策。
今天我们先学习内存的虚拟化技术。
内存是稀缺的，随着应用使用内存也在膨胀。当程序越来复杂，进程对内存的需求会越来越大。从安全角度考虑，进程间使用内存需要隔离。另外还有一些特殊场景，比如说，我在“模块四加餐”中提到的内存一致性问题，存在不希望 CPU 进行缓存的场景。 这个时候，有一个虚拟化层承接各种各样的诉求，统一进行处理，就会有很大的优势。
还有一个大家普遍关心的问题，也是这节课我给大家带来的面试题：一个程序最多能使用多少内存?
要回答这个问题，就需要对内存的虚拟化有一定的认识。接下来就请你带着问题，和我一起学习“内存的虚拟化技术”。
为什么内存不够用？ 要理解一个技术，就必须理解它为何而存在。总体来说，虚拟化技术是为了解决内存不够用的问题，那么内存为何不够用呢？
主要是因为程序越来越复杂。比如说我现在给你录音的机器上就有 200 个进程，目前内存的消耗是 21G，我的内存是 64G 的，但是多开一些程序还是会被占满。 另外，如果一个程序需要使用大的内存，比如 1T，是不是应该报错？如果报错，那么程序就会不好写，程序员必须小心翼翼地处理内存的使用，避免超过允许的内存使用阈值。以上提到的这些都是需要解决的问题，也是虚拟化技术存在的价值和意义。
那么如何来解决这些问题呢？ 历史上有过不少的解决方案，但最终沉淀下的是虚拟化技术。接下来我为你介绍一种历史上存在过的 Swap 技术以及虚拟化技术。
交换（Swap）技术 Swap 技术允许一部分进程使用内存，不使用内存的进程数据先保存在磁盘上。注意，这里提到的数据，是完整的进程数据，包括正文段（程序指令）、数据段、堆栈段等。轮到某个进程执行的时候，尝试为这个进程在内存中找到一块空闲的区域。如果空间不足，就考虑把没有在执行的进程交换（Swap）到磁盘上，把空间腾挪出来给需要的进程。
上图中，内存被拆分成多个区域。 内核作为一个程序也需要自己的内存。另外每个进程独立得到一个空间——我们称为地址空间（Address Space）。你可以认为地址空间是一块连续分配的内存块。每个进程在不同地址空间中工作，构成了一个原始的虚拟化技术。
比如：当进程 A 想访问地址 100 的时候，实际上访问的地址是基于地址空间本身位置（首字节地址）计算出来的。另外，当进程 A 执行时，CPU 中会保存它地址空间的开始位置和结束位置，当它想访问超过地址空间容量的地址时，CPU 会检查然后报错。
上图描述的这种方法，是一种比较原始的虚拟化技术，进程使用的是基于地址空间的虚拟地址。但是这种方案有很多明显的缺陷，比如：
 碎片问题：上图中我们看到进程来回分配、回收交换，内存之间会产生很多缝隙。经过反反复复使用，内存的情况会变得十分复杂，导致整体性能下降。 频繁切换问题：如果进程过多，内存较小，会频繁触发交换。  你可以先思考这两个问题的解决方案，接下来我会带你进行一些更深入地思考——首先重新 Review 下我们的设计目标。
 隔离：每个应用有自己的地址空间，互不影响。 性能：高频使用的数据保留在内存中、低频使用的数据持久化到磁盘上。 程序好写（降低程序员心智负担）：让程序员不用关心底层设施。  现阶段，Swap 技术已经初步解决了问题 1。关于问题 2，Swap 技术在性能上存在着碎片、频繁切换等明显劣势。关于问题 3，使用 Swap 技术，程序员需要清楚地知道自己的应用用多少内存，并且小心翼翼地使用内存，避免需要重新申请，或者研发不断扩容的算法——这让程序心智负担较大。</description>
    </item>
    
    <item>
      <title>23 分析服务的特性：我的服务应该开多少个进程、多少个线程？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/23-%E5%88%86%E6%9E%90%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%89%B9%E6%80%A7%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%BA%94%E8%AF%A5%E5%BC%80%E5%A4%9A%E5%B0%91%E4%B8%AA%E8%BF%9B%E7%A8%8B%E5%A4%9A%E5%B0%91%E4%B8%AA%E7%BA%BF%E7%A8%8B/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:20 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/23-%E5%88%86%E6%9E%90%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%89%B9%E6%80%A7%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%BA%94%E8%AF%A5%E5%BC%80%E5%A4%9A%E5%B0%91%E4%B8%AA%E8%BF%9B%E7%A8%8B%E5%A4%9A%E5%B0%91%E4%B8%AA%E7%BA%BF%E7%A8%8B/</guid>
      <description>在平时工作中，你应该经常会遇到自己设计的服务即将上线，这就需要从整体评估各项指标，比如应该开多少个容器、需要多少 CPU 呢？另一方面，应该开多少个线程、多少个进程呢？——如果结合服务特性、目标并发量、目标吞吐量、用户可以承受的延迟等分析，又应该如何调整各种参数？
资源分配多了，CPU、内存等资源会产生资源闲置浪费。资源给少了，则服务不能正常工作，甚至雪崩。因此这里就产生了一个性价比问题——这一讲，就以“我的服务应该开多少个进程、多少个线程”为引，我们一起讨论如何更好地利用系统的资源。
计算密集型和 I/O 密集型 通常我们会遇到两种任务，一种是计算、一种是 I/O。
计算，就是利用 CPU 处理算数运算。比如深度神经网络（Deep Neural Networks），需要大量的计算来计算神经元的激活和传播。再比如，根据营销规则计算订单价格，虽然每一个订单只需要少量的计算，但是在并发高的时候，所有订单累计加起来就需要大量计算。如果一个应用的主要开销在计算上，我们称为计算密集型。
再看看 I/O 密集型，I/O 本质是对设备的读写。读取键盘的输入是 I/O，读取磁盘（SSD）的数据是 I/O。通常 CPU 在设备 I/O 的过程中会去做其他的事情，当 I/O 完成，设备会给 CPU 一个中断，告诉 CPU 响应 I/O 的结果。比如说从硬盘读取数据完成了，那么硬盘给 CPU 一个中断。如果操作对 I/O 的依赖强，比如频繁的文件操作（写日志、读写数据库等），可以看作I/O 密集型。
你可能会有一个疑问，读取硬盘数据到内存中这个过程，CPU 需不需要一个个字节处理？
通常是不用的，因为在今天的计算机中有一个叫作 Direct Memory Access（DMA）的模块，这个模块允许硬件设备直接通过 DMA 写内存，而不需要通过 CPU（占用 CPU 资源）。
很多情况下我们没法使用 DMA，比如说你想把一个数组拷贝到另一个数组内，执行的 memcpy 函数内部实现就是一个个 byte 拷贝，这种情况也是一种CPU 密集的操作。
可见，区分是计算密集型还是 I/O 密集型这件事比较复杂。按说查询数据库是一件 I/O 密集型的事情，但是如果存储设备足够好，比如用了最好的固态硬盘阵列，I/O 速度很快，反而瓶颈会在计算上（对缓存的搜索耗时成为主要部分）。因此，需要一些可衡量指标，来帮助我们确认应用的特性。
衡量 CPU 的工作情况的指标 我们先来看一下 CPU 关联的指标。如下图所示：CPU 有 2 种状态，忙碌和空闲。此外，CPU 的时间还有一种被偷走的情况。</description>
    </item>
    
    <item>
      <title>23 (1)加餐 练习题详解（四）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/23-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E5%9B%9B/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:19 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/23-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E5%9B%9B/</guid>
      <description>今天我会带你把《模块四：进程和多线程》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。
练习题详解 17 | 进程和线程：进程的开销比线程大在了哪里？ 【问题】考虑下面的程序：
fork()
fork()
fork()
print(&amp;ldquo;Hello World\n&amp;rdquo;)
请问这个程序执行后， 输出结果 Hello World 会被打印几次？
【解析】 这道题目考察大家对 fork 能力的理解。
fork 的含义是复制一份当前进程的全部状态。第 1 个 fork 执行 1 次产生 1 个额外的进程。 第 2 个 fork，执行 2 次，产生 2 个额外的进程。第 3 个 fork 执行 4 次，产生 4 个额外的进程。所以执行 print 的进程一共是 8 个。
18 | 锁、信号量和分布式锁：如何控制同一时间只有 2 个线程运行？ 【问题】如果考虑到 CPU 缓存的存在，会对上面我们讨论的算法有什么影响？
【解析】 这是一道需要大家查一些资料的题目。这里涉及一个叫作内存一致性模型的概念。具体就是说，在同一时刻，多线程之间，对内存中某个地址的数据认知是否一致（简单理解，就是多个线程读取同一个内存地址能不能读到一致的值）。
对某个地址，和任意时刻，如果所有线程读取值，得到的结果都一样，是一种强一致性，我们称为线性一致性（Sequencial Consistency），含义就是所有线程对这个地址中数据的历史达成了一致，历史没有分差，有一条大家都能认可的主线，因此称为线性一致。 如果只有部分时刻所有线程的理解是一致的，那么称为弱一致性（Weak Consistency）。
那么为什么会有内存不一致问题呢? 这就是因为 CPU 缓存的存在。
如上图所示：假设一开始 A=0,B=0。两个不在同一个 CPU 核心执行的 Thread1、Thread2 分别执行上图中的简单程序。在 CPU 架构中，Thread1,Thread2 在不同核心，因此它们的 L1\L2 缓存不共用， L3 缓存共享。</description>
    </item>
    
    <item>
      <title>22 进程间通信： 进程间通信都有哪些方法？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/22-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:18 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/22-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95/</guid>
      <description>这节课带给你的面试题目是：进程间通信都有哪些方法？
在上一讲中，我们提到过，凡是面试官问“什么情况下”的时候，面试官实际想听的是你经过理解，整理得到的认知。回答应该是概括的、简要的。而不是真的去列举每一种 case。
另外，面试官考察进程间通信，有一个非常重要的意义——进程间通信是架构复杂系统的基石。复杂系统往往是分成各种子系统、子模块、微服务等等，按照 Unix 的设计哲学，系统的每个部分应该是稳定、独立、简单有效，而且强大的。系统本身各个模块就像人的器官，可以协同工作。而这个协同的枢纽，就是我们今天的主题——进程间通信。
什么是进程间通信？ 进程间通信（Intermediate Process Communication，IPC）。所谓通信就是交换数据。所以，狭义地说，就是操作系统创建的进程们之间在交换数据。 我们今天不仅讨论狭义的通信，还要讨论 IPC 更广泛的意义——程序间的通信。 程序可以是进程，可以是线程，可以是一个进程的两个部分（进程自己发送给自己），也可以是分布式的——总之，今天讨论的是广义的交换数据。
管道 之前我们在“07 | 进程、重定向和管道指令：xargs 指令的作用是？”中讲解过管道和命名管道。 管道提供了一种非常重要的能力，就是组织计算。进程不用知道有管道存在，因此管道的设计是非侵入的。程序员可以先着重在程序本身的设计，只需要预留响应管道的接口，就可以利用管道的能力。比如用shell执行MySQL语句，可能会这样：
进程1 | 进程2 | 进程3 | mysql -u... -p | 爬虫进程我们可以由进程 1、进程 2、进程 3 计算出 MySQL 需要的语句，然后直接通过管道执行。MySQL经过计算将结果传给一个爬虫进程，爬虫就开始工作。MySQL并不是设计用于管道，爬虫进程也不是设计专门用于管道，只是程序员恰巧发现可以这样用，完美地解决了自己的问题，比如：用管道构建一个微型爬虫然后把结果入库。
我们还学过一个词叫作命名管道。命名管道并没有改变管道的用法。相比匿名管道，命名管道提供了更多的编程手段。比如：
进程1 &amp;gt; namedpipe进程2 &amp;gt; namedpipe上面的程序将两个进程的临时结果都同时重定向到 namedpipe，相当于把内容合并了再找机会处理。再比如说，你的进程要不断查询本地的 MySQL，也可以考虑用命名管道将查询传递给 MySQL，再用另一个命名管道传递回来。这样可以省去和 localhost 建立 TCP 3 次握手的时间。 当然，现在数据库都是远程的了，这里只是一个例子。
管道的核心是不侵入、灵活，不会增加程序设计负担，又能组织复杂的计算过程。
本地内存共享 同一个进程的多个线程本身是共享进程内存的。 这种情况不需要特别考虑共享内存。如果是跨进程的线程（或者理解为跨进程的程序），可以考虑使用共享内存。内存共享是现代操作系统提供的能力， Unix 系操作系统，包括 Linux 中有 POSIX 内存共享库——shmem。（如果你感兴趣可以参考网页中的内容，这里不做太深入地分析。）Linux 内存共享库的实现原理是以虚拟文件系统的形式，从内存中划分出一块区域，供两个进程共同使用。看上去是文件，实际操作是内存。
共享内存的方式，速度很快，但是程序不是很好写，因为这是一种侵入式的开发，也就是说你需要为此撰写大量的程序。比如如果修改共享内存中的值，需要调用 API。如果考虑并发控制，还要处理同步问题等。因此，只要不是高性能场景，进程间通信通常不考虑共享内存的方式。
本地消息/队列 内存共享不太好用，因此本地消息有两种常见的方法。一种是用消息队列——现代操作系统都会提供类似的能力。Unix 系可以使用 POSIX 标准的 mqueue。另一种方式，就是直接用网络请求，比如 TCP/IP 协议，也包括建立在这之上的更多的通信协议（这些我们在下文中的“远程调用”部分详细讲解）。</description>
    </item>
    
    <item>
      <title>21 哲学家就餐问题：什么情况下会触发饥饿和死锁？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/21-%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%B0%B1%E9%A4%90%E9%97%AE%E9%A2%98%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E4%BC%9A%E8%A7%A6%E5%8F%91%E9%A5%A5%E9%A5%BF%E5%92%8C%E6%AD%BB%E9%94%81/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:17 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/21-%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%B0%B1%E9%A4%90%E9%97%AE%E9%A2%98%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E4%BC%9A%E8%A7%A6%E5%8F%91%E9%A5%A5%E9%A5%BF%E5%92%8C%E6%AD%BB%E9%94%81/</guid>
      <description>这一讲给你带来的面试题目是：什么情况下会触发饥饿和死锁？
读题可知，这道题目在提问“场景”，从表面来看，解题思路是列举几个例子。但是在回答这类面试题前你一定要想一想面试官在考察什么，往往在题目中看到“什么情况下”时，其实考察的是你总结和概括信息的能力。
关于上面这道题目，如果你只回答一个场景，而没有输出概括性的总结内容，就很容易被面试官认为对知识理解不到位，因而挂掉面试。另外，提问死锁和饥饿还有一个更深层的意思，就是考察你在实战中对并发控制算法的理解，是否具备设计并发算法来解决死锁问题并且兼顾性能（并发量）的思维和能力。
要学习这部分知识有一个非常不错的模型，就是哲学家就餐问题。1965 年，计算机科学家 Dijkstra 为了帮助学生更好地学习并发编程设计的一道练习题，后来逐渐成为大家广泛讨论的问题。
哲学家就餐问题 问题描述如下：有 5 个哲学家，围着一个圆桌就餐。圆桌上有 5 份意大利面和 5 份叉子。哲学家比较笨，他们必须拿到左手和右手的 2 个叉子才能吃面。哲学不饿的时候就在思考，饿了就去吃面，吃面的必须前提是拿到 2 个叉子，吃完面哲学家就去思考。
假设每个哲学家用一个线程实现，求一种并发控制的算法，让哲学家们按部就班地思考和吃面。当然我这里做了一些改动，比如 Dijkstra 那个年代线程还没有普及，最早的题目每个哲学家是一个进程。
问题的抽象 接下来请你继续思考，我们对问题进行一些抽象，比如哲学是一个数组，编号 0~4。我这里用 Java 语言给你演示，哲学家是一个类，代码如下：
static class Philosopher implements Runnable {private static Philosopher[] philosophers;static {philosophers = new Philosopher[5];}}这里考虑叉子也使用编号 0~4，代码如下：
private static Integer[] forks;private static Philosopher[] philosophers;static {for(int i = 0; i &amp;lt; 5; i++) {philosophers[i] = new Philosopher(i);forks[i] = -1;}}forks[i]的值等于 x，相当于编号为i的叉子被编号为 x 的哲学家拿起；如果等于-1，那么叉子目前放在桌子上。</description>
    </item>
    
    <item>
      <title>20 线程的调度：线程调度都有哪些方法？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/20-%E7%BA%BF%E7%A8%8B%E7%9A%84%E8%B0%83%E5%BA%A6%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:16 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/20-%E7%BA%BF%E7%A8%8B%E7%9A%84%E8%B0%83%E5%BA%A6%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95/</guid>
      <description>这一讲我带来的面试题目是：线程调度都有哪些方法？
所谓调度，是一个制定计划的过程，放在线程调度背景下，就是操作系统如何决定未来执行哪些线程？
这类型的题目考察的并不是一个死的概念，面试官会通过你的回答考量你对知识进行加工和理解的能力。这有点类似于设计技术方案，要对知识进行系统化、结构化地思考和分类。就这道题目而言，可以抓两条主线，第一条是形形色色调度场景怎么来的？第二条是每个调度算法是如何工作的？
先到先服务 早期的操作系统是一个个处理作业（Job），比如很多保险业务，每处理一个称为一个作业（Job）。处理作业最容易想到的就是先到先服务（First Come First Service，FCFS），也就是先到的作业先被计算，后到的作业，排队进行。
这里需要用到一个叫作队列的数据结构，具有先入先出（First In First Out，FIFO）性质。先进入队列的作业，先处理，因此从公平性来说，这个算法非常朴素。另外，一个作业完全完成才会进入下一个作业，作业之间不会发生切换，从吞吐量上说，是最优的——因为没有额外开销。
但是这样对于等待作业的用户来说，是有问题的。比如一笔需要用时 1 天的作业 ，如果等待了 10 分钟，用户是可以接受的；一个用时 10 分钟的作业，用户等待一天就要投诉了。 因此如果用时 1 天的作业先到，用时 10 分钟的任务后到，应该优先处理用时少的，也就是短作业优先（Shortest Job First，SJF）。
短作业优先 通常会同时考虑到来顺序和作业预估时间的长短，比如下面的到来顺序和预估时间：
这样就会优先考虑第一个到来预估时间为 3 分钟的任务。 我们还可以从另外一个角度来审视短作业优先的优势，就是平均等待时间。
平均等待时间 = 总等待时间/任务数
上面例子中，如果按照 3,3,10 的顺序处理，平均等待时间是：(0 + 3 + 6) / 3 = 3 分钟。 如果按照 10,3,3 的顺序来处理，就是( 0+10+13 )/ 3 = 7.66 分钟。
平均等待时间和用户满意度是成反比的，等待时间越长，用户越不满意，因此在大多数情况下，应该优先处理用时少的，从而降低平均等待时长。
采用 FCFS 和 SJF 后，还有一些问题没有解决。
 紧急任务如何插队？比如老板安排的任务。 等待太久的任务如何插队？比如用户等太久可能会投诉。 先执行的大任务导致后面来的小任务没有执行如何处理？比如先处理了一个 1 天才能完成的任务，工作半天后才发现预估时间 1 分钟的任务也到来了。  为了解决上面的问题，我们设计了两种方案， 一种是优先级队列（PriorityQueue），另一种是抢占（Preemption）。</description>
    </item>
    
    <item>
      <title>19 乐观锁、区块链：除了上锁还有哪些并发控制方法？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/19-%E4%B9%90%E8%A7%82%E9%94%81%E5%8C%BA%E5%9D%97%E9%93%BE%E9%99%A4%E4%BA%86%E4%B8%8A%E9%94%81%E8%BF%98%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:15 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/19-%E4%B9%90%E8%A7%82%E9%94%81%E5%8C%BA%E5%9D%97%E9%93%BE%E9%99%A4%E4%BA%86%E4%B8%8A%E9%94%81%E8%BF%98%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95/</guid>
      <description>这一讲我带来的面试题是：除了上锁还有哪些并发控制方法？
上面这道面试题是在“有哪些并发控制方法？”这个问题的基础上加了一个限制条件。
在我面试候选人的过程中，“上锁”是我听到过回答频次最多的答案，也就是说大多数程序员都可以想到这个并发控制方法。因此，是否能回答出上锁以外的方法，是检验程序员能力的一个分水岭，其实锁以外还有大量优秀的方法。
你掌握的方法越多，那么在解决实际问题的时候，思路就越多。即使你没有做过高并发场景的设计，但是如果脑海中有大量优秀的方法可以使用，那么公司也会考虑培养你，将高并发场景交给你去解决。今天我们就以这道面试题为引，一起探讨下“锁以外的并发控制方法”。
悲观锁/乐观锁 说到并发场景，设计系统的目的往往是达到同步（Synchronized）的状态，同步就是大家最终对数据的理解达成了一致。
同步的一种方式，就是让临界区互斥。 这种方式，每次只有一个线程可以进入临界区。比如多个人修改一篇文章，这意味着必须等一个人编辑完，另一个人才能编辑。但是从实际问题出发，如果多个人编辑的不是文章的同一部分，是可以同时编辑的。因此，让临界区互斥的方法（对临界区上锁），具有强烈的排他性，对修改持保守态度，我们称为悲观锁（Pressimistic Lock）。
通常意义上，我们说上锁，就是悲观锁，比如说 MySQL 的表锁、行锁、Java 的锁，本质是互斥（mutex）。
和悲观锁（PressimisticLock）持相反意见的，是乐观锁（Optimistic Lock）。你每天都用的，基于乐观锁的应用就是版本控制工具 Git。Git 允许大家一起编辑，将结果先存在本地，然后都可以向远程仓库提交，如果没有版本冲突，就可以提交上去。这就是一种典型的乐观锁的场景，或者称为基于版本控制的场景。
Git 的类比 比如现在代码仓库的版本是 100。Bob 和 Alice 把版本 100 拷贝到本地，Bob 在本地写到了 106 版本，Alice 在本地写到 108 版本。那么如果 Alice 先提交，代码仓库的版本就到了 108。 Bob 再提交的时候，发现版本已经不是 100 了，就需要把最新的代码 fetch 到本地，然后合并冲突，再尝试提交一个更新的版本，比如 110。
这种方式非常类似cas指令的形式，就是每次更新的发起方，需要明确地知道想从多少版本更新到多少版本。以 Git 为例，可以写出cas的伪代码：
cas(&amp;amp;version, 100, 108); // 成功cas(&amp;amp;version, 100, 106); // 失败，因为version是108上面代码第二次cas操作时因为版本变了，更新失败，这就是一个乐观锁——Alice 和 Bob 可以同时写，先更新的人被采纳，后更新的人负责解决冲突。
购物车的类比 再举个例子，比如说要实现一个购物车。用户可能在移动端、PC 端之间切换，比如他用一会手机累了，然后换成用电脑，当他用电脑累了，再换回手机。
在移动端和 PC 端，用户都在操作购物车。 比如在移动端上，用户增加了商品 A；然后用户打开 PC 端，增加了商品 B；然后用户又换回了移动端，想增加商品 C。</description>
    </item>
    
    <item>
      <title>18 锁、信号量和分布式锁：如何控制同一时间只有 2 个线程运行？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/18-%E9%94%81%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%90%8C%E4%B8%80%E6%97%B6%E9%97%B4%E5%8F%AA%E6%9C%89-2-%E4%B8%AA%E7%BA%BF%E7%A8%8B%E8%BF%90%E8%A1%8C/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:14 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/18-%E9%94%81%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%90%8C%E4%B8%80%E6%97%B6%E9%97%B4%E5%8F%AA%E6%9C%89-2-%E4%B8%AA%E7%BA%BF%E7%A8%8B%E8%BF%90%E8%A1%8C/</guid>
      <description>锁是一个面试的热门话题，有乐观锁、悲观锁、重入锁、公平锁、分布式锁。有很多和锁相关的数据结构，比如说阻塞队列。还有一些关联的一些工具，比如说 Semaphore、Monitor 等。这些知识点可以关联很多的面试题目，比如：
 锁是如何实现的？ 如何控制同一时间只有 2 个线程运行？ 如何实现分布式锁？  面试官通过这类题目考查你的这部分知识，就知道你对并发的理解是停留在表面，还是可以深入原理，去设计高并发的数据结构。这一讲我将帮你把锁类问题一网打尽。
原子操作 要想弄清楚锁，就要弄清楚锁的实现，实现锁需要底层提供的原子操作，因此我们先来学习下原子操作。
原子操作就是操作不可分。在多线程环境，一个原子操作的执行过程无法被中断。那么你可以思考下，具体原子操作的一个示例。
比如i++就不是一个原子操作，因为它是 3 个原子操作组合而成的：
 读取 i 的值； 计算 i+1； 写入新的值。  像这样的操作，在多线程 + 多核环境会造成竞争条件。
竞争条件 竞争条件就是说多个线程对一个资源（内存地址）的读写存在竞争，在这种条件下，最后这个资源的值不可预测，而是取决于竞争时具体的执行顺序。
举个例子，比如两个线程并发执行i++。那么可以有下面这个操作顺序，假设执行前i=0：
虽然上面的程序执行了两次i++，但最终i的值为 1。
i++这段程序访问了共享资源，也就是变量i，这种访问共享资源的程序片段我们称为临界区。在临界区，程序片段会访问共享资源，造成竞争条件，也就是共享资源的值最终取决于程序执行的时序，因此这个值不是确定的。
竞争条件是一件非常糟糕的事情，你可以把上面的程序想象成两个自动提款机。如果用户同时操作两个自动提款机，用户的余额就可能会被算错。
解决竞争条件 解决竞争条件有很多方案，一种方案就是不要让程序同时进入临界区，这个方案叫作互斥。还有一些方案旨在避免竞争条件，比如 ThreadLocal、 cas 指令以及 “19 讲”中我们要学习的乐观锁。
避免临界区 不让程序同时进入临界区这个方案比较简单，核心就是我们给每个线程一个变量i，比如利用 ThreadLocal，这样线程之间就不存在竞争关系了。这样做优点很明显，缺点就是并不是所有的情况都允许你这样做。有一些资源是需要共享的，比如一个聊天室，如果每次用户请求都有一个单独的线程在处理，不可能为每个请求（线程）都维护一份聊天记录。
cas 指令 另一个方案是利用 CPU 的指令，让i++成为一个原子操作。 很多 CPU 都提供 Compare And Swap 指令。这个指令的作用是更新一个内存地址的值，比如把i更新为i+1，但是这个指令明确要求使用者必须确定知道内存地址中的值是多少。比如一个线程想把i从100更新到101，线程必须明确地知道现在i是 100，否则就会更新失败。
cas 可以用下面这个函数表示：
cas(&amp;amp;oldValue, expectedValue, targetValue)这里我用的是伪代码，用&amp;amp;符号代表这里取内存地址。注意 cas 是 CPU 提供的原子操作。因此上面的比较和设置值的过程，是原子的，也就是不可分。
比如想用 cas 更新i的值，而且知道i是 100，想更新成101。那么就可以这样做：</description>
    </item>
    
    <item>
      <title>17 进程和线程：进程的开销比线程大在了哪里？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/17-%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%BC%80%E9%94%80%E6%AF%94%E7%BA%BF%E7%A8%8B%E5%A4%A7%E5%9C%A8%E4%BA%86%E5%93%AA%E9%87%8C/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:13 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/17-%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%BC%80%E9%94%80%E6%AF%94%E7%BA%BF%E7%A8%8B%E5%A4%A7%E5%9C%A8%E4%BA%86%E5%93%AA%E9%87%8C/</guid>
      <description>不知你在面试中是否遇到过这样的问题，题目很短，看似简单，但在回答时又感觉有点吃力？比如下面这两个问题：
 进程内部都有哪些数据？ 为什么创建进程的成本很高？  这样的问题确实不好回答，除非你真正理解了进程和线程的原理，否则很容易掉入面试大坑。本讲，我将带你一起探究问题背后的原理，围绕面试题展开理论与实践知识的学习。通过本讲的学习，希望你可以真正理解进程和线程原理，从容应对面试。
进程和线程 进程（Process），顾名思义就是正在执行的应用程序，是软件的执行副本。而线程是轻量级的进程。
进程是分配资源的基础单位。而线程很长一段时间被称作轻量级进程（Light Weighted Process），是程序执行的基本单位。
在计算机刚刚诞生的年代，程序员拿着一个写好程序的闪存卡，插到机器里，然后电能推动芯片计算，芯片每次从闪存卡中读出一条指令，执行后接着读取下一条指令。闪存中的所有指令执行结束后，计算机就关机。
早期的 ENIAC
一开始，这种单任务的模型，在那个时代叫作作业（Job），当时计算机的设计就是希望可以多处理作业。图形界面出现后，人们开始利用计算机进行办公、购物、聊天、打游戏等，因此一台机器正在执行的程序会被随时切来切去。于是人们想到，设计进程和线程来解决这个问题。
每一种应用，比如游戏，执行后是一个进程。但是游戏内部需要图形渲染、需要网络、需要响应用户操作，这些行为不可以互相阻塞，必须同时进行，这样就设计成线程。
资源分配问题 设计进程和线程，操作系统需要思考分配资源。最重要的 3 种资源是：计算资源（CPU）、内存资源和文件资源。早期的 OS 设计中没有线程，3 种资源都分配给进程，多个进程通过分时技术交替执行，进程之间通过管道技术等进行通信。
但是这样做的话，设计者们发现用户（程序员），一个应用往往需要开多个进程，因为应用总是有很多必须要并行做的事情。并行并不是说绝对的同时，而是说需要让这些事情看上去是同时进行的——比如图形渲染和响应用户输入。于是设计者们想到了，进程下面，需要一种程序的执行单位，仅仅被分配 CPU 资源，这就是线程。
轻量级进程 线程设计出来后，因为只被分配了计算资源（CPU），因此被称为轻量级进程。被分配的方式，就是由操作系统调度线程。操作系统创建一个进程后，进程的入口程序被分配到了一个主线程执行，这样看上去操作系统是在调度进程，其实是调度进程中的线程。
这种被操作系统直接调度的线程，我们也成为内核级线程。另外，有的程序语言或者应用，用户（程序员）自己还实现了线程。相当于操作系统调度主线程，主线程的程序用算法实现子线程，这种情况我们称为用户级线程。Linux 的 PThread API 就是用户级线程，KThread API 则是内核级线程。
分时和调度 因为通常机器中 CPU 核心数量少（从几个到几十个）、进程&amp;amp;线程数量很多（从几十到几百甚至更多），你可以类比为发动机少，而机器多，因此进程们在操作系统中只能排着队一个个执行。每个进程在执行时都会获得操作系统分配的一个时间片段，如果超出这个时间，就会轮到下一个进程（线程）执行。再强调一下，现代操作系统都是直接调度线程，不会调度进程。
分配时间片段 如下图所示，进程 1 需要 2 个时间片段，进程 2 只有 1 个时间片段，进程 3 需要 3 个时间片段。因此当进程 1 执行到一半时，会先挂起，然后进程 2 开始执行；进程 2 一次可以执行完，然后进程 3 开始执行，不过进程 3 一次执行不完，在执行了 1 个时间片段后，进程 1 开始执行；就这样如此周而复始。这个就是分时技术。
下面这张图更加直观一些，进程 P1 先执行一个时间片段，然后进程 P2 开始执行一个时间片段， 然后进程 P3，然后进程 P4……</description>
    </item>
    
    <item>
      <title>16 WinMacUnixLinux 的区别和联系：为什么 Debian 漏洞排名第一还这么多人用？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/16-winmacunixlinux-%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB%E4%B8%BA%E4%BB%80%E4%B9%88-debian-%E6%BC%8F%E6%B4%9E%E6%8E%92%E5%90%8D%E7%AC%AC%E4%B8%80%E8%BF%98%E8%BF%99%E4%B9%88%E5%A4%9A%E4%BA%BA%E7%94%A8/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:12 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/16-winmacunixlinux-%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB%E4%B8%BA%E4%BB%80%E4%B9%88-debian-%E6%BC%8F%E6%B4%9E%E6%8E%92%E5%90%8D%E7%AC%AC%E4%B8%80%E8%BF%98%E8%BF%99%E4%B9%88%E5%A4%9A%E4%BA%BA%E7%94%A8/</guid>
      <description>在我的印象中 Windows 才是最容易被攻击的操作系统，没想到 2020 年美国 NIST 的报告中， Debian 竟然是过去 20 年中漏洞最多的操作系统。Debain 以 3067 个漏洞稳居第一，第二名是 Android，第三名是 Linux Kernel。那么为什么 Debian 漏洞数会排在第一位呢？
NIST的数据报告：软件漏洞排名
今天我们就以这个问题为引，带你了解更多的操作系统。这就要追溯到 20 世纪操作系统蓬勃发展的年代。那是一个惊艳绝伦的时代，一个个天才黑客，一场场激烈的商战，一次次震撼的产品发布会——每个人都想改变世界，都在积极的抓住时机，把握时代赋予的机会。我们今天的工程师文化——一种最纯粹的、崇尚知识，崇尚创造的文化，也是传承于此。
本课时作为内核部分的最后一课，我会带你了解一些操作系统的历史，希望通过这种方式，把这种文化传承下去，让你更有信心去挑战未来的变化。当然，你也可以把本课时当作一个选学的内容，不会影响你继续学习我后面的课程。
IBM 话不多说，我们正式开始。1880 年美国进行了一次人口普查，涉及5000 多万人。因为缺少技术手段，总共用了 7 年半时间才完成。后来霍尔列斯发明了一种穿孔制表机，大大改善了这种情况，而后他还给这种机器申请了专利。
1896 年，霍尔列斯成立了 CRT 公司，也就是 IBM 的前身。后来霍尔列斯经营不善，遇到困难，中间有金融家，军火商都参与过 CRT 的经营，却没能使得情况好转。
直到 1914 年托马斯·约翰·沃森（老沃森）加盟CRT，帮助霍尔列斯管理 CRT，情况才逐渐好转。老沃森是一个销售出身，很懂得建立销售团队的文化，所以才能逐渐把 CRT 的业务做起来，成为 CRT 的实际掌控者。在 1924 年 CRT 正式更名为 IBM，开启了沃森的时代。
IBM（International Business Machines Corporation）一开始是卖机器的。后来沃森的儿子，也就是小沃森后来逐渐接管了 IBM。小沃森对蓬勃发展的计算机产业非常感兴趣，同时也很看好计算机市场。但也正因如此，沃森父子间发生了一场冲突。老沃森的著名论断也是出自这场冲突：世界上对计算机有需求的人不会超过 5 个。于是我们都成了这幸运的 5 个人之一。
所以 IBM 真正开始做计算机是 1949 年小沃森逐渐掌权后。1954 年，IBM 推出了世界上第一个拥有操作系统的商用计算机——IBM 704，并且在 1956 年时独占了计算机市场的 70% 的份额。</description>
    </item>
    
    <item>
      <title>16 (1)加餐 练习题详解（三）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/16-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%B8%89/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:11 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/16-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%B8%89/</guid>
      <description>今天我会带你把《模块三：操作系统基础知识》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。
练习题详解 13 | 操作系统内核：Linux 内核和 Windows 内核有什么区别？ 【问题】 Unix 和 Mac OS 内核属于哪种类型？
【解析】 Unix 和 Linux 非常类似，也是宏内核。Mac OS 用的是 XNU 内核， XNU 是一种混合型内核。为了帮助你理解，我找了一张 Mac OS 的内核架构图。 如下图所示，可以看到内部是一个叫作 XNU 的宏内核。XNU 是 X is not Unix 的意思， 是一个受 Unix 影响很大的内核。
Mac OS 内核架构图
14 | 用户态和内核态：用户态线程和内核态线程有什么区别？ 【问题】 JVM 的线程是用户态线程还是内核态线程？
【解析】 JVM 自己本身有一个线程模型。在 JDK 1.1 的时候，JVM 自己管理用户级线程。这样做缺点非常明显，操作系统只调度内核级线程，用户级线程相当于基于操作系统分配到进程主线程的时间片，再次拆分，因此无法利用多核特性。
为了解决这个问题，后来 Java 改用线程映射模型，因此，需要操作系统支持。在 Windows 上是 1 对 1 的模型，在 Linux 上是 n 对 m 的模型。顺便说一句，Linux 的PThreadAPI 创建的是用户级线程，如果 Linux 要创建内核级线程有KThreadAPI。映射关系是操作系统自动完成的，用户不需要管。</description>
    </item>
    
    <item>
      <title>15 中断和中断向量：Javajs 等语言为什么可以捕获到键盘输入？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/15-%E4%B8%AD%E6%96%AD%E5%92%8C%E4%B8%AD%E6%96%AD%E5%90%91%E9%87%8Fjavajs-%E7%AD%89%E8%AF%AD%E8%A8%80%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AF%E4%BB%A5%E6%8D%95%E8%8E%B7%E5%88%B0%E9%94%AE%E7%9B%98%E8%BE%93%E5%85%A5/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:10 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/15-%E4%B8%AD%E6%96%AD%E5%92%8C%E4%B8%AD%E6%96%AD%E5%90%91%E9%87%8Fjavajs-%E7%AD%89%E8%AF%AD%E8%A8%80%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AF%E4%BB%A5%E6%8D%95%E8%8E%B7%E5%88%B0%E9%94%AE%E7%9B%98%E8%BE%93%E5%85%A5/</guid>
      <description>你好，发现求知的乐趣，我是林䭽。
本课时我们依然以一道面试题为引开启今天的学习。请你思考：Java/JS 等语言为什么可以捕获到键盘的输入？
其实面试是一个寻找同类的过程，在阿里叫作“闻味道”——用键盘输入是程序员每天必做的事情，如果你对每天发生的事情背后的技术原理保持好奇心和兴趣，并且愿意花时间去探索和学习，这就是技术潜力强的表现。相反，如果你只对马上能为自己创造价值的事情感兴趣，不愿意通过探索和思考的方式，去理解普遍存在的世界，长此以往就会导致知识储备不足。
我想通过本课时讲解一种特别的学习技巧，可以说是“填鸭式学习”的反义词，叫作“探索式学习”。我看网上也叫作“破案式学习”，学习过程像攻破一个谜题，或者分析一个案件，并不是从结论开始，然后一层层学习理论；而是通过找到一个目标，一层层挖掘需要的知识、理论，一点点去思考解决方案，最终达到提升解决问题能力的目的。
接下来，请你和我一起化身成一名计算机科学家，假设明天就要生产机器了，但是为 Java/JS 等语言提供键盘输入支持模块的操作系统今天还没有完成，现在还有一节课的时间，那么我们应该如何去做呢？
探索过程：如何设计响应键盘的整个链路？ 当你拿到一个问题时，需要冷静下来思考和探索解决方案。你可以查资料、看视频或者咨询专家，但是在这之前，你先要进行一定的思考和梳理，有的问题可以直接找到答案，有的问题却需要继续深挖寻找其背后的理论支撑。
问题 1：我们的目标是什么?
我们的目标是在 Java/JS 中实现按键响应程序。这种实现有点像 Switch-Case 语句——根据不同的按键执行不同的程序，比如按下回车键可以换行，按下左右键可以移动光标。
问题 2：按键怎么抽象？
键盘上一般不超过 100 个键。因此我们可以考虑用一个 Byte 的数据来描述用户按下了什么键。按键有两个操作，一个是按下、一个是释放，这是两个不同的操作。对于一个 8 位的字节，可以考虑用最高位的 1 来描述按下还是释放的状态，然后后面的 7 位（0~127）描述具体按了哪个键。这样我们只要确定了用户按键/释放的顺序，对我们的系统来说，就不会有歧义。
问题 3：如何处理按键？使用操作系统处理还是让每个程序自己实现？
处理按键是一个通用程序，可以考虑由操作系统先进行一部分处理，比如：
 用户按下了回车键，先由操作系统进行统一的封装，再把按键的编码转换为字符串Enter方便各种程序使用。 处理组合键这种操作，由操作系统先一步进行计算比较好。因为底层只知道按键、释放，组合键必须结合时间因素判断。  你可以把下面这种情况看作是一个Ctrl + C组合键，这种行为可以由操作系统进行统一处理，如下所示：
按下 Ctrl按下 C释放 Ctrl释放 C问题 4：程序用什么模型响应按键？
当一个 Java 或者 JS 写的应用程序想要响应按键时，应该考虑消息模型。因为如果程序不停地扫描按键，会给整个系统带来很大的负担。比如程序写一个while循环去扫描有没有按键，开销会很大。 如果程序在操作系统端注册一个响应按键的函数，每次只有真的触发按键时才执行这个函数，这样就能减少开销了。
问题 5：处理用户按键，需不需要打断正在执行的程序？
从用户体验上讲，按键应该是一个高优先级的操作，比如用户按 Ctrl+C 或者 Esc 的时候，可能是因为用户想要打断当前执行的程序。即便是用户只想要输入，也应该尽可能地集中资源给到用户，因为我们不希望用户感觉到延迟。
如果需要考虑到程序随时会被中断，去响应其他更高优先级的情况，那么从程序执行的底层就应该支持这个行为，而且最好从硬件层面去支持，这样速度最快。 这就引出了本课时的主角——中断。具体如何处理，见下面我们关于中断部分的分析。
问题 6：操作系统如何知道用户按了哪个键？
这里有一个和问题 5 类似的问题。操作系统是不断主动触发读取键盘按键，还是每次键盘按键到来的时候都触发一段属于操作系统的程序呢？</description>
    </item>
    
    <item>
      <title>14 用户态和内核态：用户态线程和内核态线程有什么区别？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/14-%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E7%94%A8%E6%88%B7%E6%80%81%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E7%BA%BF%E7%A8%8B%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:09 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/14-%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E7%94%A8%E6%88%B7%E6%80%81%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E7%BA%BF%E7%A8%8B%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</guid>
      <description>这节课给你带来了一道非常经典的面试题目：用户态线程和内核态线程有什么区别？
这是一个组合型的问题，由很多小问题组装而成，比如：
 用户态和内核态是什么？ 用户级线程和内核级线程是一个怎样的对应关系？ 内核响应系统调用是一个怎样的过程？ ……  而且这个问题还关联到了我们后面要学习的多线程、I/O 模型、网络优化等。 所以这是一道很不错的面试题目，它不是简单考某个概念，而是通过让求职者比较两种东西，从而考察你对知识整体的认知和理解。
今天就请你顺着这个问题，深入学习内核的工作机制，和我一起去理解用户态和内核态。
什么是用户态和内核态 Kernel 运行在超级权限模式（Supervisor Mode）下，所以拥有很高的权限。按照权限管理的原则，多数应用程序应该运行在最小权限下。因此，很多操作系统，将内存分成了两个区域：
 内核空间（Kernal Space），这个空间只有内核程序可以访问； 用户空间（User Space），这部分内存专门给应用程序使用。  用户态和内核态 用户空间中的代码被限制了只能使用一个局部的内存空间，我们说这些程序在用户态（User Mode） 执行。内核空间中的代码可以访问所有内存，我们称这些程序在内核态（Kernal Mode） 执行。
系统调用过程 如果用户态程序需要执行系统调用，就需要切换到内核态执行。下面我们来讲讲这个过程的原理。
如上图所示：内核程序执行在内核态（Kernal Mode），用户程序执行在用户态（User Mode）。当发生系统调用时，用户态的程序发起系统调用。因为系统调用中牵扯特权指令，用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。
发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。关于中断，我们将在“15 课时”进行详细讨论。
线程模型 上面我们学习了用户态和内核态，接下来我们从进程和线程的角度进一步思考本课时开头抛出的问题。
进程和线程 一个应用程序启动后会在内存中创建一个执行副本，这就是进程。Linux 的内核是一个 Monolithic Kernel（宏内核），因此可以看作一个进程。也就是开机的时候，磁盘的内核镜像被导入内存作为一个执行副本，成为内核进程。
进程可以分成用户态进程和内核态进程两类。用户态进程通常是应用程序的副本，内核态进程就是内核本身的进程。如果用户态进程需要申请资源，比如内存，可以通过系统调用向内核申请。
那么用户态进程如果要执行程序，是否也要向内核申请呢？
程序在现代操作系统中并不是以进程为单位在执行，而是以一种轻量级进程（Light Weighted Process），也称作线程（Thread）的形式执行。
一个进程可以拥有多个线程。进程创建的时候，一般会有一个主线程随着进程创建而创建。
如果进程想要创造更多的线程，就需要思考一件事情，这个线程创建在用户态还是内核态。
你可能会问，难道不是用户态的进程创建用户态的线程，内核态的进程创建内核态的线程吗？
其实不是，进程可以通过 API 创建用户态的线程，也可以通过系统调用创建内核态的线程，接下来我们说说用户态的线程和内核态的线程。
用户态线程 用户态线程也称作用户级线程（User Level Thread）。操作系统内核并不知道它的存在，它完全是在用户空间中创建。
用户级线程有很多优势，比如。
 管理开销小：创建、销毁不需要系统调用。 切换成本低：用户空间程序可以自己维护，不需要走操作系统调度。  但是这种线程也有很多的缺点。
 与内核协作成本高：比如这种线程完全是用户空间程序在管理，当它进行 I/O 的时候，无法利用到内核的优势，需要频繁进行用户态到内核态的切换。 线程间协作成本高：设想两个线程需要通信，通信需要 I/O，I/O 需要系统调用，因此用户态线程需要支付额外的系统调用成本。 无法利用多核优势：比如操作系统调度的仍然是这个线程所属的进程，所以无论每次一个进程有多少用户态的线程，都只能并发执行一个线程，因此一个进程的多个线程无法利用多核的优势。 操作系统无法针对线程调度进行优化：当一个进程的一个用户态线程阻塞（Block）了，操作系统无法及时发现和处理阻塞问题，它不会更换执行其他线程，从而造成资源浪费。  内核态线程 内核态线程也称作内核级线程（Kernel Level Thread）。这种线程执行在内核态，可以通过系统调用创造一个内核级线程。</description>
    </item>
    
    <item>
      <title>13 操作系统内核：Linux 内核和 Windows 内核有什么区别？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/13-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E6%A0%B8linux-%E5%86%85%E6%A0%B8%E5%92%8C-windows-%E5%86%85%E6%A0%B8%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:08 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/13-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E6%A0%B8linux-%E5%86%85%E6%A0%B8%E5%92%8C-windows-%E5%86%85%E6%A0%B8%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</guid>
      <description>Windows 和 Linux 是当今两款最主流的服务器操作系统产品，都拥有广泛的用户和信徒。Windows 通过强大的商业运作，驱动了大量优秀人才加盟到它的开发团队中；Linux 通过社区产品的魅力吸引着世界上大量的顶级程序员为它贡献源代码、解答问题。两者在服务器市场上竞争激烈，不分伯仲，但也存在互相扶持的关系。
我觉得，两个操作系统各有千秋。每次学习两个操作系统的技术知识，都让我切实地感受到编程真的是一门艺术，而学习编程就像是在探索艺术。
今天我们继续从一道面试题目“ Linux 内核和 Windows 内核有什么区别？”入手，去了解这两个操作系统内核的设计，帮助你学习操作系统中最核心的一个概念——内核，并希望这些知识可以伴随你日后的每个系统设计。
什么是内核？ 说到操作系统，就必须说内核。内核是操作系统中应用连接硬件设备的桥梁。
内核的能力 对于一个现代的操作系统来说，它的内核至少应该提供以下 4 种基本能力：
 管理进程、线程（决定哪个进程、线程使用 CPU）； 管理内存（决定内存用来做什么）； 连接硬件设备（为进程、和设备间提供通信能力）； 提供系统调用（接收进程发送来的系统调用）。  操作系统分层 从上面 4 种能力来看操作系统和内核之间的关系，通常可以把操作系统分成 3 层，最底层的硬件设备抽象、中间的内核和最上层的应用。
内核是如何工作的？ 为了帮助你理解什么是内核，请你先思考一个问题：进程和内核的关系，是不是像浏览器请求服务端服务？你可以先自己思考，然后在留言区写下你此时此刻对这个问题的认知，等学完“模块三”再反过头来回顾这个知识，相信你定会产生新的理解。
接下来，我们先一起分析一下这个问题。
内核权限非常高，它可以管理进程、可以直接访问所有的内存，因此确实需要和进程之间有一定的隔离。这个隔离用类似请求/响应的模型，非常符合常理。
但不同的是在浏览器、服务端模型中，浏览器和服务端是用不同的机器在执行，因此不需要共享一个 CPU。但是在进程调用内核的过程中，这里是存在资源共享的。
 比如，一个机器有 4 个 CPU，不可能让内核用一个 CPU，其他进程用剩下的 CPU。这样太浪费资源了。 再比如，进程向内核请求 100M 的内存，内核把 100M 的数据传回去。 这个模型不可行，因为传输太慢了。  所以，这里多数操作系统的设计都遵循一个原则：进程向内核发起一个请求，然后将 CPU 执行权限让出给内核。内核接手 CPU 执行权限，然后完成请求，再转让出 CPU 执行权限给调用进程。
关于这块知识，我们会在“ 14 |户态和内核态：用户态线程和内核态线程有什么区别？”中详细讨论。
Linux 的设计 Linux 操作系统第一版是1991 年林纳斯托·瓦兹（一个芬兰的小伙子，当时 22 岁）用 C 语音写的。 写完之后他在网络上发布了 Linux 内核的源代码。又经过了 3 年的努力，在 1994 年发布了完整的核心 Version 1.</description>
    </item>
    
    <item>
      <title>12 高级技巧之集群部署：利用 Linux 指令同时在多台机器部署程序</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/12-%E9%AB%98%E7%BA%A7%E6%8A%80%E5%B7%A7%E4%B9%8B%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%88%A9%E7%94%A8-linux-%E6%8C%87%E4%BB%A4%E5%90%8C%E6%97%B6%E5%9C%A8%E5%A4%9A%E5%8F%B0%E6%9C%BA%E5%99%A8%E9%83%A8%E7%BD%B2%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:07 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/12-%E9%AB%98%E7%BA%A7%E6%8A%80%E5%B7%A7%E4%B9%8B%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%88%A9%E7%94%A8-linux-%E6%8C%87%E4%BB%A4%E5%90%8C%E6%97%B6%E5%9C%A8%E5%A4%9A%E5%8F%B0%E6%9C%BA%E5%99%A8%E9%83%A8%E7%BD%B2%E7%A8%8B%E5%BA%8F/</guid>
      <description>Linux 指令是由很多顶级程序员共同设计的，使用 Linux 指令解决问题的过程，就好像在体验一款优秀的产品。每次通过查资料使用 Linux 指令解决问题后，都会让我感到收获满满。在这个过程中，我不仅学会了一条指令，还从中体会到了软件设计的魅力：彼此独立，又互成一体。这就像每个 Linux 指令一样，专注、高效。回想起来，在我第一次看到管道、第一次使用 awk、第一次使用 sort，都曾有过这种感受。
通过前面的学习，相信你已经掌握了一些基础指令的使用方法，今天我们继续挑战一个更复杂的问题——用 Linux 指令管理一个集群。这属于 Linux 指令的高级技巧，所谓高级技巧并不是我们要学习更多的指令，而是要把之前所学的指令进行排列组合。当你从最初只能写几条指令、执行然后看结果，成长到具备书写一个拥有几十行、甚至上百行的 bash 脚本的能力时，就意味着你具备了解决复杂问题的能力。而最终的目标，是提升你对指令的熟练程度，锻炼工程能力。
本课时，我将带你朝着这个目标努力，通过把简单的指令组合起来，分层组织成最终的多个脚本文件，解决一个复杂的工程问题：在成百上千的集群中安装一个 Java 环境。接下来，请你带着这个目标，开启今天的学习。
第一步：搭建学习用的集群 第一步我们先搭建一个学习用的集群。这里简化一下模型。我在自己的电脑上装一个ubuntu桌面版的虚拟机，然后再装两个ubuntu服务器版的虚拟机。
相对于桌面版，服务器版对资源的消耗会少很多。我将教学材料中桌面版的ubuntu命名为u1，两个用来被管理的服务器版ubuntu叫作v1和v2。
用桌面版的原因是：我喜欢ubuntu漂亮的开源字体，这样会让我在给你准备素材的时候拥有一个好心情。如果你对此感兴趣，可以搜索ubuntu mono，尝试把这个字体安装到自己的文本编辑器中。不过我还是觉得在ubuntu中敲代码更有感觉。
注意，我在这里只用了 3 台服务器，但是接下来我们要写的脚本是可以在很多台服务器之间复用的。
第二步：循环遍历 IP 列表 你可以想象一个局域网中有很多服务器需要管理，它们彼此之间网络互通，我们通过一台主服务器对它们进行操作，即通过u1操作v1和v2。
在主服务器上我们维护一个ip地址的列表，保存成一个文件，如下图所示：
目前iplist中只有两项，但是如果我们有足够的机器，可以在里面放成百上千项。接下来，请你思考shell如何遍历这些ip？
你可以先尝试实现一个最简单的程序，从文件iplist中读出这些ip并尝试用for循环遍历这些ip，具体程序如下：
#!/usr/bin/bashreadarray -t ips &amp;lt; iplistfor ip in ${ips[@]}doecho $ipdone首行的#!叫作 Shebang。Linux 的程序加载器会分析 Shebang 的内容，决定执行脚本的程序。这里我们希望用bash来执行这段程序，因为我们用到的 readarray 指令是bash 4.0后才增加的能力。
readarray指令将 iplist 文件中的每一行读取到变量ips中。ips是一个数组，可以用echo ${ips[@]}打印其中全部的内容：@代表取数组中的全部内容；$符号是一个求值符号。不带$的话，ips[@]会被认为是一个字符串，而不是表达式。
for循环遍历数组中的每个ip地址，echo把地址打印到屏幕上。
如果用shell执行上面的程序会报错，因为readarray是bash 4.0后支持的能力，因此我们用chomd为foreach.sh增加执行权限，然后直接利用shebang的能力用bash执行，如下图所示：
第三步：创建集群管理账户 为了方便集群管理，通常使用统一的用户名管理集群。这个账号在所有的集群中都需要保持命名一致。比如这个集群账号的名字就叫作lagou。
接下来我们探索一下如何创建这个账户lagou，如下图所示：
上面我们创建了lagou账号，然后把lagou加入sudo分组。这样lagou就有了sudo成为root的能力，如下图所示：
接下来，我们设置lagou用户的初始化shell是bash，如下图所示：
这个时候如果使用命令su lagou，可以切换到lagou账号，但是你会发现命令行没有了颜色。因此我们可以将原来用户下面的.</description>
    </item>
    
    <item>
      <title>12 (1)加餐 练习题详解（二）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/12-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%BA%8C/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:06 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/12-1%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%BA%8C/</guid>
      <description>今天我会带你把《模块二：Linux 指令》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。
练习题详解 06 | 目录结构和文件管理指令：rm / -rf 指令的作用是？ 【问题】 搜索文件系统中所有以包含 std字符串且以.h扩展名结尾的文件。
【解析】 这道题目比较简单，大家也比较活跃，我自己只写了一种方法，没想到留言中有挺多不错的方案，那我们一起来看下。
下面是我的方案，你学完模块二的内容后，应该知道查看全部文件需要sudo，以管理员身份：
sudo find / -name &amp;quot;*std*.h&amp;quot;我在留言中看到有的同学用的是-iname，这样也是可以的，只是忽略了大小写。
也可以结合 grep 语句， 用管道实现，比如:
sudo find / -name &amp;quot;*.h&amp;quot; |grep std07 | 进程、重定向和管道指令：xargs 指令的作用是？ 【问题】 请问下面这段 Shell 程序的作用是什么？
mkfifo pipe1mkfifo pipe2echo -n run | cat - pipe1 &amp;gt; pipe2 &amp;amp;cat &amp;lt; pipe2 &amp;gt; pipe1【解析】 这个题目是我在网上看到的一个比较有趣的问题。
前 2 行代码创建了两个管道文件。
从第 3 行开始，代码变得复杂。echo -n run就是向输出流中写入一个run字符串（不带回车，所以用-n）。通过管道，将这个结果传递给了cat。cat是 concatenate 的缩写，意思是把文件粘在一起。</description>
    </item>
    
    <item>
      <title>11 高级技巧之日志分析：利用 Linux 指令分析 Web 日志</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/11-%E9%AB%98%E7%BA%A7%E6%8A%80%E5%B7%A7%E4%B9%8B%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%88%A9%E7%94%A8-linux-%E6%8C%87%E4%BB%A4%E5%88%86%E6%9E%90-web-%E6%97%A5%E5%BF%97/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:05 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/11-%E9%AB%98%E7%BA%A7%E6%8A%80%E5%B7%A7%E4%B9%8B%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%88%A9%E7%94%A8-linux-%E6%8C%87%E4%BB%A4%E5%88%86%E6%9E%90-web-%E6%97%A5%E5%BF%97/</guid>
      <description>著名的黑客、自由软件运动的先驱理查德.斯托曼说过，“编程不是科学，编程是手艺”。可见，要想真正搞好编程，除了学习理论知识，还需要在实际的工作场景中进行反复的锤炼。
所以今天我们将结合实际的工作场景，带你利用 Linux 指令分析 Web 日志，这其中包含很多小技巧，掌握了本课时的内容，将对你将来分析线上日志、了解用户行为和查找问题有非常大地帮助。
本课时将用到一个大概有 5W 多条记录的nginx日志文件，你可以在 GitHub上下载。 下面就请你和我一起，通过分析这个nginx日志文件，去锤炼我们的手艺。
第一步：能不能这样做？ 当我们想要分析一个线上文件的时候，首先要思考，能不能这样做？ 这里你可以先用htop指令看一下当前的负载。如果你的机器上没有htop，可以考虑用yum或者apt去安装。
如上图所示，我的机器上 8 个 CPU 都是 0 负载，2G的内存用了一半多，还有富余。 我们用wget将目标文件下载到本地（如果你没有 wget，可以用yum或者apt安装）。
wget 某网址（自己替代）然后我们用ls查看文件大小。发现这只是一个 7M 的文件，因此对线上的影响可以忽略不计。如果文件太大，建议你用scp指令将文件拷贝到闲置服务器再分析。下图中我使用了--block-size让ls以M为单位显示文件大小。
确定了当前机器的CPU和内存允许我进行分析后，我们就可以开始第二步操作了。
第二步：LESS 日志文件 在分析日志前，给你提个醒，记得要less一下，看看日志里面的内容。之前我们说过，尽量使用less这种不需要读取全部文件的指令，因为在线上执行cat是一件非常危险的事情，这可能导致线上服务器资源不足。
如上图所示，我们看到nginx的access_log每一行都是一次用户的访问，从左到右依次是：
 IP 地址； 时间； HTTP 请求的方法、路径和协议版本、返回的状态码； User Agent。  第三步：PV 分析 PV（Page View），用户每访问一个页面就是一次Page View。对于nginx的acess_log来说，分析 PV 非常简单，我们直接使用wc -l就可以看到整体的PV。
如上图所示：我们看到了一共有 51462 条 PV。
第四步：PV 分组 通常一个日志中可能有几天的 PV，为了得到更加直观的数据，有时候需要按天进行分组。为了简化这个问题，我们先来看看日志中都有哪些天的日志。
使用awk &#39;{print $4}&#39; access.log | less可以看到如下结果。awk是一个处理文本的领域专有语言。这里就牵扯到领域专有语言这个概念，英文是Domain Specific Language。领域专有语言，就是为了处理某个领域专门设计的语言。比如awk是用来分析处理文本的DSL，html是专门用来描述网页的DSL，SQL是专门用来查询数据的DSL……大家还可以根据自己的业务设计某种针对业务的DSL。
你可以看到我们用$4代表文本的第 4 列，也就是时间所在的这一列，如下图所示：
我们想要按天统计，可以利用 awk提供的字符串截取的能力。</description>
    </item>
    
    <item>
      <title>10 软件的安装： 编译安装和包管理器安装有什么优势和劣势？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/10-%E8%BD%AF%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E5%92%8C%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8%E5%AE%89%E8%A3%85%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8A%BF%E5%92%8C%E5%8A%A3%E5%8A%BF/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:04 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/10-%E8%BD%AF%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E5%92%8C%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8%E5%AE%89%E8%A3%85%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8A%BF%E5%92%8C%E5%8A%A3%E5%8A%BF/</guid>
      <description>今天给你带来的面试题是：编译安装和包管理器安装有什么优势和劣势？为了搞清楚这个问题，就引出了今天的话题，在 Linux 上如何安装程序。
在 Linux 上安装程序大概有 2 种思路：
 直接编译源代码； 使用包管理器。  受开源运动影响，Linux 上很多软件都可以拿到源代码，这也是 Linux 能取得成功的一个重要原因。接下来我们先尝试用包管理器安装应用，然后再用一个实战的例子，教你如何编译安装nginx。
包管理器使用 Linux 下的应用程序多数以软件包的形式发布，用户拿到对应的包之后，使用包管理器进行安装。说到包管理器，就要提到dpkg和rpm。
我们先说说包。 Linux 下两大主流的包就是rpm和dpkg。
dpkg（debian package），是linux一个主流的社区分支开发出来的。社区就是开源社区，有很多世界顶级的程序员会在社区贡献代码，比如 github。一般衍生于debian的 Linux 版本都支持dpkg，比如ubuntu。
rpm（redhatpackage manager）。在正式讲解之前，我们先来聊聊 RedHat 这家公司。
RedHat 是一个做 Linux 的公司，你可以把它理解成一家“保险公司”。 很多公司购买红帽的服务，是为了给自己的业务上一个保险。以防万一哪天公司内部搞不定 Linux 底层，或者底层有 Bug，再或者底层不适合当下的业务发展，需要修改等问题，红帽的工程师都可以帮企业解决。
再比如，RedHat 收购了JBoss，把 JBoss 改名为 WildFly。 像 WildFly 这种工具更多是面向企业级，比如没有大量研发团队的企业会更倾向使用成熟的技术。RedHat 公司也有自己的 Linux，就叫作 RedHat。RedHat 系比较重要的 Linux 有 RedHat/Fedora 等。
无论是dpkg还是rpm都抽象了自己的包格式，就是以.dpkg或者.rpm结尾的文件。
dpkg和rpm也都提供了类似的能力：
 查询是否已经安装了某个软件包； 查询目前安装了什么软件包； 给定一个软件包，进行安装； 删除一个安装好的软件包。  关于dpkg和rpm的具体用法，你可以用man进行学习。接下来我们聊聊yum和apt。
自动依赖管理 Linux 是一个开源生态，因此工具非常多。工具在给用户使用之前，需要先打成dpkg或者rpm包。 有的时候一个包会依赖很多其他的包，而dpkg和rpm不会对这种情况进行管理，有时候为了装一个包需要先装十几个依赖的包，过程非常艰辛！因此现在多数情况都在用yum和apt。
yum
你可能会说，我不用yum也不用apt，我只用docker。首先给你一个连击 666，然后我还是要告诉你，如果你做docker镜像，那么还是要用到yum和apt，因此还是有必要学一下。</description>
    </item>
    
    <item>
      <title>09 Linux 中的网络指令：如何查看一个域名有哪些 NS 记录？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/09-linux-%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E6%8C%87%E4%BB%A4%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E4%B8%80%E4%B8%AA%E5%9F%9F%E5%90%8D%E6%9C%89%E5%93%AA%E4%BA%9B-ns-%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:03 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/09-linux-%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E6%8C%87%E4%BB%A4%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E4%B8%80%E4%B8%AA%E5%9F%9F%E5%90%8D%E6%9C%89%E5%93%AA%E4%BA%9B-ns-%E8%AE%B0%E5%BD%95/</guid>
      <description>我看到过一道关于 Linux 指令的面试题：如何查看一个域名有哪些 NS 记录？
这类题目是根据一个场景，考察一件具体的事情如何处理。虽然你可以通过查资料找到解决方案，但是，这类问题在面试中还是有必要穿插一下，用于确定求职者技能是否熟练、经验是否丰富。特别是计算机网络相关的指令，平时在远程操作、开发、联调、Debug 线上问题的时候，会经常用到。
Linux 中提供了不少网络相关的指令，因为网络指令比较分散，本课时会从下面几个维度给你介绍，帮助你梳理常用的网络指令：
 远程操作； 查看本地网络状态； 网络测试； DNS 查询； HTTP。  这块知识从体系上属于 Linux 指令，同时也关联了很多计算机网络的知识，比如说 TCP/IP 协议、UDP 协议，我会在“模块七”为你简要介绍。
如果你对这部分指令背后的网络原理有什么困惑，可以在评论区提问。另外，你也可以关注我将在拉勾教育推出的《计算机网络》课程。下面我们开始学习今天的内容。
远程操作指令 远程操作指令用得最多的是ssh，ssh指令允许远程登录到目标计算机并进行远程操作和管理。还有一个比较常用的远程指令是scp，scp帮助我们远程传送文件。
ssh（Secure Shell） 有一种场景需要远程登录一个 Linux 系统，这时我们会用到ssh指令。比如你想远程登录一台机器，可以使用ssh user@ip的方式，如下图所示：
上图中，我在使用ssh指令从机器u1登录我的另一台虚拟机u2。这里u1和u2对应着 IP 地址，是我在/etc/hosts中设置的，如下图所示：
/etc/hosts这个文件可以设置 IP 地址对应的域名。我这里是一个小集群，总共有两台机器，因此我设置了方便记忆和操作的名字。
scp 另一种场景是我需要拷贝一个文件到远程，这时可以使用scp指令，如下图，我使用scp指令将本地计算机的一个文件拷贝到了 ubuntu 虚拟机用户的家目录中。
比如从u1拷贝家目录下的文件a.txt到u2。家目录有一个简写，就是用~。具体指令见下图：
输入 scp 指令之后会弹出一个提示，要求输入密码，系统验证通过后文件会被成功拷贝。
查看本地网络状态 如果你想要了解本地的网络状态，比较常用的网络指令是ifconfig和netstat。
ifconfig 当你想知道本地ip以及本地有哪些网络接口时，就可以使用ifconfig指令。你可以把一个网络接口理解成一个网卡，有时候虚拟机会装虚拟网卡，虚拟网卡是用软件模拟的网卡。
比如：VMware 为每个虚拟机创造一个虚拟网卡，通过虚拟网卡接入虚拟网络。当然物理机也可以接入虚拟网络，它可以通过虚拟网络向虚拟机的虚拟网卡上发送信息。
下图是我的 ubuntu 虚拟机用 ifconfig 查看网络接口信息。
可以看到我的这台 ubuntu 虚拟机一共有 2 个网卡，ens33 和 lo。lo是本地回路（local lookback），发送给lo就相当于发送给本机。ens33是一块连接着真实网络的虚拟网卡。
netstat 另一个查看网络状态的场景是想看目前本机的网络使用情况，这个时候可以用netstat。
默认行为
不传任何参数的netstat帮助查询所有的本地 socket，下图是netstat | less的结果。</description>
    </item>
    
    <item>
      <title>08 用户和权限管理指令： 请简述 Linux 权限划分的原则？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/08-%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%8C%87%E4%BB%A4-%E8%AF%B7%E7%AE%80%E8%BF%B0-linux-%E6%9D%83%E9%99%90%E5%88%92%E5%88%86%E7%9A%84%E5%8E%9F%E5%88%99/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:02 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/08-%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%8C%87%E4%BB%A4-%E8%AF%B7%E7%AE%80%E8%BF%B0-linux-%E6%9D%83%E9%99%90%E5%88%92%E5%88%86%E7%9A%84%E5%8E%9F%E5%88%99/</guid>
      <description>我看到过这样一道面试题：请简述 Linux 权限划分的原则？
这种类型的面试题也是我比较喜欢的一种题目，因为它考察的不仅是一个具体的指令，还考察了候选人技术层面的认知。
如果你对 Linux 权限有较深的认知和理解，那么完全可以通过查资料去完成具体指令的执行。更重要的是，认知清晰的程序员可以把 Linux 权限管理的知识迁移到其他的系统设计中。而且我认为，能够对某个技术形成认知的人， 同样也会热爱思考，善于总结，这样的程序员是所有团队梦寐以求的。
因此，这次我们就把这道面试题作为引子，开启今天的学习。
权限抽象 一个完整的权限管理体系，要有合理的抽象。这里就包括对用户、进程、文件、内存、系统调用等抽象。下面我将带你一一了解。
首先，我们先来说说用户和组。Linux 是一个多用户平台，允许多个用户同时登录系统工作。Linux 将用户抽象成了账户，账户可以登录系统，比如通过输入登录名 + 密码的方式登录；也可以通过证书的方式登录。
但为了方便分配每个用户的权限，Linux 还支持组 （Group）账户。组账户是多个账户的集合，组可以为成员们分配某一类权限。每个用户可以在多个组，这样就可以利用组给用户快速分配权限。
组的概念有点像微信群。一个用户可以在多个群中。比如某个组中分配了 10 个目录的权限，那么新建用户的时候可以将这个用户增加到这个组中，这样新增的用户就不必再去一个个目录分配权限。
而每一个微信群都有一个群主，Root 账户也叫作超级管理员，就相当于微信群主，它对系统有着完全的掌控。一个超级管理员可以使用系统提供的全部能力。
此外，Linux 还对文件进行了权限抽象（注意目录也是一种文件）。Linux 中一个文件可以设置下面 3 种权限：
 读权限（r）：控制读取文件。 写权限（w）：控制写入文件。 执行权限（x）：控制将文件执行，比如脚本、应用程序等。  然后每个文件又可以从 3 个维度去配置上述的 3 种权限：
 用户维度。每个文件可以所属 1 个用户，用户维度配置的 rwx 在用户维度生效； 组维度。每个文件可以所属 1 个分组，组维度配置的 rwx 在组维度生效； 全部用户维度。设置对所有用户的权限。  因此 Linux 中文件的权限可以用 9 个字符，3 组rwx描述：第一组是用户权限，第二组是组权限，第三组是所有用户的权限。然后用-代表没有权限。比如rwxrwxrwx代表所有维度可以读写执行。rw--wxr-x代表用户维度不可以执行，组维度不可以读取，所有用户维度不可以写入。
通常情况下，如果用ls -l查看一个文件的权限，会有 10 个字符，这是因为第一个字符代表的是文件类型。我们在 06 课时讲解“几种常见的文件类型”时提到过，有管道文件、目录文件、链接文件等等。-代表普通文件、d代表目录、p代表管道。
学习了这套机制之后，请你跟着我的节奏一起思考以下 4 个问题。
 文件被创建后，初始的权限如何设置？ 需要全部用户都可以执行的指令，比如ls，它们的权限如何分配？ 给一个文本文件分配了可执行权限会怎么样？ 可不可以多个用户都登录root，然后只用root账户？  你可以把以上 4 个问题作为本课时的小测验，把你的思考或者答案写在留言区，然后再来看我接下来的分析。</description>
    </item>
    
    <item>
      <title>07 进程、重定向和管道指令：xargs 指令的作用是？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/07-%E8%BF%9B%E7%A8%8B%E9%87%8D%E5%AE%9A%E5%90%91%E5%92%8C%E7%AE%A1%E9%81%93%E6%8C%87%E4%BB%A4xargs-%E6%8C%87%E4%BB%A4%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:01 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/07-%E8%BF%9B%E7%A8%8B%E9%87%8D%E5%AE%9A%E5%90%91%E5%92%8C%E7%AE%A1%E9%81%93%E6%8C%87%E4%BB%A4xargs-%E6%8C%87%E4%BB%A4%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF/</guid>
      <description>在面试中，我们经常会遇到面试官询问 Linux 指令，06 课时中讲到的rm -rf /属于比较简单的题目，相当于小学难度。这节课给你带来一道初中难度的题目：xargs指令的作用是什么？
通常这个指令是和管道一起使用，因此就引出了这节课的主题：管道。为了理解管道，和学习管道相关的内容，还有一些概念需要你理解，比如：进程、标准流和重定向。好的，接下来请和我一起，把这块知识一网打尽！
进程 为了弄清楚这节课程的内容，也就是管道，我们先来讨论一下进程。
我们知道，应用的可执行文件是放在文件系统里，把可执行文件启动，就会在操作系统里（具体来说是内存中）形成一个应用的副本，这个副本就是进程。
插一个小知识，以后你再遇到面试题：什么是进程？
可以回答：进程是应用的执行副本；而不要回答进程是操作系统分配资源的最小单位。前者是定义，后者是作用*。*
ps
如果你要看当前的进程，可以用ps指令。p 代表 processes，也就是进程；s 代表 snapshot，也就是快照。所谓快照，就是像拍照一样。
如上图所示，我启动了两个进程，ps和bash。ps 就是我刚刚启动的，被ps自己捕捉到了；bash是因为我开了这个控制台，执行的shell是bash。
当然操作系统也不可能只有这么几个进程，这是因为不带任何参数的ps指令显示的是同一个电传打字机（TTY上）的进程。TTY 这个概念是一个历史的概念，过去用来传递信息，现在已经被传真、邮件、微信等取代。
操作系统上的 TTY 是一个输入输出终端的概念，比如用户打开 bash，操作系统就为用户分配了一个输入输出终端。没有加任何参数的ps只显示在同一个 TTY 的进程。
如果想看到所有的进程，可以用ps -e，-e没有特殊含义，只是为了和-A区分开。我们通常不直接用ps -e而是用ps -ef，这是因为-f可以带上更多的描述字段，如下图所示：
 UID 指进程的所有者； PID 是进程的唯一标识； PPID 是进程的父进程 ID； C 是 CPU 的利用率（就是 CPU 占用）； STIME 是开始时间； TTY 是进程所在的 TTY，如果没有 TTY 就是 ？号； TIME； CMD 是进程启动时的命令，如果不是一个 Shell 命令，而是用方括号括起来，那就是系统进程或者内核过程。  另外一个用得比较多的是ps aux，它和ps -ef能力差不多，但是是 BSD 风格的。就是加州伯克利分校研发的 Unix 分支版本的衍生风格，这种风格其实不太好描述，我截了一张图，你可以体会一下：
在 BSD 风格中有些字段的叫法和含义变了，如果你感兴趣，可以作为课后延伸学习的内容。</description>
    </item>
    
    <item>
      <title>06 目录结构和文件管理指令：rm -rf 指令的作用是？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/06-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E6%8C%87%E4%BB%A4rm-rf-%E6%8C%87%E4%BB%A4%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF/</link>
      <pubDate>Wed, 22 Dec 2021 01:49:00 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/06-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E6%8C%87%E4%BB%A4rm-rf-%E6%8C%87%E4%BB%A4%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF/</guid>
      <description>通过模块一的学习，你应该掌握了计算机组成原理的重点知识，到了模块二，我们开始学习 Linux 指令，它是操作系统的前端，学好这部分内容一方面可以帮助你应对工作场景，另一方面可以让你在学习操作系统底层知识前，对 Linux 有一个大概的了解。
接下来，我们依然通过一道常见的高频面试题，引出今天的主要内容。面试题如下：请你说说rm / -rf的作用？
相信 90% 的同学是知道这个指令的。这里先预警一下，你千万不要轻易在服务器上尝试。要想知道这条指令是做什么的，能够帮助我们解决哪些问题，那就请你认真学习今天的内容。在本课时的最后我会公布这道题目的分析过程和答案。
什么是 Shell 在我们学习 Linux 指令之前，先来说一下什么是 Shell？Shell 把我们输入的指令，传递给操作系统去执行，所以 Shell 是一个命令行的用户界面。
早期程序员没有图形界面用，就用 Shell。而且图形界面制作成本较高，不能实现所有功能，因此今天的程序员依然在用 Shell。
你平时还经常会看到一个词叫作bash（Bourne Again Shell），它是用 Shell 组成的程序。这里的 Bourne 是一个人名，Steve Bourne 是 bash 的发明者。
我们今天学习的所有指令，不是写死在操作系统中的，而是一个个程序。比如rm指令，你可以用which指令查看它所在的目录。如下图所示，你会发现rm指令在/usr/bin/rm目录中。
如上图所示，ramroll是我的英文名字，ubuntu 是我这台机器的名字。我输入了which rm，然后获得了/usr/bin/rm的结果，最终执行这条指令的是操作系统，连接我和操作系统的程序就是 Shell。
Linux 对文件目录操作的指令就工作在 Shell 上，接下来我们讲讲文件目录操作指令。
Linux 对文件目录的抽象 Linux 对文件进行了一个树状的抽象。/代表根目录，每一节目录也用/分开，所以在上图所展示的/usr/bin/rm中，第一级目录是/根目录，第二级目录是usr目录，第三级是bin目录。最后的rm是一个文件。
路径（path） 像/usr/bin/rm称为可执行文件rm的路径。路径就是一个文件在文件系统中的地址。如果文件系统是树形结构，那么通常一个文件只有一个地址（路径）。
目标文件的绝对路径（Absolute path），也叫作完全路径（full path），是从/开始，接下来每一层都是一级子目录，直到定位到目标文件为止。
如上图所示的例子中，/usr/bin/rm就是一个绝对路径。
工作目录 为了方便你工作，Shell 还抽象出了工作目录。当用户打开 Shell 的时候，Shell 就会给用户安排一个工作目录。因此也就产生了相对路径。
相对路径（Relative path）是以工作目录为基点的路径。比如：
 当用户在/usr目录下的时候，rm文件的相对路径就是bin/rm； 如果用户在/usr/bin目录下的时候，rm文件的路径就是./rm或者rm，这里用.代表当前目录； 如果用户在/usr/bin/somedir下，那么rm的相对路径就是../rm，这里用..代表上一级目录。  我们使用cd（change directory）指令切换工作目录，既可以用绝对路径，也可以用相对路径。 这里我要强调几个注意事项：
 输入cd，不带任何参数会切换到用户的家目录，Linux 中通常是/home/{用户名}。以我自己为例，我的家目录是/home/ramroll； 输入cd .</description>
    </item>
    
    <item>
      <title>05 存储器分级：L1 Cache 比内存和 SSD 快多少倍？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/05-%E5%AD%98%E5%82%A8%E5%99%A8%E5%88%86%E7%BA%A7l1-cache-%E6%AF%94%E5%86%85%E5%AD%98%E5%92%8C-ssd-%E5%BF%AB%E5%A4%9A%E5%B0%91%E5%80%8D/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:59 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/05-%E5%AD%98%E5%82%A8%E5%99%A8%E5%88%86%E7%BA%A7l1-cache-%E6%AF%94%E5%86%85%E5%AD%98%E5%92%8C-ssd-%E5%BF%AB%E5%A4%9A%E5%B0%91%E5%80%8D/</guid>
      <description>近两年我在面试求职者的时候，喜欢问这样一道面试题：SSD、内存和 L1 Cache 相比速度差多少倍？
其实比起复杂的技术问题，我更喜欢在面试中提问这种像生活常识一样的简单问题。因为我觉得，复杂的问题是由简单的问题组成的，如果你把简单的问题学扎实了，那么复杂问题也是可以自己推导的。
如果你不知道 L1 Cache，可能会错误地判断内存执行速度。我们写程序，会用寄存器、内存以及硬盘，所以按照墨菲定律，如果这里有一个认知是错误的，那么最终的结果就会产生问题。
下面，回到我们今天的问题，这个问题关联的知识点是存储器分级策略。接下来，请你带着问题开始学习今天的内容。
为什么会有存储器分级策略？ 要想弄清楚存储器分级策略。
首先，你要弄清楚，“我们希望存储器是什么样子的”，也就是“我们的需求是什么”？
然后，你要弄清楚，我们的需求有哪些“实现约束”。
从需求上讲，我们希望存储器速度快、体积小、空间大、能耗低、散热好、断电数据不丢失。但在现实中，我们往往无法把所有需求都实现。
下面我们举几个例子，带你深入体会一下，比如：
 如果一个存储器的体积小，那它存储空间就会受到制约。 如果一个存储器电子元件密度很大，那散热就会有问题。因为电子元件都会产生热能，所以电子元件非常集中的 CPU，就需要单独的风扇或者水冷帮助电子元件降温。 如果一个存储器离 CPU 较远，那么在传输过程中必然会有延迟，因此传输速度也会下降。  这里你可能会有疑问，因为在大多数人的认知里，光速是很快的，而信号又是以光速传输的。既然光速这么快，那信号的延迟应该很小才对。但事实并不是这样，比如时钟信号是 1GHz 的 CPU，1G 代表 10 个亿，因此时钟信号的一个周期是 1/10 亿秒。而光的速度是 3×10 的 8 次方米每秒，就是 3 亿米每秒。所以在一个周期内，光只能前进 30 厘米。
你看！虽然在宏观世界里光速非常快，但是到计算机世界里，光速并没有像我们认知中的那么快。所以即使元件离 CPU 的距离稍微远了一点，运行速度也会下降得非常明显。
你可能还会问，那干吗不把内存放到 CPU 里？
如果你这么做的话，除了整个电路散热和体积会出现问题，服务器也没有办法做定制内存了。也就是说 CPU 在出厂时就决定了它的内存大小，如果你想换更大的内存，就要换 CPU，而组装定制化是你非常重要的诉求，这肯定是不能接受的。
此外，在相同价格下，一个存储器的速度越快，那么它的能耗通常越高。能耗越高，发热量越大。
因此，我们上面提到的需求是不可能被全部满足的，除非将来哪天存储技术有颠覆性的突破。
存储器分级策略 既然我们不能用一块存储器来解决所有的需求，那就必须把需求分级。
一种可行的方案，就是根据数据的使用频率使用不同的存储器：高频使用的数据，读写越快越好，因此用最贵的材料，放到离 CPU 最近的位置；使用频率越低的数据，我们放到离 CPU 越远的位置，用越便宜的材料。
具体来说，通常我们把存储器分成这么几个级别：
 寄存器； L1-Cache； L2-Cache； L3-Cahce； 内存； 硬盘/SSD。  寄存器（Register） 寄存器紧挨着 CPU 的控制单元和逻辑计算单元，它所使用的材料速度也是最快的。就像我们前面讲到的，存储器的速度越快、能耗越高、产热越大，而且花费也是最贵的，因此数量不能很多。</description>
    </item>
    
    <item>
      <title>05 (1) 加餐 练习题详解（一）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/05-1-%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%B8%80/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:58 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/05-1-%E5%8A%A0%E9%A4%90-%E7%BB%83%E4%B9%A0%E9%A2%98%E8%AF%A6%E8%A7%A3%E4%B8%80/</guid>
      <description>今天我会带你把《模块一：计算机组成原理》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。
练习题详解 01 | 计算机是什么：“如何把程序写好”这个问题是可计算的吗？ 【问题】 可不可以构造一段程序证明停机问题无解?如果可以，请用自己熟悉的语言写出这段程序。
【解析】拿到这道题，我们可以先从问题的抽象入手。
 判断一段程序是否会停机的方法可以抽象成一个函数。 一段程序，也可以抽象成一个函数。  因此，问题可以转换为：存不存在一个通用函数判断另一个函数是否会停止？
接下来，再来构造冲突。
假设存在一个函数 willStop，它只有一个参数 func，willStop 可以判断任意函数 func 是否会停止：
 如果会停止，返回 true； 如果不会停止返回 false。  willStop 具体如何实现我们无法给出，这里只是做一个假设。
func willStop(func){//...}下面我们构造一组冲突，构造一个叫作wrappedWillStop函数，它调用willStop构造冲突。
function wrappedWillStop(){if( willStop(wrappedWillStop) ) {while(true){}} else {return}}wrappedWillStop()wrapped版本构造冲突方法如下：调用willStop并把自己传进去。如果willStop认为wrapped会停止，那么就执行一个死循环。 如果willStop认为wrapped不会停止，就直接返回。
通过上述的方法，我们就知道willStop这样的函数肯定是无法被实现的；也就是停机问题无解。
03 | 程序的执行：相比 32 位 64 位的优势是什么？ 【问题】 CPU 中有没有求对数的指令？如果没有那么程序如何去计算？
【解析】 CPU 中求一个数字的 2 倍，可以通过左移指令。比如 10 代表数字 2，左移 1 位变成 100 就代表数字 4。CPU 提供了乘法指令，所以如果求一个数字的幂，比如 33，可以拿 3*3 再乘以 3，需要计算 2 次。</description>
    </item>
    
    <item>
      <title>04 构造复杂的程序：将一个递归函数转成非递归函数的通用方法</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/04-%E6%9E%84%E9%80%A0%E5%A4%8D%E6%9D%82%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%B0%86%E4%B8%80%E4%B8%AA%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%E8%BD%AC%E6%88%90%E9%9D%9E%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%E7%9A%84%E9%80%9A%E7%94%A8%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:57 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/04-%E6%9E%84%E9%80%A0%E5%A4%8D%E6%9D%82%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%B0%86%E4%B8%80%E4%B8%AA%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%E8%BD%AC%E6%88%90%E9%9D%9E%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%E7%9A%84%E9%80%9A%E7%94%A8%E6%96%B9%E6%B3%95/</guid>
      <description>我看到过一道非常不错的面试题：不支持递归的程序语言如何实现递归程序？
之所以说这道题好，是因为：
 首先，它不是纯粹考概念和死记硬背，求职者在回答问题之前需要进行一定的思考； 其次，这道题目可以继续深挖，比如可以让求职者具体写一个程序，就变成了一道编程题； 最后，这道题目有实战意义，它背后考察的是求职者的编程功底。  为了弄清楚这道题目，你需要对程序有一个更深层次的认识，不仅仅停留在指令的执行层面，而是要灵活使用指令，去实现更加复杂的功能。
for 循环如何被执行 首先，我们来看 for 循环是如何实现的。
下面是一个求 1 加到 100 的 Java 程序，请你思考如何将它转换为指令：
var i = 1, s = 0;for(; i &amp;lt;= 100; i++) {s+=i;}指令是简单的，像积木一样，程序是复杂的，像房子一样。我们将简单的事情组合，然后去完成复杂的事情，这就是程序员每天在做的。在这个过程中，你会产生思考，比如如何排列组合，如何搭积木，才能更快更准地完成项目？所以这也是训练思维的一个过程。
经过思考，如果按照顺序执行上面的程序，则需要很多指令，因为 for 循环可以执行 1 次，也可以执行 100W 次，还可以执行无数次。因此，指令的设计者提供了一种 jump 类型的指令，让你可以在程序间跳跃，比如:
loop:jump loop这就实现了一个无限循环，程序执行到 jumploop 的时候，就会跳回 loop 标签。
用这种方法，我们可以将 for 循环用底层的指令实现：
# var i = 1, s = 0# 对应 Java 代码，我们首先将 1 和 0 存储到两个地址# 这两个地址我们用 $i 和 $s 表示store #1 -&amp;gt; $i // 将数字 1 存入i的地址store #0 -&amp;gt; $s // 将数字 0 存入 s 的地址# 接下来循环要开始了，我们在这里预留一个 loop 标签# loop 是一个自定义标签，它代表指令的相对位置# 后续我们可以用 jump 指令跳转回这个位置实现循环loop: # 循环标签# for .</description>
    </item>
    
    <item>
      <title>03 程序的执行：相比 32 位，64 位的优势是什么？（下）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/03-%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E7%9B%B8%E6%AF%94-32-%E4%BD%8D64-%E4%BD%8D%E7%9A%84%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%8B/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:56 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/03-%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E7%9B%B8%E6%AF%94-32-%E4%BD%8D64-%E4%BD%8D%E7%9A%84%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%8B/</guid>
      <description>在 02 课时中我们学习了计算机的组成原理，还分析了一些你在工作中可能会遇到的问题。本课时，我们继续深入学习程序执行部分，进一步讨论程序在冯诺依曼模型上如何执行。
程序的执行过程 当 CPU 执行程序的时候：
1.首先，CPU 读取 PC 指针指向的指令，将它导入指令寄存器。具体来说，完成读取指令这件事情有 3 个步骤：
步骤 1：CPU 的控制单元操作地址总线指定需要访问的内存地址（简单理解，就是把 PC 指针中的值拷贝到地址总线中）。
步骤 2：CPU 通知内存设备准备数据（内存设备准备好了，就通过数据总线将数据传送给 CPU）。
步骤 3：CPU 收到内存传来的数据后，将这个数据存入指令寄存器。
完成以上 3 步，CPU 成功读取了 PC 指针指向指令，存入了指令寄存器。
2.然后，CPU 分析指令寄存器中的指令，确定指令的类型和参数。 3.如果是计算类型的指令，那么就交给逻辑运算单元计算；如果是存储类型的指令，那么由控制单元执行。 4.PC 指针自增，并准备获取下一条指令。
 比如在 32 位的机器上，指令是 32 位 4 个字节，需要 4 个内存地址存储，因此 PC 指针会自增 4。
 了解了程序的执行过程后，我还有一些问题想和大家一起讨论：
 内存虽然是一个随机存取器，但是我们通常不会把指令和数据存在一起，这是为了安全起见。具体的原因我会在模块四进程部分展开讲解，欢迎大家在本课时的留言区讨论起来，我会结合你们留言的内容做后续的课程设计。 程序指针也是一个寄存器，64 位的 CPU 会提供 64 位的寄存器，这样就可以使用更多内存地址。特别要说明的是，64 位的寄存器可以寻址的范围非常大，但是也会受到地址总线条数的限制。比如和 64 位 CPU 配套工作的地址总线只有 40 条，那么可以寻址的范围就只有 1T，也就是 240。 从 PC 指针读取指令、到执行、再到下一条指令，构成了一个循环，这个不断循环的过程叫作CPU 的指令周期，下面我们会详细讲解这个概念。  详解 a = 11 + 15 的执行过程 上面我们了解了基本的程序执行过程，接下来我们来看看如果用冯诺依曼模型执行a=11+15是一个怎样的过程。</description>
    </item>
    
    <item>
      <title>02 程序的执行：相比 32 位，64 位的优势是什么？（上）</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/02-%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E7%9B%B8%E6%AF%94-32-%E4%BD%8D64-%E4%BD%8D%E7%9A%84%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%8A/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:55 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/02-%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E7%9B%B8%E6%AF%94-32-%E4%BD%8D64-%E4%BD%8D%E7%9A%84%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%8A/</guid>
      <description>本节课给你讲学习操作系统之前的一个前置知识：程序是如何执行的？
我们先来看一道常规的面试题：相比 32 位，64 位的优势是什么？
面试官考察这种类型的问题，主要是想看求职者是否有扎实的计算机基础，同时想知道求职者在工作中是否充满好奇，会主动学习、寻根问底，毕竟 32、64 位是经常出现在程序员视野的词汇，常见的东西都弄明白了，那说明这个人学习能力强。
其实 ，面试官在这里给你挖了一个陷阱，因为他没有说清楚 32、64 位指的是操作系统、是软件、还是 CPU？
 如果是软件，那么我们的数据库有 32 位和 64 位版本； 如果是操作系统，那么在阿里云上选择 Centos 和 Debian 版本的时候，也会有 32/64 版本； 如果是 CPU，那么有 32 位 CPU，也有 64 位 CPU。  接下来请你带着问题开始今天的课程学习，本课时的重点是带你学懂程序执行的原理。
图灵机的构造 想要学懂程序执行的原理，就要从图灵机说起了。它在计算机科学方面有两个巨大的贡献：
第一，它清楚地定义了计算机能力的边界，也就是可计算理论；
第二，它定义了计算机由哪些部分组成，程序又是如何执行的。
我们先来看一看图灵机的内部构造：
 图灵机拥有一条无限长的纸带，纸带上是一个格子挨着一个格子，格子中可以写字符，你可以把纸带看作内存，而这些字符可以看作是内存中的数据或者程序。 图灵机有一个读写头，读写头可以读取任意格子上的字符，也可以改写任意格子的字符。 读写头上面的盒子里是一些精密的零件，包括图灵机的存储、控制单元和运算单元。  图灵机如何执行程序 下面我们来举一个例子，让大家弄清楚图灵机是如何工作的，比如我们要计算 11 + 15 的值，具体的运算步骤如下：
 首先，我们将“11、15、+” 分别写入纸带上的 3 个格子（现在纸带上的字符串是11、15、 +)，然后将读写头先停在 11 对应的格子上。   接下来，图灵机通过读写头读入 11 到它的存储设备中（这个存储设备也叫作图灵机的状态）。图灵机没有说读写头为什么可以识别纸带上的字符，而是假定读写头可以做到这点。   然后读写头向右移动一个格，用同样的方法将 15 读入图灵机的状态中。现在图灵机的状态中有两个连续的数字，11 和 15。   接下来重复上面的过程，会读到一个+号。下面我详细说一下这个运算流程：  读写头读到一个 + 号 ； 然后将 + 号传输给控制单元 ； 控制单元发现是一个 + 号，所以没有存入状态中。因为 + 号是一个我们预设的控制符（指令），它的作用是加和目前状态。因此，控制单元识别出是控制符，并通知运算单元工作； 运算单元从状态中读入 11、15 并进行计算，将结果 26 存储到状态； 运算单元将结果回传给控制单元； 控制单元将结果传输给读写头。     读写头向右移动，将结果 26 写入纸带。  这样，我们就通过图灵机计算出了 11+15 的值。不知道你有没有发现，图灵机构造的这一台机器，主要功能就是读写纸带然后计算；纸带中有数据、也有控制字符（也就是指令），这个设计和我们今天的计算机是一样的。</description>
    </item>
    
    <item>
      <title>01 计算机是什么：“如何把程序写好”这个问题是可计算的吗？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%98%AF%E4%BB%80%E4%B9%88%E5%A6%82%E4%BD%95%E6%8A%8A%E7%A8%8B%E5%BA%8F%E5%86%99%E5%A5%BD%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E6%98%AF%E5%8F%AF%E8%AE%A1%E7%AE%97%E7%9A%84%E5%90%97/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:54 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%98%AF%E4%BB%80%E4%B9%88%E5%A6%82%E4%BD%95%E6%8A%8A%E7%A8%8B%E5%BA%8F%E5%86%99%E5%A5%BD%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E6%98%AF%E5%8F%AF%E8%AE%A1%E7%AE%97%E7%9A%84%E5%90%97/</guid>
      <description>我记得自己在面试中遇到过这样一个问题：“可不可以计算一个人程序写得好不好？”
当时我也没有想明白“计算”这个词是什么意思。但事后分析来看，“计算”不就是写程序吗？
其实简单理解这个问题就是“可不可以用机器来判断人的程序写得好不好？”如果从这个角度考虑，我是可以和面试官论述一番的。
后面我查阅了资料，历史上有一个对计算机领域影响颇深的可计算理论，面试官说的“计算”应该就来源于这里。其实继续深挖还能找出很多涉及计算机本源的有趣的知识，比如图灵机、冯诺依曼模型；再比如说 CPU 的构成、程序如何执行、缓存的分级、总线的作用等。
上面提到的这些内容其实都属于操作系统的前置课程，我会利用第一章 4 个课时和大家探讨一下计算机组成原理，然后我们再正式进入操作系统的学习。其实学习就是这样，追溯源头，回到本质，才能挖掘兴趣、激发思考，否则就变成了死记硬背。接下来我们将从计算能源的角度入手，来展开今天的课程学习。
芯片：计算能源 我们知道第一次工业革命出现了蒸汽机，能源是煤炭。第二次工业革命出现了发电机，能源是电。20 世纪四五十年代，又发生了第三次科技革命，革命产物是计算机。而第四次科技革命，就发生在当下，出现了人工智能，能源是数据。
说到这里，你可能会有个疑问：第三次科技革命的能源是什么呢？
你的第一反应可能是电，但是细想又觉得不对。前两次工业革命都有带来能源变革，为什么第三次科技革命就没有了能源变革？其实，第三次科技革命的能源是一种数字能量，本质是计算。
下面我们来看一看这种数字能量是如何产生的。电能供给给芯片，芯片中的一种电子元件晶振（也就是石英晶体）通电后产生震荡，震荡会产生频率稳定的脉冲信号。通常这是一种高频的脉冲信号，每秒可达百万次。然后，我们通过谐振效应发放这个信号，形成方波。再通过电子元件调整这种脉冲的频率，把脉冲信号转换为我们需要的频率，这就形成了驱动芯片工作的时钟信号。这种信号的频率，我们也称作芯片的时钟频率。最后，时钟信号驱动着芯片工作，就像人体的脉搏一样，每一次脉冲到来，都让芯片的状态发生一次变化，用这种方法，最终存储器中的指令被一行行执行。指令被执行，其实就是数据被计算，这就是我说的计算能量。
芯片普及后，不仅给计算机和手机提供支持，它们还被安装到了航天设备、能源设备、医疗设备及通信设备中，甚至小到电灯、微波炉、咖啡机、热水器里面都有了芯片。有了芯片，设备通电后才可以计算，有了计算，这些设备才能够实现更加复杂而精确的功能。
摩尔定律：计算能力的发展 值得一提的是，历史上是先有计算机，后有的芯片。世界上第一个芯片，也被称作集成电路， 1958 年由美国德州仪器公司的工程师杰克·基尔比发明。而世界上第一台通用计算机 ENIAC 则是在 1946 年诞生于美国陆军弹道研究实验室。
看到这里你可能会有疑问，为什么是先发明计算机再发明芯片呢？
其实，这个道理就好比很多程序员先实现产品功能，再考虑封装和复用。ENIAC 中负责计算的模块和后来的芯片原理是一样的，都是利用电路实现逻辑运算。只不过在 20 世纪 40 年代人们还没有将这种能力抽象成一个独立的产品，而且也没有办法解决电路体积的问题，ENIAC的体积看上去就像一所学校那么大。
芯片的计算能力来源于芯片内部的集成电路，集成电路大大减小了电路的体积，所有的元件都是用同一块半导体材料制作而成，也就是把所有的电路都集成到了一个单一的硅片上。为了提高计算性能，集成电路越来越复杂，里面的电子元件也越来越多。从最早拥有 100 个左右晶体管的小型集成电路，发展到 21 世纪初，拥有上亿电子元件的巨大规模集成电路。
芯片的发展，带来了计算能力的飞跃，ENIAC 只能每秒计算 5000 次加法和 400 次乘法，到 1978 年 8086 芯片已经可以每秒计算百万次了。而今天随便一个芯片不但可以轻轻松松每秒计算数亿次，而且不只有一个核心，是多个核心都能达到这一量级的计算能力。
在当时那个年代，Intel 的创始人之一摩尔就观察到了这个现象，并提出了摩尔定律：当价格不变时，集成电路中可容纳的晶体管数目约每隔 18～24 个月就会增加一倍，性能也将提升一倍。这一定律揭示了信息技术发展的速度，但到今天，摩尔定律失效了。因为随着芯片越来越小，在尺寸和散热等方面已经挑战了人类的极限，芯片中无法再放入更多的电子元件了。
但是计算能力又开始以另一种方式发展，比如一个普普通通的 NVIDA 显卡中就拥有了几百个核心，这样就可以进行大量的并发计算；另外，一个分布式的大数据集群，里面就可能有上千个核心。
展望未来，计算能力还有更多的增长点，不仅有可以无限提高计算能力的量子计算机，还有利用光学元件替代晶体元件的光电集成电路。
可计算理论：图灵机 当然，在科学家们尝试发明计算机和芯片之前，他们必须回答一个问题，那就是计算或者程序可以用来做什么？比如：计算可不可以用来做饭？换一个更专业的说法，做饭可不可以被计算？
生活在数字时代的我们，用着导航、玩着游戏，本能地知道很多问题是可以被计算的，但是生活在 20 世纪初的科学家们，需要在没有计算机和芯片的时代就想清楚这些问题，并不是一件容易的事情。
公理化体系和不完备性定理 最早在 19 世纪初，德国著名数学家希尔伯特提出：这个世界可以建立一套完善的公理体系，由少数几个公理出发，推导出所有的定理和推论。这样就可以逐渐通过这种方法将世界上的万事万物都统一到一个体系中。
当然，这只是一个非常美好的设想，如果万事万物都可以用形式化（简单理解就是程序化规范化）的手段统一到一套体系中，也就意味着计算能力将被无限扩展，只要给定足够的时间和空间，计算机就可以完成任何工作。
但在不久后，美籍数学家哥德尔就提出了哥德尔不完备性定理，内容是：即便在完善的公理体系中仍然可以找到不能被证明也不能被证伪的命题。
这让我联想到，一说谎，鼻子就会变长的匹诺曹。如果他说“我说谎了”，那么他的鼻子应该变长还是变短呢？对于人类而言，这个问题可以理解，但是对于计算机来说这个问题是不可以被计算的。
正是因为世界上存在着大量的这种“公说公有理，婆说婆有理”的问题，才让大家认识到计算不能解决所有问题，所以：计算机能力也是有边界的。哥德尔的不完备性定理，让大家看到了世界上还有大量不可计算的问题。
图灵机和可计算理论 于是人们意识到了需要一个理论，专门回答这样的问题：哪些问题可以被计算，哪些不可以被计算，这就是可计算性理论，该理论是计算机科学的理论基础之一。
1936 年，被誉为人工智能之父的阿兰·图灵提出了图灵机，它是一种不断执行指令的抽象计算机。之所以说抽象，是因为图灵并没有真的造出这台机器，而是把它当成理论去和大家探讨可计算问题。</description>
    </item>
    
    <item>
      <title>00 课前必读 构建知识体系，可以这样做！</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/00-%E8%AF%BE%E5%89%8D%E5%BF%85%E8%AF%BB-%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E5%8F%AF%E4%BB%A5%E8%BF%99%E6%A0%B7%E5%81%9A/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:53 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/00-%E8%AF%BE%E5%89%8D%E5%BF%85%E8%AF%BB-%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E5%8F%AF%E4%BB%A5%E8%BF%99%E6%A0%B7%E5%81%9A/</guid>
      <description>我认为，在学习中有一件非常重要的事情，那就是梳理知识体系，所以在进入操作系统课程的学习之前，我想先给你一份这门课程的知识体系（也是一份学习路径），然后再介绍一套我自己梳理知识体系的方法，帮助你更轻松地学好这门课。
课程内容&amp;amp;知识体系 我们先来看下这门课程的知识体系结构，分为 8 个模块，39 个课时，具体如下。
 模块一：（前置知识）计算机组成原理。 如果你对计算机的组成原理中涉及的比如内存、寄存器工作原理、CPU 指令、总线都是怎么工作的这些基本问题，没有搞清楚，大概率会影响你后续对操作系统的学习。因此，在课程开始前，我先来给你一份操作系统的前置知识，帮助你更好地理解后续内容。 模块二：（初探）Linux 指令入门。 这个模块将介绍一些实用的知识，带你入门 Bash 编程，并通过日志分析、性能监控、集群管理等实战场景深入学习 Linux 指令。这些对于日常开发和运维人员来说，都会非常有帮助。 模块三：（总纲）操作系统概述。 这部分帮助你了解操作系统的整体设计，介绍内核、用户空间等基本概念，还会介绍操作系统的分类，以及对比一下市面上的操作系统（如 Windows、Linux、Unix、Android 等），让你对整个操作系统生态能有一个整体的认识。  总的来说，模块四 ~ 模块七是我们这门课程的核心内容，也是面试的重点考区。设置这块内容的目的是借助操作系统的知识，帮你思考如何解决实战问题，比如我们反复提及的高并发、数据一致性、大数据存储和网络问题等。
 模块四：（面试重点）进程和线程。 我会针对大家在面试和工作中最常见的并发和数据同步问题，从进程原理、多线程编程、互斥和乐观锁、死锁和饥饿、调度算法、进程通信等多个方面，同时结合一些语言特性（比如 Java 的语言特性）讲解原理、思考方案及对策。 模块五：（面试重点）内存管理。 这部分我们是从页表和 MMU、虚拟化、内存的分配和回收、缓存置换、逃逸分析、三色算法、生代算法等方面入手，帮助你了解内存的工作原理，应对高并发带来的内存使用问题。 模块六：（面试重点）文件系统。 这部分内容我们将从两个方面入手，一方面是通过学习 Linux 的文件目录结构，了解 Linux 下不同的文件目录的功能和作用，帮助你把 Linux 用好；另一个方面，从文件系统的底层设计入手，帮助你了解文件系统的设计思路和原理，并且通过讲解数据库的文件系统，比如 MySQL 的 InnoDb、B+Tree 以及 Hadoop 的 HDFS，帮你把文件系统的知识应用到处理海量数据的领域。 模块七：（面试重点）网络与安全。 这部分讲解面试中常见的互联网协议群、TCP 和 UDP 协议、Linux 的 I/O 模型、公私钥加密体系，以及一些最基本的计算机网络安全知识，帮助你理解操作系统和网络之间的交互，从而更好地利用操作系统知识设计业务系统的网络架构。 模块八：（知识拓展）虚拟化和其他。 最后这部分，我们将从操作系统的角度学习容器化应用（比如 Kubernetes 和 Docker），还会深入讨论 Linux 架构及商业操作系统。这些知识一方面能够帮你和面试官产生更多的共鸣，另一方面还能帮你开拓视野、打开思路，看到未来的发展趋势。  接下来，我给大家梳理一下操作系统整体的知识框架，帮你扫除知识盲区。
从知识结构上来看，操作系统最核心的部分是进程，因为操作系统自己不能提供服务，它要想实现价值，就必须通过安装在系统中的应用程序。而安装好的应用程序，启动后就成了进程，所以说进程处在操作系统知识体系的核心。
了解了以上内容后，我们围绕进程继续梳理，可以发现：
 进程往往要同时做很多事情，比如浏览器同时要处理网络、又要处理鼠标、还要展示内容，因此有了多线程的概念。 进程需要执行用的存储空间，比如需要存程序指令、需要堆栈存执行数据，因此需要内存。 进程需要将一部分数据持久的存储下来，因此需要文件系统。 进程需要和外界通信，其中一种途径就是网络。 开发过程中我们希望进程可以单独部署，于是需要容器。 操作系统内核本身也是一个程序，可以理解成一个进程，它同样是需要单独研究的。  所以，进程是核心，内核、多线程、内存、文件系统、网络、容器和虚拟是配套的能力。我们要想展开操作系统知识的学习，就要先从它的核心——进程入手，通过进程将操作系统的知识串联起来，然后逐一击破。</description>
    </item>
    
    <item>
      <title>00 开篇词 为什么大厂面试必考操作系统？</title>
      <link>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/00-%E5%BC%80%E7%AF%87%E8%AF%8D-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E5%8E%82%E9%9D%A2%E8%AF%95%E5%BF%85%E8%80%83%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Wed, 22 Dec 2021 01:48:52 +0800</pubDate>
      
      <guid>http://yipsen.github.io/documents/columns/linux/%E9%87%8D%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/00-%E5%BC%80%E7%AF%87%E8%AF%8D-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A4%A7%E5%8E%82%E9%9D%A2%E8%AF%95%E5%BF%85%E8%80%83%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
      <description>你好，发现求知的乐趣，我是林䭽。
我在阿里巴巴做架构的多年时间里，每天都在和复杂的业务场景斗争着，比如如何应对高并发场景？如何解决系统间的数据一致性问题？如何带给用户更快更爽的体验？
在处理一个又一个业务架构、系统架构问题的过程中，我愈发地意识到有一块知识非常重要，也就是我们这门课的主题——操作系统。操作系统可以作为一个完整的知识框架，把复杂如高并发、数据一致性的问题，基础到编程语言、计算框架、业务框架的问题都串联起来。
为什么要学习操作系统？ 操作系统（Operating System）作为一门计算机专业大学必修课，如今已经成为程序员跳槽、涨薪、过面试的必考内容。像面试中高频的考点，比如 Linux 指令、中断、多线程、并发、性能、内存管理、系统稳定性、文件系统、容器和虚拟化等，知识都来源于操作系统。学了操作系统：
 你不懂 Java 多线程，也可以回答好 Java 多线程的面试题； 你不熟悉 Docker，也可以回答出容器化应该如何做。  操作系统已不仅仅是一门大学的必修课那么简单，更是计算机领域的本源知识，任何编程语言学下去都会碰到操作系统知识，比如 Java 的虚拟机、Go 语言的协程与通道、Node.js 的 I/O 模型等。任何研发工具学下去也都会碰到操作系统，比如：
 MySQL 深入学下去会碰到 InnoDB 文件系统； HBase 深入学下去会有 Hadoop 文件系统（HDFS）； Redis 深入学下去会碰到 Linux 的I/O模型； Docker 深入学下去有 Linux 的命名空间等； 甚至 Spring 框架，也需要用到线程池和调度算法。  因此，作为面试官，我们需要通过操作系统知识判断求职者的综合能力，你可以将这些语言、开发工具用到什么层次？是能够使用还是理解原理，甚至具备系统改造的能力？
为什么你要学习我这门操作系统课？ 互联网领域有一个非常重要的分析方法，那就是一件事情如果可以成功，无非就是合适的人，在合适的时间，做合适的事情。接下来，我将结合课程设计思路和自己的人生经历来分析， 你为什么要学习我的这门操作系统课。
我们可以先从“事到人”的角度入手。从事情上说，我希望做一门学了就能用的课程，所以本课程学习目标有两个：一是帮助你顺利通过面试、跳槽涨薪；另一个是帮助你提升应对实际工作场景的能力，具体包括以下几点。
 提升学习和理解能力：比如学习 Redis 可以理解到日志文件系统层面；学习 Java/Python/Node 等语言可以理解到语言最底层。 提升应用架构能力：比如可以将操作系统的微内核架构迁移到自己设计的系统中。 提升系统稳定性架构能力：比如在多线程设计上更出色，可以帮助同事找到设计漏洞。 提升运维能力：做到可以方便地管理集群和分析日志。  下面我再来结合我自身背景和互联网行业特点与你具体聊一聊。
首先，帮你面试涨薪这块我非常有底气，为什么我敢这样说？
我曾在 3 家互联网大厂任职架构师（技术专家），而且是技术委员会成员；另一方面，我做了 10 年的面试官，每年都会到拉勾网筛选简历，保守估计按每年面试 100 个人来算，我至少已经面试过上千人了；还有一方面，我有很多朋友在大厂做技术 Leader，也有很多学生在大厂工作，因此我有一个精准的面试圈子。</description>
    </item>
    
  </channel>
</rss>
